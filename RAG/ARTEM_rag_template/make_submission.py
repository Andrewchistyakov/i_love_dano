# make_submission.py
#!/usr/bin/env python3
import argparse
import csv
import json
from pathlib import Path
from typing import Any, Dict, List, Tuple

import yaml

from rag.config import load_config, AppConfig
from rag.experiments import apply_overrides
from rag.index import load_index
from rag.retrievers import create_retriever
from rag.llms import create_llm
from rag.reranker import create_reranker
from rag.ranker import create_ranker
from rag.pipeline import RAGPipeline


def load_experiment_overrides(experiments_yaml: str, experiment_name: str) -> Dict[str, Any]:
    p = Path(experiments_yaml)
    if not p.exists():
        raise FileNotFoundError(experiments_yaml)
    with open(p, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    for e in data.get("experiments", []):
        if e["name"] == experiment_name:
            return e.get("overrides", {})
    raise ValueError(f"Experiment '{experiment_name}' not found in {experiments_yaml}")


def build_pipeline(cfg: AppConfig) -> RAGPipeline:
    index = load_index(cfg)
    retriever = create_retriever(cfg, index)
    llm = create_llm(cfg.llm)
    ranker = create_ranker(cfg)
    reranker = None
    if ranker is None:
        reranker = create_reranker(cfg)
    return RAGPipeline(cfg, retriever, llm, reranker=reranker, ranker=ranker)


# ====== –ú–µ—Å—Ç–æ, –≥–¥–µ –º—ã –¥–æ—Å—Ç–∞—ë–º sections/pages –∏–∑ —á–∞–Ω–∫–æ–≤ ======

def extract_section_and_page_from_source(source: str) -> Tuple[str | None, str | None]:
    """
    –•–µ–ª–ø–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–æ –ø—É—Ç–∏ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (c['source']) –ø—ã—Ç–∞–µ—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å:
      - section: —Å—Ç—Ä–æ–∫–∞ –≤—Ä–æ–¥–µ "psychological_research/approaches_to_research"
      - page: —Å—Ç—Ä–æ–∫–∞ —Å –Ω–æ–º–µ—Ä–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä "41"

    ‚ö†Ô∏è –û—á–µ–Ω—å –≤–∞–∂–Ω–æ:
    - –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏–∫—É –ø–æ–¥ —Ç–≤–æ—é —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–æ–≤.
    - –°–µ–π—á–∞—Å —Å—Ç–æ–∏—Ç —Ä–∞–∑—É–º–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç: —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –ø—É—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ
        data/docs/<section>/<page>.<ext>
      –∏ –±–µ—Ä—ë–º:
        section = "<section>" –∏–ª–∏ "subdir/subsubdir"
        page = "<stem —Ñ–∞–π–ª–∞>" (—Å –æ—Ç—Ä–µ–∑–∞–Ω–∏–µ–º –ø—Ä–µ—Ñ–∏–∫—Å–∞ 'page_' –µ—Å–ª–∏ –µ—Å—Ç—å)
    """
    p = Path(source)

    # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫—É—Å–æ–∫ –ø—É—Ç–∏ –ø–æ—Å–ª–µ "data/docs"
    parts = p.parts
    section = None
    page = None

    try:
        # –∏—â–µ–º "data" –∏ "docs" –≤ –ø—É—Ç–∏
        if "data" in parts:
            idx_data = parts.index("data")
            # –µ—Å–ª–∏ –¥–∞–ª—å—à–µ –µ—Å—Ç—å "docs" ‚Äî –∏—â–µ–º –ø–æ—Å–ª–µ –Ω–µ–≥–æ
            if "docs" in parts[idx_data + 1:]:
                idx_docs = parts.index("docs", idx_data + 1)
                # –≤—Å—ë, —á—Ç–æ –ø–æ—Å–ª–µ docs, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (—Ñ–∞–π–ª–∞) ‚Äî —Å—á–∏—Ç–∞–µ–º section-–ø—É—Ç—ë–º
                section_parts = parts[idx_docs + 1:-1]
                if section_parts:
                    section = "/".join(section_parts)
        # fallback: –ø—Ä–æ—Å—Ç–æ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –ø–∞–ø–∫–∞
        if section is None:
            section = p.parent.name

        # page: –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        stem = p.stem  # –Ω–∞–ø—Ä–∏–º–µ—Ä "41" –∏–ª–∏ "page_41"
        if stem.lower().startswith("page_"):
            stem = stem[5:]
        page = stem
    except Exception:
        # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ‚Äî –ª—É—á—à–µ –≤–µ—Ä–Ω—É—Ç—å —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
        section = p.parent.name
        page = p.stem

    return section, page


def build_references_from_contexts(contexts: List[Dict]) -> Dict[str, List[str]]:
    """
    –°—Ç—Ä–æ–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
      {
        "sections": [...],
        "pages": [...]
      }
    –ø–æ —Å–ø–∏—Å–∫—É —á–∞–Ω–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Ä–Ω—É–ª RAG-–ø–∞–π–ø–ª–∞–π–Ω.
    """
    sections: List[str] = []
    pages: List[str] = []

    for c in contexts:
        src = c.get("source", "")
        section, page = extract_section_and_page_from_source(src)
        if section and section not in sections:
            sections.append(section)
        if page and page not in pages:
            pages.append(page)

    return {
        "sections": sections,
        "pages": pages,
    }


def main():
    parser = argparse.ArgumentParser(
        description="Generate competition submission file (ID,context,answer,references) from RAG pipeline."
    )
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="Base config.yaml",
    )
    parser.add_argument(
        "--test-path",
        type=str,
        default="data/competition/test_queries.jsonl",
        help="JSONL —Å –ø–æ–ª—è–º–∏ {ID, query} (–æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ: –ø–æ–ª–µ 'ID', –∞ –Ω–µ 'id')",
    )
    parser.add_argument(
        "--out-path",
        type=str,
        default="submission.csv",
        help="–ü—É—Ç—å –¥–æ —Ñ–∞–π–ª–∞ —Å–∞–±–º–∏—Ç–∞ (CSV)",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=None,
        help="Override –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å config.index.top_k)",
    )
    parser.add_argument(
        "--experiments-yaml",
        type=str,
        default="experiments.yaml",
        help="YAML —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏ (–¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞)",
    )
    parser.add_argument(
        "--experiment-name",
        type=str,
        default=None,
        help="–ò–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏–∑ experiments.yaml, —á—å–∏ overrides –ø—Ä–∏–º–µ–Ω–∏—Ç—å",
    )
    args = parser.parse_args()

    cfg = load_config(args.config)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º overrides –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–ª—É—á—à–µ–≥–æ —Ä–µ–∂–∏–º–∞)
    if args.experiment_name is not None:
        overrides = load_experiment_overrides(args.experiments_yaml, args.experiment_name)
        cfg = apply_overrides(cfg, overrides)

    pipeline = build_pipeline(cfg)

    test_path = Path(args.test_path)
    if not test_path.exists():
        raise FileNotFoundError(test_path)

    print(f"üì• –ß–∏—Ç–∞–µ–º —Ç–µ—Å—Ç –∏–∑ {test_path}")
    if test_path.suffix == ".jsonl":
        rows = []
        with open(test_path, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)
                qid = item.get("ID") or item.get("id") or item.get("query_id")
                if qid is None:
                    raise ValueError(f"–°—Ç—Ä–æ–∫–∞ —Ç–µ—Å—Ç–∞ –±–µ–∑ ID: {item}")
                rows.append(
                    {
                        "ID": qid,
                        "query": item["query"],
                    }
                )
    elif test_path.suffix == ".json":
        rows = []
        with open(test_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            for item in data:
                qid = item.get("ID") or item.get("id") or item.get("query_id")
                if qid is None:
                    raise ValueError(f"–°—Ç—Ä–æ–∫–∞ —Ç–µ—Å—Ç–∞ –±–µ–∑ ID: {item}")
                rows.append(
                    {
                        "ID": qid,
                        "query": item["question"],
                    }
                )
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {test_path}")

    print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(rows)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

    out_path = Path(args.out_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    print(f"üì§ –ü–∏—à–µ–º —Å–∞–±–º–∏—Ç –≤ {out_path}")

    with open(out_path, "w", encoding="utf-8", newline="") as f_out:
        writer = csv.writer(f_out)
        # –°—Ç—Ä–æ–≥–æ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –∑–∞–¥–∞—á–∏:
        # ID,context,answer,references
        writer.writerow(["ID", "context", "answer", "references"]) #–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ —á—Ç–æ –Ω–∞–¥–æ

        for i, item in enumerate(rows, 1):
            qid = item["ID"]
            query = item["query"]

            result = pipeline.answer(query, top_k=args.top_k)
            contexts = result["contexts"]
            answer = result["answer"]
            
            # context ‚Äî —ç—Ç–æ —Å–∫–ª–µ–π–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤—Å–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤, –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ç—å –ø—Ä–∏ –Ω–µ –Ω–∞–¥–æ–±–Ω–æ—Å—Ç–∏
            context_text = "\n\n".join(c["text"] for c in contexts)

            # references ‚Äî JSON: {"sections": [...], "pages": [...]}
            refs = build_references_from_contexts(contexts)
            refs_str = json.dumps(refs, ensure_ascii=False)

            writer.writerow([qid, context_text, answer, refs_str]) #—É–±—Ä–∞—Ç—å —á—Ç–æ –Ω–µ –Ω—É–∂–Ω–æ

            if i % 20 == 0 or i == len(rows):
                print(f"  ‚úì –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(rows)}")

    print("‚úÖ –ì–æ—Ç–æ–≤–æ. submission.csv –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.")
    

if __name__ == "__main__":
    main()