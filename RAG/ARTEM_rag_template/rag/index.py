import json
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import numpy as np
from tqdm import tqdm
from rank_bm25 import BM25Okapi

from .config import AppConfig
from .loaders import load_documents
from .chunking import chunk_document
from .embeddings import embed_texts


@dataclass
class SimpleIndex:
    embeddings: np.ndarray
    chunks: List[Dict]
    bm25: Optional[BM25Okapi] = None
    faiss_index: Optional[object] = None  # faiss.Index, –Ω–æ –±–µ–∑ –∂—ë—Å—Ç–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞

    def vector_search(self, query_embedding: np.ndarray, top_k: int) -> Tuple[List[int], List[float]]:
        # FAISS backend, –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.faiss_index is not None:
            import numpy as np  # –ª–æ–∫–∞–ª—å–Ω—ã–π import –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
            q = np.expand_dims(query_embedding.astype("float32"), axis=0)
            scores, idxs = self.faiss_index.search(q, top_k)
            idxs = idxs[0].tolist()
            scores = scores[0].tolist()
            return idxs, scores

        # –ø—Ä–æ—Å—Ç–∞—è numpy dot (cosine similarity, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã)
        sims = self.embeddings @ query_embedding  # shape: (N,)
        idx = np.argsort(-sims)[:top_k]
        return idx.tolist(), sims[idx].tolist()

    def bm25_search(self, tokens: List[str], top_k: int) -> Tuple[List[int], List[float]]:
        if self.bm25 is None:
            raise RuntimeError("BM25 index is not available")
        scores = self.bm25.get_scores(tokens)
        idx = np.argsort(-scores)[:top_k]
        return idx.tolist(), scores[idx].tolist()


def _tokenize(text: str) -> List[str]:
    return [t for t in text.lower().split() if t.strip()]


def _build_faiss_index(emb: np.ndarray, cfg: AppConfig, index_dir: Path) -> Optional[object]:
    backend = (cfg.index.vector_backend or "numpy").lower()
    if backend == "numpy":
        return None

    try:
        import faiss  # type: ignore
    except ImportError:
        print("‚ö†Ô∏è  faiss –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, vector_backend –±—É–¥–µ—Ç 'numpy'.")
        return None

    d = emb.shape[1]

    if backend == "faiss_flat":
        index = faiss.IndexFlatIP(d)
    elif backend == "faiss_hnsw":
        m = cfg.index.faiss_hnsw_m
        index = faiss.IndexHNSWFlat(d, m)
        # –º–æ–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å efSearch –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        index.hnsw.efSearch = max(32, cfg.index.top_k * 2)
    else:
        print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π vector_backend={backend}, –∏—Å–ø–æ–ª—å–∑—É—é numpy.")
        return None

    index.add(emb.astype("float32"))
    faiss.write_index(index, str(index_dir / "faiss.index"))
    print(f"üß± FAISS –∏–Ω–¥–µ–∫—Å ({backend}) —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {index_dir / 'faiss.index'}")
    return index


def build_index(cfg: AppConfig, docs_path: str = "data/docs") -> None:
    """
    –°—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å:
      - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π/—Å–∏–º–≤–æ–ª—å–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥
      - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
      - FAISS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
      - BM25
      - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫
    """
    index_dir = Path(cfg.index.index_dir)
    index_dir.mkdir(parents=True, exist_ok=True)

    print(f"üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ {docs_path} ...")
    docs = load_documents(docs_path)
    all_chunks: List[Dict] = []

    print("‚úÇÔ∏è  –ß–∞–Ω–∫–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã ...")
    for d in tqdm(docs, desc="Docs"):
        chunks = chunk_document(cfg, d["text"], doc_id=d["id"], source=d["path"])
        all_chunks.extend(chunks)

    if not all_chunks:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞")

    print(f"üì¶ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {len(all_chunks)}")

    texts = [c["text"] for c in all_chunks]

    print(f"üß† –°—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ {cfg.embedding.model_name} ...")
    emb = embed_texts(cfg.embedding.model_name, texts)

    print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –º–µ—Ç–∞–¥–∞—Ç—É –∏–Ω–¥–µ–∫—Å–∞ ...")
    np.save(index_dir / "embeddings.npy", emb)

    with open(index_dir / "chunks.jsonl", "w", encoding="utf-8") as f:
        for c in all_chunks:
            f.write(json.dumps(c, ensure_ascii=False) + "\n")

    # FAISS –∏–Ω–¥–µ–∫—Å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    _build_faiss_index(emb, cfg, index_dir)

    # BM25 –∏–Ω–¥–µ–∫—Å
    print("üìê –°—Ç—Ä–æ–∏–º BM25 –∏–Ω–¥–µ–∫—Å ...")
    tokenized_corpus = [_tokenize(t) for t in texts]
    bm25 = BM25Okapi(tokenized_corpus)

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º bm25
    import pickle

    with open(index_dir / "bm25.pkl", "wb") as f:
        pickle.dump({"bm25": bm25}, f)

    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –≥–æ—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {index_dir}")


def load_index(cfg: AppConfig) -> SimpleIndex:
    index_dir = Path(cfg.index.index_dir)
    if not index_dir.exists():
        raise FileNotFoundError(
            f"Index directory {index_dir} not found. "
            "–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ `python main.py build-index`."
        )

    emb_path = index_dir / "embeddings.npy"
    meta_path = index_dir / "chunks.jsonl"

    if not emb_path.exists() or not meta_path.exists():
        raise FileNotFoundError("Index files not found. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å.")

    embeddings = np.load(emb_path)
    chunks: List[Dict] = []
    with open(meta_path, "r", encoding="utf-8") as f:
        for line in f:
            chunks.append(json.loads(line))

    # BM25
    bm25 = None
    bm25_path = index_dir / "bm25.pkl"
    if bm25_path.exists():
        import pickle

        with open(bm25_path, "rb") as f:
            data = pickle.load(f)
            bm25 = data.get("bm25")

    # FAISS (–µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª –∏ backend –Ω–µ numpy)
    faiss_index = None
    backend = (cfg.index.vector_backend or "numpy").lower()
    faiss_path = index_dir / "faiss.index"
    if backend != "numpy" and faiss_path.exists():
        try:
            import faiss  # type: ignore
            faiss_index = faiss.read_index(str(faiss_path))
            print(f"üß± –ó–∞–≥—Ä—É–∂–µ–Ω FAISS –∏–Ω–¥–µ–∫—Å –∏–∑ {faiss_path}")
        except ImportError:
            print("‚ö†Ô∏è  faiss –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é numpy backend.")

    return SimpleIndex(embeddings=embeddings, chunks=chunks, bm25=bm25, faiss_index=faiss_index)