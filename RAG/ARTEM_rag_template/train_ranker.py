#!/usr/bin/env python3
import json
from pathlib import Path

import numpy as np
import joblib
from sklearn.model_selection import GroupKFold
from sklearn.metrics import ndcg_score

from lightgbm import LGBMRanker
from catboost import CatBoostRanker, Pool

from rag.config import load_config
from rag.ranker_features import build_features_for_query
from sentence_transformers import CrossEncoder


def load_ranker_dataset(path: str):
    path = Path(path)
    if not path.exists():
        raise FileNotFoundError(path)

    data = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            data.append(item)
    return data


def build_dataset(cfg, records):
    """
    records: list of {"query", "chunk", "label"}
    -> X, y, groups
    """
    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ query
    from collections import defaultdict

    by_query = defaultdict(list)
    for r in records:
        by_query[r["query"]].append(r)

    rcfg = cfg.ranker
    ce_model = None
    if rcfg.use_cross_encoder_feature:
        ce_model = CrossEncoder(cfg.reranker.model_name)

    X_all = []
    y_all = []
    groups = []

    for qi, (q, items) in enumerate(by_query.items()):
        # candidates –≤ —Ñ–æ—Ä–º–∞—Ç–µ pipeline'–∞
        candidates = []
        for pos, r in enumerate(items):
            candidates.append(
                {
                    "text": r["chunk"],
                    "retrieval_rank": pos,
                }
            )
        X_q, feature_names, _ = build_features_for_query(
            cfg, q, candidates, ce_model=ce_model
        )
        y_q = np.array([r["label"] for r in items], dtype="float32")

        X_all.append(X_q)
        y_all.append(y_q)
        groups.append(len(items))

    X = np.vstack(X_all)
    y = np.concatenate(y_all)
    groups_arr = np.array(groups, dtype=int)

    return X, y, groups_arr, feature_names


def train_ranker():
    import argparse

    parser = argparse.ArgumentParser(
        description="Train supervised ranker (LightGBMRanker / CatBoostRanker)"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="–ü—É—Ç—å –∫ config.yaml",
    )
    parser.add_argument(
        "--data",
        type=str,
        default="data/ranker/train_ranker.jsonl",
        help="JSONL —Å (query, chunk, label)",
    )
    parser.add_argument(
        "--model-type",
        type=str,
        default=None,
        choices=["lgbm", "catboost"],
        help="–¢–∏–ø –º–æ–¥–µ–ª–∏; –µ—Å–ª–∏ None ‚Äî –±–µ—Ä—ë–º –∏–∑ config.ranker.model_type",
    )
    args = parser.parse_args()

    cfg = load_config(args.config)
    rcfg = cfg.ranker
    model_type = args.model_type or rcfg.model_type

    records = load_ranker_dataset(args.data)
    X, y, groups, feature_names = build_dataset(cfg, records)

    print(f"üì¶ samples: {len(y)}, features: {X.shape[1]}, groups: {len(groups)}")

    # CV –ø–æ –≥—Ä—É–ø–ø–∞–º (query)
    gkf = GroupKFold(n_splits=3)
    group_ids = []
    # —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º groups ‚Üí group_id –Ω–∞ –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
    gi = 0
    for n in groups:
        group_ids.extend([gi] * n)
        gi += 1
    group_ids = np.array(group_ids, dtype=int)

    ndcgs = []

    if model_type == "lgbm":
        print("üß† Training LightGBMRanker...")
        for fold, (tr_idx, val_idx) in enumerate(gkf.split(X, y, groups=group_ids), 1):
            model = LGBMRanker(
                n_estimators=200,
                learning_rate=0.05,
                max_depth=-1,
                subsample=0.8,
                colsample_bytree=0.8,
                objective="lambdarank",
                random_state=42 + fold,
            )
            # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –¥–ª—è LightGBM ‚Äî –¥–ª–∏–Ω—ã –≥—Ä—É–ø–ø
            # –ø–æ–ª—É—á–∞–µ–º groups_tr/val –∫–∞–∫ —Å—É–º–º—ã –ø–æ group_ids
            def make_lgbm_groups(idx):
                # idx ‚Äî –∏–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫, –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –¥–ª–∏–Ω—ã –≥—Ä—É–ø–ø –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏—è
                from collections import OrderedDict

                d = OrderedDict()
                for i in idx:
                    g = int(group_ids[i])
                    d.setdefault(g, 0)
                    d[g] += 1
                return list(d.values())

            grp_tr = make_lgbm_groups(tr_idx)
            grp_val = make_lgbm_groups(val_idx)

            model.fit(
                X[tr_idx],
                y[tr_idx],
                group=grp_tr,
                eval_set=[(X[val_idx], y[val_idx])],
                eval_group=[grp_val],
                eval_at=[cfg.index.top_k],
                verbose=False,
            )

            y_pred = model.predict(X[val_idx])
            # —Å—á–∏—Ç–∞–µ–º NDCG@k –Ω–∞ —É—Ä–æ–≤–Ω–µ fold
            # –î–ª—è NDCG –Ω—É–∂–µ–Ω —Ä–∞–∑–±–æ—Ä –ø–æ –≥—Ä—É–ø–ø–∞–º
            ndcgs_fold = []
            start = 0
            for g_size in grp_val:
                end = start + g_size
                nd = ndcg_score(
                    [y[val_idx][start:end]],
                    [y_pred[start:end]],
                    k=cfg.index.top_k,
                )
                ndcgs_fold.append(nd)
                start = end
            ndcgs.append(float(np.mean(ndcgs_fold)))
            print(f"Fold {fold}: NDCG@{cfg.index.top_k} = {ndcgs[-1]:.4f}")

        print(f"‚úÖ CV mean NDCG@{cfg.index.top_k}: {np.mean(ndcgs):.4f}")
        # –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ
        final_model = LGBMRanker(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=-1,
            subsample=0.9,
            colsample_bytree=0.9,
            objective="lambdarank",
            random_state=42,
        )
        final_groups = groups.tolist()
        final_model.fit(X, y, group=final_groups)
        Path(rcfg.model_path).parent.mkdir(parents=True, exist_ok=True)
        joblib.dump(final_model, rcfg.model_path)
        print(f"üíæ LightGBMRanker —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {rcfg.model_path}")

    else:
        print("üß† Training CatBoostRanker...")
        # –¥–ª—è CatBoost –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ group_id –ø—Ä—è–º–æ
        for fold, (tr_idx, val_idx) in enumerate(gkf.split(X, y, groups=group_ids), 1):
            train_pool = Pool(
                X[tr_idx],
                y[tr_idx],
                group_id=group_ids[tr_idx],
                feature_names=feature_names,
            )
            val_pool = Pool(
                X[val_idx],
                y[val_idx],
                group_id=group_ids[val_idx],
                feature_names=feature_names,
            )
            model = CatBoostRanker(
                iterations=300,
                learning_rate=0.05,
                depth=6,
                loss_function="YetiRank",
                random_seed=42 + fold,
                verbose=False,
            )
            model.fit(train_pool, eval_set=val_pool, verbose=False)
            y_pred = model.predict(val_pool)

            # NDCG –ø–æ –≥—Ä—É–ø–ø–∞–º
            ndcgs_fold = []
            # –ø–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–æ–ª–¥–∞
            from collections import OrderedDict
            d = OrderedDict()
            for g in group_ids[val_idx]:
                d.setdefault(int(g), 0)
                d[int(g)] += 1
            grp_val = list(d.values())
            start = 0
            for g_size in grp_val:
                end = start + g_size
                nd = ndcg_score(
                    [y[val_idx][start:end]],
                    [y_pred[start:end]],
                    k=cfg.index.top_k,
                )
                ndcgs_fold.append(nd)
                start = end
            ndcgs.append(float(np.mean(ndcgs_fold)))
            print(f"Fold {fold}: NDCG@{cfg.index.top_k} = {ndcgs[-1]:.4f}")

        print(f"‚úÖ CV mean NDCG@{cfg.index.top_k}: {np.mean(ndcgs):.4f}")
        final_pool = Pool(
            X,
            y,
            group_id=group_ids,
            feature_names=feature_names,
        )
        final_model = CatBoostRanker(
            iterations=400,
            learning_rate=0.05,
            depth=6,
            loss_function="YetiRank",
            random_seed=42,
            verbose=False,
        )
        final_model.fit(final_pool, verbose=False)
        Path(rcfg.model_path).parent.mkdir(parents=True, exist_ok=True)
        joblib.dump(final_model, rcfg.model_path)
        print(f"üíæ CatBoostRanker —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {rcfg.model_path}")


if __name__ == "__main__":
    train_ranker()