{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":25383,"databundleVersionId":2684322,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"2433d0f1-8024-4b7f-bbef-af55252c74de","cell_type":"code","source":"import sys,subprocess\npkgs=[\"autogluon.tabular==1.4.0\",\"catboost==1.2.8\",\"tqdm\"]\nsubprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\"]+pkgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:24:39.000543Z","iopub.execute_input":"2025-11-18T22:24:39.000847Z","iopub.status.idle":"2025-11-18T22:24:52.786430Z","shell.execute_reply.started":"2025-11-18T22:24:39.000823Z","shell.execute_reply":"2025-11-18T22:24:52.785795Z"}},"outputs":[{"name":"stdout","text":"   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 487.3/487.3 kB 9.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.1/225.1 kB 17.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.2/64.2 kB 4.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.0/71.0 kB 6.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 80.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 278.0/278.0 kB 21.0 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":1},{"id":"4e6307c9-ac5b-4e86-ac95-e325c34eb638","cell_type":"code","source":"#!pip install \"protobuf<5\" --force-reinstall -q\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"38ea76f1","cell_type":"code","source":"# Глобальный конфиг для всей тетрадки\n# Здесь можно быстро менять датасет, тип задачи, пути к файлам и настройки картинок.\n\nCONFIG = {\n    # === основные настройки задачи ===\n    \"task_type\": \"regression\",          # \"regression\" | \"binary\" | \"multiclass\"\n    \"metric\": \"rmse\",                   # метрика для AutoGluon / CatBoost / пр.\n\n    # папка с табличными данными и имена файлов\n    \"data_dir\": \".\",                    # где лежат train / test\n    \"train_csv\": \"/kaggle/input/petfinder-pawpularity-score/train.csv\",\n    \"test_csv\": \"/kaggle/input/petfinder-pawpularity-score/test.csv\",\n    \"sep\": \",\",                         # разделитель в csv/tsv\n    \"target_column\": \"Pawpularity\",          # имя таргета\n    \"id_column\": \"Id\",                  # id-колонка в test (можно None)\n\n    # === настройки AutoML / времени ===\n    \"time_limit_sec\": 1800,             # время на medium-модель (сек)\n    \"cat_time_limit_sec\": 1800,         # время на CatBoost-only\n    \"heavy_time_limit_sec\": 7200,       # время на heavy-режим\n    \"autogluon_presets\": \"medium_quality_faster_train\",\n\n    # ---------- images (CLIP) ---------\n    # папка с train-картинками (если используем image-фичи)\n    \"train_images_dir\": \"/kaggle/input/petfinder-pawpularity-score/train\",  # например \"/kaggle/input/petfinder-pawpularity-score/train\"\n\n    # папка с test-картинками (если используем image-фичи)\n    \"test_images_dir\": \"/kaggle/input/petfinder-pawpularity-score/test\",   # например \"/kaggle/input/petfinder-pawpularity-score/test\"\n\n    # Если в таблице image_id уже содержит \".jpg\", поставь image_ext = \"\"\n    # расширение файлов картинок (если в таблице только id без расширения)\n    \"image_ext\": \".jpg\",\n\n    # колонка в таблице с именем файла картинки\n    # Обычно совпадает с id, к которому дописывается image_ext.\n    \"file_names_column\": \"Id\",\n\n    # размер батча при обработке картинок\n    # Чем больше батч, тем быстрее, но тем больше память видеокарты/CPU.\n    \"batch_size\": 32,\n\n    # имя CLIP-модели в HuggingFace, которая используется для извлечения image-эмбеддингов.\n    \"clip_model_name\": \"openai/clip-vit-base-patch32\",\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:26:34.568522Z","iopub.execute_input":"2025-11-18T22:26:34.569231Z","iopub.status.idle":"2025-11-18T22:26:34.574783Z","shell.execute_reply.started":"2025-11-18T22:26:34.569206Z","shell.execute_reply":"2025-11-18T22:26:34.573801Z"}},"outputs":[],"execution_count":3},{"id":"a679f445-f1a1-439d-98e7-c8d9d4c6fa51","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom autogluon.features.generators import AutoMLPipelineFeatureGenerator\nfrom catboost import CatBoostRegressor,Pool\nfrom catboost.utils import get_gpu_device_count\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.auto import tqdm\n\nfrom pathlib import Path\nimport pandas as pd\n\n# базовая папка с данными из CONFIG\npath = Path(CONFIG.get(\"data_dir\", \".\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:26:44.001464Z","iopub.execute_input":"2025-11-18T22:26:44.001738Z","iopub.status.idle":"2025-11-18T22:26:47.467677Z","shell.execute_reply.started":"2025-11-18T22:26:44.001716Z","shell.execute_reply":"2025-11-18T22:26:47.466884Z"}},"outputs":[],"execution_count":4},{"id":"275b3318-8eb5-4a9e-88e8-849c3e610a77","cell_type":"code","source":"# читаем train / test согласно CONFIG\ntrain_path = path / CONFIG.get(\"train_csv\", \"train.csv\")\ntest_path  = path / CONFIG.get(\"test_csv\", \"test.csv\")\n\ntrain = pd.read_csv(train_path, sep=CONFIG.get(\"sep\", \",\"))\ntest = pd.read_csv(test_path,  sep=CONFIG.get(\"sep\", \",\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:26:48.481003Z","iopub.execute_input":"2025-11-18T22:26:48.481814Z","iopub.status.idle":"2025-11-18T22:26:48.522050Z","shell.execute_reply.started":"2025-11-18T22:26:48.481786Z","shell.execute_reply":"2025-11-18T22:26:48.521294Z"}},"outputs":[],"execution_count":5},{"id":"2082ea7a-5081-49d0-81e4-26449b5801fa","cell_type":"code","source":"train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:26:54.485076Z","iopub.execute_input":"2025-11-18T22:26:54.485461Z","iopub.status.idle":"2025-11-18T22:26:54.493027Z","shell.execute_reply.started":"2025-11-18T22:26:54.485435Z","shell.execute_reply":"2025-11-18T22:26:54.492198Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n       'Pawpularity'],\n      dtype='object')"},"metadata":{}}],"execution_count":6},{"id":"e0500cdf-a01f-4afa-b81c-57096632d45d","cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:26:58.050240Z","iopub.execute_input":"2025-11-18T22:26:58.050992Z","iopub.status.idle":"2025-11-18T22:26:58.073704Z","shell.execute_reply.started":"2025-11-18T22:26:58.050964Z","shell.execute_reply":"2025-11-18T22:26:58.072871Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n5  b03f7041962238a7c9d6537e22f9b017              0     0     1     1       1   \n6  c978013571258ed6d4637f6e8cc9d6a3              1     0     0     0       1   \n7  e0de453c1bffc20c22b072b34b54e50f              1     0     1     0       0   \n\n   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n0          1      1        0      0          1     0     1  \n1          0      1        1      0          0     0     0  \n2          1      1        1      0          1     1     1  \n3          0      0        0      0          0     1     0  \n4          1      0        1      0          1     1     0  \n5          1      1        1      1          0     1     0  \n6          1      0        1      0          1     1     1  \n7          0      0        0      1          0     0     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Subject Focus</th>\n      <th>Eyes</th>\n      <th>Face</th>\n      <th>Near</th>\n      <th>Action</th>\n      <th>Accessory</th>\n      <th>Group</th>\n      <th>Collage</th>\n      <th>Human</th>\n      <th>Occlusion</th>\n      <th>Info</th>\n      <th>Blur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4128bae22183829d2b5fea10effdb0c3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43a2262d7738e3d420d453815151079e</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4e429cead1848a298432a0acad014c9d</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8f49844c382931444e68dffbe20228f4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b03f7041962238a7c9d6537e22f9b017</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"2fb01c39-b8e8-43dc-a67c-ec81092f8c8c","cell_type":"code","source":"# выбираем таргет и базовые фичи из CONFIG\ntarget_col = CONFIG.get(\"target_column\", \"target\")  # или как называется таргет в новом датасете\n\nfeature_cols = [c for c in train.columns if c != target_col and c in test.columns]\n\nX = train[feature_cols].copy()\ny = train[target_col].values\nX_test = test[feature_cols].copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:27:00.116184Z","iopub.execute_input":"2025-11-18T22:27:00.116774Z","iopub.status.idle":"2025-11-18T22:27:00.130223Z","shell.execute_reply.started":"2025-11-18T22:27:00.116747Z","shell.execute_reply":"2025-11-18T22:27:00.129615Z"}},"outputs":[],"execution_count":8},{"id":"aad8fe4c","cell_type":"code","source":"# ==== РУЧНЫЕ (КАСТОМНЫЕ) ФИЧИ ====\n# В этой ячейке можно руками дописывать любые фичи на табличных данных.\n# Важно: делайте одинаковые преобразования для train (X) и test (X_test).\n\ndef add_manual_features(X: pd.DataFrame, X_test: pd.DataFrame):\n    \"\"\"\n    Здесь можно руками добавить любые фичи на основе табличных данных.\n    Пример:\n        if \"col1\" in X.columns and \"col2\" in X.columns:\n            X[\"col1_div_col2\"] = X[\"col1\"] / (X[\"col2\"] + 1)\n            X_test[\"col1_div_col2\"] = X_test[\"col1\"] / (X_test[\"col2\"] + 1)\n\n    Не забывайте синхронизировать преобразования для train и test.\n    \"\"\"\n    # --- пример (можно удалить/изменить) ---\n    # if \"col1\" in X.columns and \"col2\" in X.columns:\n    #     X[\"col1_div_col2\"] = X[\"col1\"] / (X[\"col2\"] + 1)\n    #     X_test[\"col1_div_col2\"] = X_test[\"col1\"] / (X_test[\"col2\"] + 1)\n    # ---------------------------------------\n    return X, X_test\n\n\nX, X_test = add_manual_features(X, X_test)\nprint(\"После ручных фичей:\", X.shape, X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:27:06.356072Z","iopub.execute_input":"2025-11-18T22:27:06.356875Z","iopub.status.idle":"2025-11-18T22:27:06.362831Z","shell.execute_reply.started":"2025-11-18T22:27:06.356847Z","shell.execute_reply":"2025-11-18T22:27:06.361994Z"}},"outputs":[{"name":"stdout","text":"После ручных фичей: (9912, 13) (8, 13)\n","output_type":"stream"}],"execution_count":9},{"id":"a8059ec2","cell_type":"code","source":"# ==== ИМЕНОВЫЕ ФИЧИ ИЗ КАРТИНОК (CLIP) ====\n# Если в таблице есть колонка с именем файла картинки, можно добавить\n# к табличным фичам эмбеддинги, посчитанные CLIP-моделью.\n\nimport os\n\nimport torch\nfrom PIL import Image\nfrom transformers import CLIPModel, CLIPProcessor\nfrom tqdm.auto import tqdm\n\ndef _normalize_image_name(name: str, default_ext: str | None = None) -> str:\n    \"\"\"\n    Приводим имя файла к нормальному виду:\n    - убираем пробелы/переводы строк\n    - берём только basename пути\n    - если нет расширения, добавляем default_ext или CONFIG[\"image_ext\"]\n    \"\"\"\n    name = str(name).strip()\n    base = os.path.basename(name)\n    root, ext = os.path.splitext(base)\n    if ext == \"\":\n        if default_ext is None:\n            default_ext = CONFIG.get(\"image_ext\", \"\")\n        return root + (default_ext or \"\")\n    return root + ext\n\n\ndef process_images(file_paths, model, processor, device, name):\n    \"\"\"\n    Считает эмбеддинги для списка путей к картинкам одной CLIP-моделью.\n    Использует CLIPProcessor + CLIPModel.get_image_features.\n    \"\"\"\n    batch_size = CONFIG.get(\"batch_size\", 32)\n\n    collect_embs = []\n    if not file_paths:\n        return pd.DataFrame()\n\n    for start in tqdm(\n        range(0, len(file_paths), batch_size),\n        total=(len(file_paths) + batch_size - 1) // batch_size,\n        desc=f\"Images {name} process...\"\n    ):\n        batch_paths = file_paths[start:start + batch_size]\n        images = []\n        for path in batch_paths:\n            try:\n                img = Image.open(path).convert(\"RGB\")\n            except Exception:\n                # если не удалось открыть картинку — используем заглушку\n                img = Image.new(\"RGB\", (224, 224), color=0)\n            images.append(img)\n\n        with torch.no_grad():\n            inputs = processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n            embs = model.get_image_features(**inputs)\n\n            # L2-нормализация по строкам (num_samples x dim)\n            embs = embs / (embs.norm(dim=-1, keepdim=True) + 1e-12)\n\n        collect_embs.extend(embs.cpu().numpy().tolist())\n\n    if not collect_embs:\n        # На всякий случай, чтобы не упасть на пустом списке\n        return pd.DataFrame()\n\n    n_feat = len(collect_embs[0])\n    return pd.DataFrame(collect_embs, columns=[f\"emb_{i}\" for i in range(n_feat)])\n\n\ndef images_features(X: pd.DataFrame, test_df: pd.DataFrame | None):\n    \"\"\"\n    Добавляет к табличным фичам эмбеддинги картинок, посчитанные CLIP-моделью от OpenAI\n    (через HuggingFace Transformers, только image-encoder).\n\n    Ожидается, что в CONFIG заданы:\n      - 'file_names_column'   — колонка с именами файлов\n      - 'train_images_dir'    — папка с train-картинками\n      - 'test_images_dir'     — папка с test-картинками\n      - 'batch_size'          — размер батча для инференса\n      - 'clip_model_name'     — имя CLIP-модели в HuggingFace (по умолчанию ViT-L/14)\n    \"\"\"\n    file_name_column = CONFIG[\"file_names_column\"]\n\n    if file_name_column not in X.columns:\n        raise KeyError(f\"CONFIG['file_names_column']={file_name_column!r} нет в train (X)\")\n\n    if test_df is not None and file_name_column not in test_df.columns:\n        raise KeyError(f\"CONFIG['file_names_column']={file_name_column!r} нет в test (X_test)\")\n\n    # ----------------- CLIP BACKBONE (image encoder only) -----------------\n    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n        device = \"mps\"\n    else:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    clip_model_name = CONFIG.get(\"clip_model_name\", \"openai/clip-vit-large-patch14\")\n    # Загружаем модель и процессор CLIP\n    model = CLIPModel.from_pretrained(clip_model_name)\n    processor = CLIPProcessor.from_pretrained(clip_model_name)\n\n    model = model.to(device)\n    model.eval()\n\n    # ----------------- TRAIN IMAGES -----------------\n    train_file_paths = [\n        os.path.join(\n            CONFIG[\"train_images_dir\"],\n            _normalize_image_name(file_name, CONFIG.get(\"image_ext\", \"\"))\n        )\n        for file_name in X[file_name_column]\n    ]\n    train_images_part = process_images(train_file_paths, model, processor, device, name=\"train_clip\")\n    train_images_part.index = X.index\n    X = pd.concat([X, train_images_part], axis=1)\n\n    # ----------------- TEST IMAGES ------------------\n    if test_df is not None:\n        test_file_paths = [\n            os.path.join(\n                CONFIG[\"test_images_dir\"],\n                _normalize_image_name(file_name, CONFIG.get(\"image_ext\", \"\"))\n            )\n            for file_name in test_df[file_name_column]\n        ]\n        test_images_part = process_images(test_file_paths, model, processor, device, name=\"test_clip\")\n        test_images_part.index = test_df.index\n        test_df = pd.concat([test_df, test_images_part], axis=1)\n\n    # (опционально) выбрасываем колонку с именем файла, чтобы она не ушла в бустинги\n    for df in (X, test_df):\n        if df is not None and file_name_column in df.columns:\n            df.drop(columns=[file_name_column], inplace=True)\n\n    return X, test_df\n\n\n# Если папка с картинками задана в CONFIG — считаем эмбеддинги и добавляем их к X/X_test\nif CONFIG.get(\"train_images_dir\"):\n    print(\"Images process starts...\")\n    X, X_test = images_features(X, X_test)\n    print(\"После image-фичей:\", X.shape, X_test.shape)\nelse:\n    print(\"CONFIG['train_images_dir'] пуст — image-фичи не считаем.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:27:10.197002Z","iopub.execute_input":"2025-11-18T22:27:10.197685Z","iopub.status.idle":"2025-11-18T22:32:39.657737Z","shell.execute_reply.started":"2025-11-18T22:27:10.197660Z","shell.execute_reply":"2025-11-18T22:32:39.657033Z"}},"outputs":[{"name":"stderr","text":"2025-11-18 22:27:25.182701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763504845.370702      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763504845.422571      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Images process starts...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9afec6ad3d0945fca177cb80ad2946be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dcd67150c804b898509a5f3d3bec345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becf9330a2ff42b9b9e47897b975bc21"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba446048daf34e838767e9f4782b0e71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8d0fcf8e914f00902f6b6543bdae89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c6a77ec57694202b260e636dd15fd3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21f07a7bdb245748527efe1c366f3c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5cc758796646d1b8a3ac27f7e21d2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b59947206c04b2995d105e312131088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Images train_clip process...:   0%|          | 0/310 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ac8b317425c4fbc96e7769c35ce06da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Images test_clip process...:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4bf6dc46c6a4d44b84164485072701a"}},"metadata":{}},{"name":"stdout","text":"После image-фичей: (9912, 524) (8, 524)\n","output_type":"stream"}],"execution_count":10},{"id":"dd1890e6-83d0-4c67-b7d6-9b14b9b89c67","cell_type":"code","source":"print(\"До автофичей:\", X.shape)          # (41105, N_исходных_фич)\nprint(\"Число исходных фич:\", X.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:12.522053Z","iopub.execute_input":"2025-11-18T22:33:12.522813Z","iopub.status.idle":"2025-11-18T22:33:12.527900Z","shell.execute_reply.started":"2025-11-18T22:33:12.522785Z","shell.execute_reply":"2025-11-18T22:33:12.526879Z"}},"outputs":[{"name":"stdout","text":"До автофичей: (9912, 524)\nЧисло исходных фич: 524\n","output_type":"stream"}],"execution_count":12},{"id":"eb3df2cf-72ae-4af4-a57e-11dc67300376","cell_type":"code","source":"from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n\nfg = AutoMLPipelineFeatureGenerator(\n    enable_numeric_features=True,\n    enable_categorical_features=True,\n    enable_datetime_features=True,\n    enable_text_special_features=True,\n    enable_text_ngram_features=True,\n    enable_raw_text_features=False,\n)\n\nX_tr_feat = fg.fit_transform(X=X, y=y)\nX_te_feat = fg.transform(X_test)\n\nprint(X_tr_feat.shape, X_te_feat.shape)\nprint(X_tr_feat.columns[:30])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:14.204301Z","iopub.execute_input":"2025-11-18T22:33:14.204665Z","iopub.status.idle":"2025-11-18T22:33:16.177484Z","shell.execute_reply.started":"2025-11-18T22:33:14.204637Z","shell.execute_reply":"2025-11-18T22:33:16.176635Z"}},"outputs":[{"name":"stdout","text":"(9912, 524) (8, 524)\nIndex(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group',\n       'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'emb_0', 'emb_1',\n       'emb_2', 'emb_3', 'emb_4', 'emb_5', 'emb_6', 'emb_7', 'emb_8', 'emb_9',\n       'emb_10', 'emb_11', 'emb_12', 'emb_13', 'emb_14', 'emb_15', 'emb_16',\n       'emb_17'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":13},{"id":"2728437a-c174-4234-8dd4-7186b85d6d27","cell_type":"code","source":"print(\"После автофичей:\", X_tr_feat.shape)   # (41105, 916)\nprint(\"Число фич после генерации:\", X_tr_feat.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:46.895176Z","iopub.execute_input":"2025-11-18T22:33:46.895994Z","iopub.status.idle":"2025-11-18T22:33:46.900585Z","shell.execute_reply.started":"2025-11-18T22:33:46.895970Z","shell.execute_reply":"2025-11-18T22:33:46.899548Z"}},"outputs":[{"name":"stdout","text":"После автофичей: (9912, 524)\nЧисло фич после генерации: 524\n","output_type":"stream"}],"execution_count":14},{"id":"677f5db2-cb31-4898-8b4c-e3b7a9e931f4","cell_type":"code","source":"from catboost.utils import get_gpu_device_count\nimport catboost, sys\nprint(\"python:\", sys.executable)\nprint(\"catboost version:\", catboost.__version__)\nprint(\"GPU devices seen by catboost:\", get_gpu_device_count())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:47.868203Z","iopub.execute_input":"2025-11-18T22:33:47.868963Z","iopub.status.idle":"2025-11-18T22:33:47.876495Z","shell.execute_reply.started":"2025-11-18T22:33:47.868938Z","shell.execute_reply":"2025-11-18T22:33:47.875626Z"}},"outputs":[{"name":"stdout","text":"python: /usr/bin/python3\ncatboost version: 1.2.8\nGPU devices seen by catboost: 2\n","output_type":"stream"}],"execution_count":15},{"id":"fef3d256-65b6-47d6-8367-d28474cb00b7","cell_type":"code","source":"import numpy as np\n\ncat_cols = [\n    c for c in X_tr_feat.columns\n    if str(X_tr_feat[c].dtype) in (\"category\", \"object\")\n]\n\nfor c in cat_cols:\n    X_tr_feat[c] = X_tr_feat[c].astype(str).replace({\"nan\": \"missing\"}).fillna(\"missing\")\n    if c in X_te_feat.columns:\n        X_te_feat[c] = X_te_feat[c].astype(str).replace({\"nan\": \"missing\"}).fillna(\"missing\")\n\nprint(\"Категориальных колонок:\", len(cat_cols))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:50.949836Z","iopub.execute_input":"2025-11-18T22:33:50.950119Z","iopub.status.idle":"2025-11-18T22:33:50.960897Z","shell.execute_reply.started":"2025-11-18T22:33:50.950097Z","shell.execute_reply":"2025-11-18T22:33:50.960120Z"}},"outputs":[{"name":"stdout","text":"Категориальных колонок: 0\n","output_type":"stream"}],"execution_count":16},{"id":"1570d3ee-e78a-4434-a730-d30b13409ed3","cell_type":"code","source":"cat_features = [\n    c for c in X_tr_feat.columns\n    if str(X_tr_feat[c].dtype) in (\"object\",)  # теперь всё строковое\n]\nprint(len(cat_features), \"cat_features\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:53.047836Z","iopub.execute_input":"2025-11-18T22:33:53.048661Z","iopub.status.idle":"2025-11-18T22:33:53.059852Z","shell.execute_reply.started":"2025-11-18T22:33:53.048616Z","shell.execute_reply":"2025-11-18T22:33:53.059057Z"}},"outputs":[{"name":"stdout","text":"0 cat_features\n","output_type":"stream"}],"execution_count":17},{"id":"9cb16849-4758-4eed-89d9-8160a659592d","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f1e03b40-02e8-46e9-bfcb-df6361bb16a3","cell_type":"code","source":"from catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\nidx = np.arange(len(X_tr_feat))\nnp.random.seed(42)\nnp.random.shuffle(idx)\nsmall_idx = idx[:1000]\n\nX_small = X_tr_feat.iloc[small_idx]\ny_small = y[small_idx]\n\ntrain_pool = Pool(X_small, y_small, cat_features=cat_features)\n\nmodel_gpu_test = CatBoostRegressor(\n    loss_function=\"RMSE\",\n    eval_metric=\"RMSE\",\n    iterations=300,\n    learning_rate=0.05,\n    depth=6,\n    task_type=\"GPU\",\n    devices=\"0\",\n    verbose=50,\n    random_seed=42,\n)\n\nprint(\"=== GPU sanity fit (300 iters on 1000 rows) ===\")\nmodel_gpu_test.fit(train_pool)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:33:55.173897Z","iopub.execute_input":"2025-11-18T22:33:55.174319Z","iopub.status.idle":"2025-11-18T22:33:57.812965Z","shell.execute_reply.started":"2025-11-18T22:33:55.174293Z","shell.execute_reply":"2025-11-18T22:33:57.811876Z"}},"outputs":[{"name":"stdout","text":"=== GPU sanity fit (300 iters on 1000 rows) ===\n0:\tlearn: 20.5999128\ttotal: 147ms\tremaining: 43.9s\n50:\tlearn: 15.9621574\ttotal: 615ms\tremaining: 3s\n100:\tlearn: 13.6811772\ttotal: 995ms\tremaining: 1.96s\n150:\tlearn: 11.5693277\ttotal: 1.3s\tremaining: 1.28s\n200:\tlearn: 9.8029428\ttotal: 1.6s\tremaining: 789ms\n250:\tlearn: 8.2915987\ttotal: 1.9s\tremaining: 372ms\n299:\tlearn: 7.0792625\ttotal: 2.21s\tremaining: 0us\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostRegressor at 0x7bbe07048c10>"},"metadata":{}}],"execution_count":18},{"id":"a28a7b65-8e5d-40c7-9495-a1faee436bdd","cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfor c in X_tr_feat.columns:\n    if X_tr_feat[c].dtype == \"object\":\n        X_tr_feat[c] = X_tr_feat[c].fillna(\"missing\").astype(str)\n        if c in X_te_feat.columns:\n            X_te_feat[c] = X_te_feat[c].fillna(\"missing\").astype(str)\n    else:\n        X_tr_feat[c] = pd.to_numeric(X_tr_feat[c], errors=\"coerce\")\n        if c in X_te_feat.columns:\n            X_te_feat[c] = pd.to_numeric(X_te_feat[c], errors=\"coerce\")\n\ncat_features = [\n    i for i, c in enumerate(X_tr_feat.columns)\n    if X_tr_feat[c].dtype == \"object\"\n]\n\nprint(\"cat_features count:\", len(cat_features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:34:05.539789Z","iopub.execute_input":"2025-11-18T22:34:05.540070Z","iopub.status.idle":"2025-11-18T22:34:05.739885Z","shell.execute_reply.started":"2025-11-18T22:34:05.540047Z","shell.execute_reply":"2025-11-18T22:34:05.738830Z"}},"outputs":[{"name":"stdout","text":"cat_features count: 0\n","output_type":"stream"}],"execution_count":19},{"id":"633ae418-4203-44dc-a557-99585dd29058","cell_type":"code","source":"'''надо поменять вообще было функцию на MAE для этой соревы но я проебался малек'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:34:08.622927Z","iopub.execute_input":"2025-11-18T22:34:08.623681Z","iopub.status.idle":"2025-11-18T22:34:08.628054Z","shell.execute_reply.started":"2025-11-18T22:34:08.623653Z","shell.execute_reply":"2025-11-18T22:34:08.627371Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'надо поменять вообще было функцию на MAE для этой соревы но я проебался малек'"},"metadata":{}}],"execution_count":20},{"id":"049be6d5-42a9-46c2-82c6-d296546b7072","cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor, Pool\nfrom tqdm.auto import tqdm\nimport numpy as np\n\ndef rmse_func(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred) ** 0.5\n\nN_SPLITS = 5\nN_ITER = 3000\nDEPTH = 8\nOD_WAIT = 300\nTASK_TYPE = \"GPU\"\n\nX = X_tr_feat\ny_arr = y\n\nkf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\noof = np.zeros(len(X))\ntest_pred = np.zeros(len(X_te_feat))\nscores = []\n\nfor fold, (tr_idx, val_idx) in enumerate(tqdm(kf.split(X), total=N_SPLITS, desc=\"Folds\"), 1):\n    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n    y_tr, y_val = y_arr[tr_idx], y_arr[val_idx]\n\n    train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n    val_pool = Pool(X_val, y_val, cat_features=cat_features)\n\n    params = dict(\n        loss_function=\"RMSE\",\n        eval_metric=\"RMSE\",\n        iterations=N_ITER,\n        learning_rate=0.01,\n        depth=DEPTH,\n        l2_leaf_reg=3.0,\n        random_seed=42 + fold,\n        verbose=200,\n        od_type=\"Iter\",\n        od_wait=OD_WAIT,\n        task_type=TASK_TYPE,\n    )\n\n    if TASK_TYPE == \"GPU\":\n        params[\"devices\"] = \"0\"\n\n    print(f\"\\n=== Fold {fold}/{N_SPLITS} ===\")\n    model = CatBoostRegressor(**params)\n    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n\n    val_pred = model.predict(X_val)\n    oof[val_idx] = val_pred\n    rmse = rmse_func(y_val, val_pred)\n    scores.append(rmse)\n    print(f\"Fold {fold} RMSE: {rmse:.5f}\")\n\n    bs = 1024\n    fold_test = np.zeros(len(X_te_feat))\n    for s in tqdm(range(0, len(X_te_feat), bs), leave=False, desc=f\"Predict fold {fold}\"):\n        e = s + bs\n        fold_test[s:e] = model.predict(X_te_feat.iloc[s:e])\n    test_pred += fold_test / N_SPLITS\n\noof_rmse = rmse_func(y_arr, oof)\nprint(\"\\nfold_rmse:\", scores)\nprint(\"mean_rmse:\", np.mean(scores))\nprint(\"oof_rmse:\", oof_rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:34:09.057350Z","iopub.execute_input":"2025-11-18T22:34:09.057663Z","iopub.status.idle":"2025-11-18T22:38:34.871524Z","shell.execute_reply.started":"2025-11-18T22:34:09.057642Z","shell.execute_reply":"2025-11-18T22:38:34.870296Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3376a1a3b48d4b319b57d85a3ce19f57"}},"metadata":{}},{"name":"stdout","text":"\n=== Fold 1/5 ===\n0:\tlearn: 20.4522336\ttest: 21.0004615\tbest: 21.0004615 (0)\ttotal: 213ms\tremaining: 10m 38s\n200:\tlearn: 17.9462165\ttest: 19.2109429\tbest: 19.2109429 (200)\ttotal: 20.7s\tremaining: 4m 47s\n400:\tlearn: 16.9086892\ttest: 18.7397518\tbest: 18.7397518 (400)\ttotal: 40.2s\tremaining: 4m 20s\n600:\tlearn: 16.2093929\ttest: 18.5461953\tbest: 18.5461953 (600)\ttotal: 59.4s\tremaining: 3m 57s\n800:\tlearn: 15.6517869\ttest: 18.4435377\tbest: 18.4435377 (800)\ttotal: 1m 18s\tremaining: 3m 35s\n1000:\tlearn: 15.1427062\ttest: 18.3765396\tbest: 18.3765396 (1000)\ttotal: 1m 37s\tremaining: 3m 15s\n1200:\tlearn: 14.6678651\ttest: 18.3274354\tbest: 18.3272006 (1199)\ttotal: 1m 57s\tremaining: 2m 55s\n1400:\tlearn: 14.2334530\ttest: 18.2987755\tbest: 18.2987755 (1400)\ttotal: 2m 16s\tremaining: 2m 36s\n1600:\tlearn: 13.8428466\ttest: 18.2687638\tbest: 18.2687638 (1600)\ttotal: 2m 36s\tremaining: 2m 16s\n1800:\tlearn: 13.4938830\ttest: 18.2518815\tbest: 18.2518815 (1800)\ttotal: 2m 55s\tremaining: 1m 56s\n2000:\tlearn: 13.1561247\ttest: 18.2382448\tbest: 18.2356982 (1953)\ttotal: 3m 15s\tremaining: 1m 37s\n2200:\tlearn: 12.8449331\ttest: 18.2264586\tbest: 18.2259286 (2197)\ttotal: 3m 34s\tremaining: 1m 17s\n2400:\tlearn: 12.5587376\ttest: 18.2197428\tbest: 18.2186417 (2390)\ttotal: 3m 53s\tremaining: 58.4s\n2600:\tlearn: 12.2808337\ttest: 18.2060231\tbest: 18.2060231 (2600)\ttotal: 4m 13s\tremaining: 38.9s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1658882418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Fold {fold}/{N_SPLITS} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5874\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2411\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"id":"2f985a72-c57c-48b3-818b-ffdbbddc0e6b","cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# предполагаем, что есть:\n# - test (оригинальный тестовый df)\n# - test_pred (предсказания из k-fold)\n# - target_col (имя таргета, как в train)\n\nid_col = \"id\"  # или \"ID\", или другое\nfor c in [\"id\", \"ID\", \"Id\"]:\n    if c in test.columns:\n        id_col = c\n        break\n\nif id_col is not None:\n    sub = pd.DataFrame({\n        id_col: test[id_col].values,\n        target_col: test_pred\n    })\nelse:\n    sub = pd.DataFrame({\n        \"id\": np.arange(len(test_pred)),\n        target_col: test_pred\n    })\n\nsub.to_csv(\"submission_catboost_kfold_autofeat_gpu.csv\", index=False)\nsub.head()","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21472</td>\n","      <td>3.420300</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9837</td>\n","      <td>3.249490</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41791</td>\n","      <td>3.861935</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18441</td>\n","      <td>3.117375</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>49348</td>\n","      <td>2.765881</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    target\n","0  21472  3.420300\n","1   9837  3.249490\n","2  41791  3.861935\n","3  18441  3.117375\n","4  49348  2.765881"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"execution_count":33},{"id":"0c4a56ea-dc30-4dbb-8658-b4e6ddb46c5f","cell_type":"code","source":"train_ag = X_tr_feat.copy()\ntrain_ag[target_col] = y\n\ntest_ag = X_te_feat.copy()\n\nprint(train_ag.shape, test_ag.shape)\ntrain_ag.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:38:42.120236Z","iopub.execute_input":"2025-11-18T22:38:42.120684Z","iopub.status.idle":"2025-11-18T22:38:42.195782Z","shell.execute_reply.started":"2025-11-18T22:38:42.120654Z","shell.execute_reply":"2025-11-18T22:38:42.194380Z"}},"outputs":[{"name":"stdout","text":"(9912, 525) (8, 524)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   Subject Focus  Eyes  Face  Near  Action  Accessory  Group  Collage  Human  \\\n0              0     1     1     1       0          0      1        0      0   \n1              0     1     1     0       0          0      0        0      0   \n2              0     1     1     1       0          0      0        0      1   \n3              0     1     1     1       0          0      0        0      0   \n4              0     0     0     1       0          0      1        0      0   \n\n   Occlusion  ...   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508  \\\n0          0  ... -0.024226 -0.033439  0.001547 -0.030126  0.010424  0.003675   \n1          0  ... -0.001851  0.015791 -0.003030 -0.043720 -0.037799 -0.004829   \n2          1  ... -0.024429 -0.050044 -0.004027 -0.035109  0.028670  0.016728   \n3          0  ... -0.024385 -0.022259 -0.007464 -0.027787  0.006609 -0.015715   \n4          0  ... -0.007597 -0.032129 -0.024223 -0.025436  0.030226  0.000809   \n\n    emb_509   emb_510   emb_511  Pawpularity  \n0  0.050864  0.018073  0.016620           63  \n1  0.033755 -0.034391 -0.000073           42  \n2 -0.030991  0.018655  0.028889           28  \n3  0.050974 -0.004093 -0.000825           15  \n4 -0.030022 -0.015488 -0.017500           72  \n\n[5 rows x 525 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject Focus</th>\n      <th>Eyes</th>\n      <th>Face</th>\n      <th>Near</th>\n      <th>Action</th>\n      <th>Accessory</th>\n      <th>Group</th>\n      <th>Collage</th>\n      <th>Human</th>\n      <th>Occlusion</th>\n      <th>...</th>\n      <th>emb_503</th>\n      <th>emb_504</th>\n      <th>emb_505</th>\n      <th>emb_506</th>\n      <th>emb_507</th>\n      <th>emb_508</th>\n      <th>emb_509</th>\n      <th>emb_510</th>\n      <th>emb_511</th>\n      <th>Pawpularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.024226</td>\n      <td>-0.033439</td>\n      <td>0.001547</td>\n      <td>-0.030126</td>\n      <td>0.010424</td>\n      <td>0.003675</td>\n      <td>0.050864</td>\n      <td>0.018073</td>\n      <td>0.016620</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.001851</td>\n      <td>0.015791</td>\n      <td>-0.003030</td>\n      <td>-0.043720</td>\n      <td>-0.037799</td>\n      <td>-0.004829</td>\n      <td>0.033755</td>\n      <td>-0.034391</td>\n      <td>-0.000073</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.024429</td>\n      <td>-0.050044</td>\n      <td>-0.004027</td>\n      <td>-0.035109</td>\n      <td>0.028670</td>\n      <td>0.016728</td>\n      <td>-0.030991</td>\n      <td>0.018655</td>\n      <td>0.028889</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.024385</td>\n      <td>-0.022259</td>\n      <td>-0.007464</td>\n      <td>-0.027787</td>\n      <td>0.006609</td>\n      <td>-0.015715</td>\n      <td>0.050974</td>\n      <td>-0.004093</td>\n      <td>-0.000825</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.007597</td>\n      <td>-0.032129</td>\n      <td>-0.024223</td>\n      <td>-0.025436</td>\n      <td>0.030226</td>\n      <td>0.000809</td>\n      <td>-0.030022</td>\n      <td>-0.015488</td>\n      <td>-0.017500</td>\n      <td>72</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 525 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"id":"08449419-52cc-4063-a7c6-e609c099de4a","cell_type":"code","source":"from autogluon.tabular import TabularPredictor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:40:57.246655Z","iopub.execute_input":"2025-11-18T22:40:57.246971Z","iopub.status.idle":"2025-11-18T22:40:58.096564Z","shell.execute_reply.started":"2025-11-18T22:40:57.246951Z","shell.execute_reply":"2025-11-18T22:40:58.095531Z"}},"outputs":[],"execution_count":24},{"id":"6a8fd937-6cab-4572-ab54-de24f39307e4","cell_type":"code","source":"predictor = TabularPredictor(\n    label=target_col,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\")\n).fit(\n    train_data=train_ag,\n    time_limit=CONFIG.get(\"time_limit_sec\", 1800),  # можно 600/900/3600 по ситуации\n    presets=\"medium_quality_faster_train\",\n    ag_args_fit={\"num_gpus\": 1},\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T22:40:58.098278Z","iopub.execute_input":"2025-11-18T22:40:58.099249Z"}},"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20251118_224058\"\nPreset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.11.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\nCPU Count:          4\nMemory Avail:       28.61 GB / 31.35 GB (91.3%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nPresets specified: ['medium_quality_faster_train']\nUsing hyperparameters preset: hyperparameters='default'\nBeginning AutoGluon training ... Time limit = 1800s\nAutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20251118_224058\"\nTrain Data Rows:    9912\nTrain Data Columns: 524\nLabel Column:       Pawpularity\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29300.77 MB\n\tTrain Data (Original)  Memory Usage: 38.83 MB (0.1% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 12 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('float', []) : 512 | ['emb_0', 'emb_1', 'emb_2', 'emb_3', 'emb_4', ...]\n\t\t('int', [])   :  12 | ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('float', [])     : 512 | ['emb_0', 'emb_1', 'emb_2', 'emb_3', 'emb_4', ...]\n\t\t('int', ['bool']) :  12 | ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', ...]\n\t1.9s = Fit runtime\n\t524 features in original data used to generate 524 features in processed data.\n\tTrain Data (Processed) Memory Usage: 38.83 MB (0.1% of available memory)\nData preprocessing and feature engineering runtime = 1.97s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.1, Train Rows: 8920, Val Rows: 992\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': [{}],\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n\t'CAT': [{}],\n\t'XGB': [{}],\n\t'FASTAI': [{}],\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n}\nFitting 9 L1 models, fit_strategy=\"sequential\" ...\nFitting model: LightGBMXT ... Training model for up to 1798.03s of the 1798.03s of remaining time.\n\tFitting with cpus=2, gpus=1, mem=0.3/28.6 GB\n\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n\t-17.7008\t = Validation score   (-root_mean_squared_error)\n\t22.46s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ... Training model for up to 1775.54s of the 1775.54s of remaining time.\n\tFitting with cpus=2, gpus=1, mem=0.3/28.5 GB\n\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n","output_type":"stream"}],"execution_count":null},{"id":"58d0f23b-2eed-47c0-a80f-d855dd4c67d2","cell_type":"code","source":"print('working')","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["working\n"]}],"execution_count":38},{"id":"238261e6-55f7-4e69-88f2-64ef6b8cd228","cell_type":"code","source":"''' если нужна модель тяжелее хотим presets=\"best_quality\" '''\n\n'''лидерборд'''\n'''\nleaderboard = predictor.leaderboard(train_ag, silent=True)\nleaderboard\n'''\n\n'''предсказания и сабмит'''\n\n'''\nid_col = \"id\"  # или \"ID\", или другое имя, если нужно\n\nag_pred = predictor.predict(test_ag)\n\nsub_ag = test[[id_col]].copy()\nsub_ag[target_col] = ag_pred\n\nsub_ag.to_csv(\"submission_autogluon_autofeat.csv\", index=False)\nsub_ag.head()\n'''\n\n","metadata":{},"outputs":[],"execution_count":null},{"id":"1495a40d-3323-4e27-914e-8bf99072d8c6","cell_type":"code","source":"leaderboard_cat = predictor_cat.leaderboard(train_ag, silent=True)\nleaderboard_cat\n\nag_train_pred = predictor_cat.predict(train_ag)\nag_test_pred = predictor_cat.predict(test_ag)\n","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'predictor_cat' is not defined","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m leaderboard_cat = \u001b[43mpredictor_cat\u001b[49m.leaderboard(train_ag, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m leaderboard_cat\n\u001b[32m      4\u001b[39m ag_train_pred = predictor_cat.predict(train_ag)\n","\u001b[31mNameError\u001b[39m: name 'predictor_cat' is not defined"]}],"execution_count":37},{"id":"1507448a-0062-418a-9d98-d342e771afe4","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"63870e94-daa9-4140-9806-124af99356d5","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"fa6ca4cb-da39-49c6-a6d7-600628cfed2d","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"55a35670-7304-44ba-b61d-f1082579fb80","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"f93b5fe4-ef7a-4287-869e-1cd06b159848","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"e2eecb38-7454-43ae-a2eb-d7dcbf7fbef2","cell_type":"code","source":"\"глюон тока с катбустом\"\n\npredictor_cat = TabularPredictor(\n    label=target_col,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\"),\n).fit(\n    train_data=train_ag,\n    time_limit=CONFIG.get(\"cat_time_limit_sec\", 1800),  # можно уменьшить/увеличить\n    hyperparameters={\n        'CAT': {}   # включаем только CatBoost-модели\n    },\n    ag_args_fit={\"num_gpus\": 1},\n)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"fc9540c4-7653-4e12-9dd3-207cba0a7919","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"37c369a2-3457-433d-9c43-13d8dd131c52","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"37b17a14-2625-480c-a659-141115fe2543","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"a51cabcd-b524-4bd2-bbd9-a0af36f98336","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"8b7795c5-b3f6-4eec-b870-fa1e9b3c96e7","cell_type":"code","source":"id_col = \"id\"  # или \"ID\", или другое имя, если нужно\n\nag_pred = predictor.predict(test_ag)\n\nsub_ag = test[[id_col]].copy()\nsub_ag[target_col] = ag_pred\n\nsub_ag.to_csv(\"submission_autogluon_autofeat_id_target.csv\", index=False)\nsub_ag.head()\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21472</td>\n","      <td>3.371200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9837</td>\n","      <td>3.245652</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41791</td>\n","      <td>4.003885</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18441</td>\n","      <td>3.178790</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>49348</td>\n","      <td>2.697172</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    target\n","0  21472  3.371200\n","1   9837  3.245652\n","2  41791  4.003885\n","3  18441  3.178790\n","4  49348  2.697172"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"execution_count":36},{"id":"41c8b4a3-9abd-47d7-9abc-2a4453c5cc16","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"f9fab672-7faf-4546-a55e-6aedd0cc681a","cell_type":"code","source":"ag_pred = predictor.predict(test_ag)\n\nsub_ag = pd.DataFrame({target_col: ag_pred})\nsub_ag.to_csv(\"submission_autogluon_autofeat_only_id.csv\", index=False)\nsub_ag.head()","metadata":{},"outputs":[],"execution_count":null},{"id":"533b0553-b752-4fdb-aa29-d3ead03e3038","cell_type":"code","source":"from autogluon.tabular import TabularPredictor\n\ntrain_ag = X_tr_feat.copy()\ntrain_ag[target_col] = y\ntest_ag = X_te_feat.copy()\n\ntrain_ag.shape, test_ag.shape","metadata":{},"outputs":[{"data":{"text/plain":["((41105, 917), (9276, 916))"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"execution_count":39},{"id":"36dea177-2150-4f8e-aa6e-36f6025b0de6","cell_type":"code","source":"predictor_cat = TabularPredictor(\n    label=target_col,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\"),\n).fit(\n    train_data=train_ag,\n    time_limit=CONFIG.get(\"cat_time_limit_sec\", 1800),  # можно уменьшить/увеличить\n    hyperparameters={\n        'CAT': {}   # включаем только CatBoost-модели\n    },\n    ag_args_fit={\"num_gpus\": 1},\n)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_190043\"\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.4.0\n","Python Version:     3.12.11\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n","CPU Count:          62\n","Memory Avail:       427.80 GB / 503.46 GB (85.0%)\n","Disk Space Avail:   127.20 GB / 130.00 GB (97.8%)\n","===================================================\n","No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n","\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n","\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n","\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n","\tpresets='high'    : Strong accuracy with fast inference speed.\n","\tpresets='good'    : Good accuracy with very fast inference speed.\n","\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n","Beginning AutoGluon training ... Time limit = 1800s\n","AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_190043\"\n","Train Data Rows:    41105\n","Train Data Columns: 916\n","Label Column:       target\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    438059.18 MB\n","\tTrain Data (Original)  Memory Usage: 145.56 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 593 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])  : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])    : 634 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\t\t('object', []) :   4 | ['name', 'coordinates', 'category', 'address']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])       :  41 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\t\t('int', ['bool']) : 593 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n","\t5.3s = Fit runtime\n","\t916 features in original data used to generate 916 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 114.16 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 5.47s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.060819851599562096, Train Rows: 38605, Val Rows: 2500\n","User-specified model hyperparameters to be fit:\n","{\n","\t'CAT': [{}],\n","}\n","Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoost ... Training model for up to 1794.53s of the 1794.53s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=1.7/427.6 GB\n","\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-0.9819\t = Validation score   (-root_mean_squared_error)\n","\t10.77s\t = Training   runtime\n","\t0.04s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1783.68s of remaining time.\n","\tEnsemble Weights: {'CatBoost': 1.0}\n","\t-0.9819\t = Validation score   (-root_mean_squared_error)\n","\t0.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 16.52s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 55500.8 rows/s (2500 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_190043\")\n"]}],"execution_count":40},{"id":"39c45a5e-dc81-4beb-8a5c-0d3b4aa594ad","cell_type":"code","source":"leaderboard_cat = predictor_cat.leaderboard(train_ag, silent=True)\nleaderboard_cat\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_test</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_test</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_test_marginal</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CatBoost</td>\n","      <td>-1.003955</td>\n","      <td>-0.981936</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.091085</td>\n","      <td>0.044779</td>\n","      <td>10.768425</td>\n","      <td>0.091085</td>\n","      <td>0.044779</td>\n","      <td>10.768425</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-1.003955</td>\n","      <td>-0.981936</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.093464</td>\n","      <td>0.045044</td>\n","      <td>10.770169</td>\n","      <td>0.002378</td>\n","      <td>0.000265</td>\n","      <td>0.001745</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 model  score_test  score_val              eval_metric  \\\n","0             CatBoost   -1.003955  -0.981936  root_mean_squared_error   \n","1  WeightedEnsemble_L2   -1.003955  -0.981936  root_mean_squared_error   \n","\n","   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n","0        0.091085       0.044779  10.768425                 0.091085   \n","1        0.093464       0.045044  10.770169                 0.002378   \n","\n","   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n","0                0.044779          10.768425            1       True   \n","1                0.000265           0.001745            2       True   \n","\n","   fit_order  \n","0          1  \n","1          2  "]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"execution_count":41},{"id":"c1bc2e50-56e8-45b2-9096-caeeba8bf926","cell_type":"code","source":"ag_train_pred = predictor_cat.predict(train_ag)\nag_test_pred = predictor_cat.predict(test_ag)\n","metadata":{},"outputs":[],"execution_count":42},{"id":"5eea09f4-7d0d-415f-b2c9-d6807b699d0f","cell_type":"code","source":"'''blend'''","metadata":{},"outputs":[],"execution_count":null},{"id":"f1dd08de-e792-4274-9bec-368a46561e56","cell_type":"code","source":"from catboost import CatBoostRegressor\nimport numpy as np\n\nZ_train = np.vstack([\n    oof,                    # OOF из твоего KFold CatBoost\n    ag_train_pred.values    # предсказания AutoGluon на train\n]).T\n\nZ_test = np.vstack([\n    test_pred,              # предсказания твоего KFold CatBoost на test\n    ag_test_pred.values     # предсказания AutoGluon на test\n]).T\n\nmeta_model = CatBoostRegressor(\n    loss_function=\"RMSE\",\n    eval_metric=\"RMSE\",\n    iterations=2000,\n    learning_rate=0.03,\n    depth=6,\n    l2_leaf_reg=3.0,\n    random_seed=777,\n    verbose=100,\n    task_type=\"CPU\",   # можно сменить на \"GPU\", devices=\"0\"\n)\n\nmeta_model.fit(Z_train, y)\n\nblend_oof = meta_model.predict(Z_train)\nblend_rmse = rmse_func(y, blend_oof)\nprint(\"blend RMSE:\", blend_rmse)\n\nblend_test = meta_model.predict(Z_test)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0:\tlearn: 1.1803559\ttotal: 16.7ms\tremaining: 33.3s\n","100:\tlearn: 0.9898654\ttotal: 784ms\tremaining: 14.7s\n","200:\tlearn: 0.9848862\ttotal: 1.65s\tremaining: 14.8s\n","300:\tlearn: 0.9827911\ttotal: 2.56s\tremaining: 14.4s\n","400:\tlearn: 0.9804082\ttotal: 3.36s\tremaining: 13.4s\n","500:\tlearn: 0.9781054\ttotal: 4.17s\tremaining: 12.5s\n","600:\tlearn: 0.9761623\ttotal: 4.79s\tremaining: 11.2s\n","700:\tlearn: 0.9744053\ttotal: 5.1s\tremaining: 9.45s\n","800:\tlearn: 0.9728192\ttotal: 5.49s\tremaining: 8.22s\n","900:\tlearn: 0.9713416\ttotal: 5.91s\tremaining: 7.21s\n","1000:\tlearn: 0.9699321\ttotal: 6.33s\tremaining: 6.32s\n","1100:\tlearn: 0.9686531\ttotal: 6.74s\tremaining: 5.5s\n","1200:\tlearn: 0.9674257\ttotal: 7.16s\tremaining: 4.76s\n","1300:\tlearn: 0.9662867\ttotal: 7.59s\tremaining: 4.08s\n","1400:\tlearn: 0.9651149\ttotal: 8.02s\tremaining: 3.43s\n","1500:\tlearn: 0.9640560\ttotal: 8.43s\tremaining: 2.8s\n","1600:\tlearn: 0.9631643\ttotal: 8.83s\tremaining: 2.2s\n","1700:\tlearn: 0.9622188\ttotal: 9.25s\tremaining: 1.63s\n","1800:\tlearn: 0.9613573\ttotal: 9.67s\tremaining: 1.07s\n","1900:\tlearn: 0.9605074\ttotal: 10.1s\tremaining: 525ms\n","1999:\tlearn: 0.9596072\ttotal: 10.5s\tremaining: 0us\n","blend RMSE: 0.959607192599873\n"]}],"execution_count":46},{"id":"03d34f23-39f5-4e58-b694-3c26eef16545","cell_type":"code","source":"# если в test есть id-колонка\nid_col = \"id\"  # или своё имя\n\nsub_blend = test[[id_col]].copy()\nsub_blend[target_col] = blend_test\nsub_blend.to_csv(\"submission_blend_catboost_meta.csv\", index=False)\nsub_blend.head()\n\n","metadata":{},"outputs":[],"execution_count":44},{"id":"d11b6fb3-0313-4939-b335-3108cc9f3d02","cell_type":"code","source":"'''далее улучшение всего вышеперечисленного (потяжелее модели) + маленько иного'''\n'''почти с нуля все'''","metadata":{},"outputs":[],"execution_count":null},{"id":"eaf606f4-60ef-481e-a6ca-556e99937c30","cell_type":"code","source":"DATA_DIR = Path(CONFIG.get(\"data_dir\", \".\"))\n\nTRAIN_PATH = DATA_DIR / \"train.tsv\"   # или train.csv\nTEST_PATH  = DATA_DIR / \"test.tsv\"    # или test.csv\nSEP = CONFIG.get(\"sep\", \",\")            # \"\\t\" для tsv, \",\" для csv\n\nTARGET_COL = CONFIG.get(\"target_column\", \"target\")            # имя таргета\nID_COL = CONFIG.get(\"id_column\", \"id\")                         # имя id-колонки в test (или None, если её нет)\n\ntrain = pd.read_csv(TRAIN_PATH, sep=SEP)\ntest  = pd.read_csv(TEST_PATH,  sep=SEP)\n\nfeature_cols = [c for c in train.columns if c != TARGET_COL and c in test.columns]\n\nX_raw = train[feature_cols].copy()\ny = train[TARGET_COL].values\nX_test_raw = test[feature_cols].copy()\n\nX_raw.shape, X_test_raw.shape\n","metadata":{},"outputs":[{"data":{"text/plain":["((41105, 285), (9276, 285))"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"execution_count":48},{"id":"c16939ac-090a-4762-99ab-1fbe9974bd07","cell_type":"code","source":"fg = AutoMLPipelineFeatureGenerator(\n    enable_numeric_features=True,\n    enable_categorical_features=True,\n    enable_datetime_features=True,\n    enable_text_special_features=True,\n    enable_text_ngram_features=True,\n    enable_raw_text_features=False,\n)\n\nX_tr_feat = fg.fit_transform(X=X_raw, y=y)\nX_te_feat = fg.transform(X_test_raw)\n\nX_tr_feat.shape, X_te_feat.shape\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    437899.84 MB\n","\tTrain Data (Original)  Memory Usage: 101.85 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\t\tFitting TextSpecialFeatureGenerator...\n","\t\t\tFitting BinnedFeatureGenerator...\n","\t\t\tFitting DropDuplicatesFeatureGenerator...\n","\t\tFitting TextNgramFeatureGenerator...\n","\t\t\tFitting CountVectorizer for text features: ['address']\n","\t\t\tCountVectorizer fit with vocabulary size = 792\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])        : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])          :   3 | ['id', 'traffic_300m', 'traffic_1000m']\n","\t\t('object', [])       :   3 | ['name', 'coordinates', 'category']\n","\t\t('object', ['text']) :   1 | ['address']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])                    :   3 | ['name', 'coordinates', 'category']\n","\t\t('category', ['text_as_category'])  :   1 | ['address']\n","\t\t('float', [])                       : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])                         :   3 | ['id', 'traffic_300m', 'traffic_1000m']\n","\t\t('int', ['binned', 'text_special']) :  12 | ['address.char_count', 'address.word_count', 'address.capital_ratio', 'address.digit_ratio', 'address.special_ratio', ...]\n","\t\t('int', ['text_ngram'])             : 619 | ['__nlp__.10', '__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', ...]\n","\t7.0s = Fit runtime\n","\t285 features in original data used to generate 916 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 137.40 MB (0.0% of available memory)\n"]},{"data":{"text/plain":["((41105, 916), (9276, 916))"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"execution_count":49},{"id":"2ea82a69-46d6-4927-a360-8a5b3fb434f3","cell_type":"code","source":"train_ag = X_tr_feat.copy()\ntrain_ag[TARGET_COL] = y\n\ntest_ag = X_te_feat.copy()\n\ntrain_ag.shape, test_ag.shape\n","metadata":{},"outputs":[{"data":{"text/plain":["((41105, 917), (9276, 916))"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"execution_count":50},{"id":"6cff032f-3bb0-4033-9c40-95d5a2385e86","cell_type":"code","source":"hyperparams_base = {\n    \"GBM\": [\n        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM\"}},\n        {\"extra_trees\": True,  \"ag_args\": {\"name_suffix\": \"GBM_XT\"}},\n    ],\n    \"CAT\": {\n        \"iterations\": 4000,\n        \"depth\": 8,\n        \"learning_rate\": 0.01,\n    },\n    \"XGB\": {},\n    \"NN_TORCH\": {},\n}\n\npredictor = TabularPredictor(\n    label=TARGET_COL,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\"),\n).fit(\n    train_data=train_ag,\n    time_limit=1800,\n    presets=\"medium_quality_faster_train\",\n    hyperparameters=hyperparams_base,\n    ag_args_fit={\"num_gpus\": 1},\n)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_215837\"\n","Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.4.0\n","Python Version:     3.12.11\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n","CPU Count:          62\n","Memory Avail:       427.95 GB / 503.46 GB (85.0%)\n","Disk Space Avail:   127.07 GB / 130.00 GB (97.7%)\n","===================================================\n","Presets specified: ['medium_quality_faster_train']\n","Beginning AutoGluon training ... Time limit = 1800s\n","AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_215837\"\n","Train Data Rows:    41105\n","Train Data Columns: 916\n","Label Column:       target\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    438182.15 MB\n","\tTrain Data (Original)  Memory Usage: 137.40 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 593 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('category', []) :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])    : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])      : 634 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])       :  41 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\t\t('int', ['bool']) : 593 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n","\t5.5s = Fit runtime\n","\t916 features in original data used to generate 916 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 114.16 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 5.64s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.060819851599562096, Train Rows: 38605, Val Rows: 2500\n","User-specified model hyperparameters to be fit:\n","{\n","\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM'}}, {'extra_trees': True, 'ag_args': {'name_suffix': 'GBM_XT'}}],\n","\t'CAT': [{'iterations': 4000, 'depth': 8, 'learning_rate': 0.01}],\n","\t'XGB': [{}],\n","\t'NN_TORCH': [{}],\n","}\n","Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM ... Training model for up to 1794.36s of the 1794.36s of remaining time.\n","\tWarning: Exception caused LightGBMGBM to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_XT ... Training model for up to 1793.95s of the 1793.95s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_XT to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoost ... Training model for up to 1793.54s of the 1793.54s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=2.5/427.5 GB\n","\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-0.9789\t = Validation score   (-root_mean_squared_error)\n","\t63.01s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Fitting model: XGBoost ... Training model for up to 1730.40s of the 1730.40s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=1.1/427.5 GB\n","\tWarning: Exception caused XGBoost to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorch ... Training model for up to 1729.24s of the 1729.24s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=0.5/427.3 GB\n","\tWarning: Exception caused NeuralNetTorch to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1728.76s of remaining time.\n","\tEnsemble Weights: {'CatBoost': 1.0}\n","\t-0.9789\t = Validation score   (-root_mean_squared_error)\n","\t0.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 71.45s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 48657.1 rows/s (2500 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_215837\")\n"]}],"execution_count":51},{"id":"7a93ef89-36b3-4d09-89ee-d45d97d8acf2","cell_type":"code","source":"hyperparams_extra = {\n    \"CAT\": {\n        \"iterations\": 4000,\n        \"depth\": 8,\n        \"learning_rate\": 0.02,\n    },\n    \"GBM\": [\n        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM_extra\"}},\n        {\"extra_trees\": True,  \"ag_args\": {\"name_suffix\": \"GBM_XT_extra\"}},\n    ],\n}\n\npredictor = predictor.fit_extra(\n    hyperparameters=hyperparams_extra,\n    ag_args_fit={\"num_gpus\": 1},\n    time_limit=1200,\n)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_extra ... Training model for up to 1200.00s of the 1200.00s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_extra to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_XT_extra ... Training model for up to 1199.56s of the 1199.56s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_XT_extra to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoost_2 ... Training model for up to 1199.11s of the 1199.11s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=2.5/427.6 GB\n","\tTraining CatBoost_2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-0.9797\t = Validation score   (-root_mean_squared_error)\n","\t30.82s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Fitting model: WeightedEnsemble_2_L2 ... Training model for up to 360.00s of the 1168.20s of remaining time.\n","\tEnsemble Weights: {'CatBoost_2': 1.0}\n","\t-0.9797\t = Validation score   (-root_mean_squared_error)\n","\t0.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_215837\")\n"]}],"execution_count":52},{"id":"0f1f1677-a8d2-4509-9aef-108f8abdb832","cell_type":"code","source":"lb = predictor.leaderboard(train_ag, silent=True)\nlb\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_test</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_test</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_test_marginal</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CatBoost</td>\n","      <td>-0.999949</td>\n","      <td>-0.978940</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.148261</td>\n","      <td>0.051061</td>\n","      <td>63.012222</td>\n","      <td>0.148261</td>\n","      <td>0.051061</td>\n","      <td>63.012222</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-0.999949</td>\n","      <td>-0.978940</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.151422</td>\n","      <td>0.051380</td>\n","      <td>63.014216</td>\n","      <td>0.003161</td>\n","      <td>0.000319</td>\n","      <td>0.001994</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CatBoost_2</td>\n","      <td>-1.003683</td>\n","      <td>-0.979668</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.102016</td>\n","      <td>0.051478</td>\n","      <td>30.824694</td>\n","      <td>0.102016</td>\n","      <td>0.051478</td>\n","      <td>30.824694</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>WeightedEnsemble_2_L2</td>\n","      <td>-1.003683</td>\n","      <td>-0.979668</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.104718</td>\n","      <td>0.051771</td>\n","      <td>30.826800</td>\n","      <td>0.002702</td>\n","      <td>0.000293</td>\n","      <td>0.002107</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   model  score_test  score_val              eval_metric  \\\n","0               CatBoost   -0.999949  -0.978940  root_mean_squared_error   \n","1    WeightedEnsemble_L2   -0.999949  -0.978940  root_mean_squared_error   \n","2             CatBoost_2   -1.003683  -0.979668  root_mean_squared_error   \n","3  WeightedEnsemble_2_L2   -1.003683  -0.979668  root_mean_squared_error   \n","\n","   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n","0        0.148261       0.051061  63.012222                 0.148261   \n","1        0.151422       0.051380  63.014216                 0.003161   \n","2        0.102016       0.051478  30.824694                 0.102016   \n","3        0.104718       0.051771  30.826800                 0.002702   \n","\n","   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n","0                0.051061          63.012222            1       True   \n","1                0.000319           0.001994            2       True   \n","2                0.051478          30.824694            1       True   \n","3                0.000293           0.002107            2       True   \n","\n","   fit_order  \n","0          1  \n","1          2  \n","2          3  \n","3          4  "]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"execution_count":53},{"id":"221e816c-4198-4ecf-b1b7-9fe596ff0a03","cell_type":"code","source":"fi = predictor.feature_importance(train_ag)\nfi.head(20)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Computing feature importance via permutation shuffling for 916 features using 5000 rows with 5 shuffle sets...\n","\t1571.19s\t= Expected runtime (314.24s per shuffle set)\n","\t133.35s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","      <th>stddev</th>\n","      <th>p_value</th>\n","      <th>n</th>\n","      <th>p99_high</th>\n","      <th>p99_low</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>category</th>\n","      <td>0.190031</td>\n","      <td>0.003282</td>\n","      <td>1.067495e-08</td>\n","      <td>5</td>\n","      <td>0.196789</td>\n","      <td>0.183273</td>\n","    </tr>\n","    <tr>\n","      <th>name</th>\n","      <td>0.095356</td>\n","      <td>0.005808</td>\n","      <td>1.643011e-06</td>\n","      <td>5</td>\n","      <td>0.107314</td>\n","      <td>0.083398</td>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <td>0.011836</td>\n","      <td>0.002606</td>\n","      <td>2.648099e-04</td>\n","      <td>5</td>\n","      <td>0.017202</td>\n","      <td>0.006469</td>\n","    </tr>\n","    <tr>\n","      <th>coordinates</th>\n","      <td>0.008139</td>\n","      <td>0.001545</td>\n","      <td>1.486646e-04</td>\n","      <td>5</td>\n","      <td>0.011320</td>\n","      <td>0.004957</td>\n","    </tr>\n","    <tr>\n","      <th>address</th>\n","      <td>0.005589</td>\n","      <td>0.001491</td>\n","      <td>5.540305e-04</td>\n","      <td>5</td>\n","      <td>0.008659</td>\n","      <td>0.002519</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.москва</th>\n","      <td>0.000860</td>\n","      <td>0.000214</td>\n","      <td>4.270179e-04</td>\n","      <td>5</td>\n","      <td>0.001301</td>\n","      <td>0.000418</td>\n","    </tr>\n","    <tr>\n","      <th>mean_income_1000m</th>\n","      <td>0.000773</td>\n","      <td>0.000084</td>\n","      <td>1.655252e-05</td>\n","      <td>5</td>\n","      <td>0.000946</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.троицк</th>\n","      <td>0.000737</td>\n","      <td>0.000363</td>\n","      <td>5.234521e-03</td>\n","      <td>5</td>\n","      <td>0.001484</td>\n","      <td>-0.000010</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.зеленоград</th>\n","      <td>0.000690</td>\n","      <td>0.000302</td>\n","      <td>3.444998e-03</td>\n","      <td>5</td>\n","      <td>0.001311</td>\n","      <td>0.000069</td>\n","    </tr>\n","    <tr>\n","      <th>mean_income_300m</th>\n","      <td>0.000645</td>\n","      <td>0.000161</td>\n","      <td>4.294521e-04</td>\n","      <td>5</td>\n","      <td>0.000977</td>\n","      <td>0.000314</td>\n","    </tr>\n","    <tr>\n","      <th>pregnancy_websites_300m</th>\n","      <td>0.000611</td>\n","      <td>0.000125</td>\n","      <td>1.991233e-04</td>\n","      <td>5</td>\n","      <td>0.000868</td>\n","      <td>0.000353</td>\n","    </tr>\n","    <tr>\n","      <th>children_goods_for_walks_and_travel_300m</th>\n","      <td>0.000597</td>\n","      <td>0.000139</td>\n","      <td>3.240168e-04</td>\n","      <td>5</td>\n","      <td>0.000882</td>\n","      <td>0.000312</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.боровское</th>\n","      <td>0.000567</td>\n","      <td>0.000169</td>\n","      <td>8.354882e-04</td>\n","      <td>5</td>\n","      <td>0.000914</td>\n","      <td>0.000220</td>\n","    </tr>\n","    <tr>\n","      <th>address.word_count</th>\n","      <td>0.000501</td>\n","      <td>0.000197</td>\n","      <td>2.359398e-03</td>\n","      <td>5</td>\n","      <td>0.000907</td>\n","      <td>0.000096</td>\n","    </tr>\n","    <tr>\n","      <th>anime_1000m</th>\n","      <td>0.000395</td>\n","      <td>0.000162</td>\n","      <td>2.717358e-03</td>\n","      <td>5</td>\n","      <td>0.000728</td>\n","      <td>0.000063</td>\n","    </tr>\n","    <tr>\n","      <th>baby_food_1000m</th>\n","      <td>0.000354</td>\n","      <td>0.000195</td>\n","      <td>7.664168e-03</td>\n","      <td>5</td>\n","      <td>0.000755</td>\n","      <td>-0.000047</td>\n","    </tr>\n","    <tr>\n","      <th>address.symbol_count..</th>\n","      <td>0.000351</td>\n","      <td>0.000165</td>\n","      <td>4.478139e-03</td>\n","      <td>5</td>\n","      <td>0.000692</td>\n","      <td>0.000011</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.арбат</th>\n","      <td>0.000297</td>\n","      <td>0.000303</td>\n","      <td>4.707519e-02</td>\n","      <td>5</td>\n","      <td>0.000922</td>\n","      <td>-0.000328</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.балашиха</th>\n","      <td>0.000279</td>\n","      <td>0.000149</td>\n","      <td>6.852329e-03</td>\n","      <td>5</td>\n","      <td>0.000585</td>\n","      <td>-0.000027</td>\n","    </tr>\n","    <tr>\n","      <th>bars_1000m</th>\n","      <td>0.000261</td>\n","      <td>0.000147</td>\n","      <td>8.304146e-03</td>\n","      <td>5</td>\n","      <td>0.000564</td>\n","      <td>-0.000042</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          importance    stddev       p_value  \\\n","category                                    0.190031  0.003282  1.067495e-08   \n","name                                        0.095356  0.005808  1.643011e-06   \n","id                                          0.011836  0.002606  2.648099e-04   \n","coordinates                                 0.008139  0.001545  1.486646e-04   \n","address                                     0.005589  0.001491  5.540305e-04   \n","__nlp__.москва                              0.000860  0.000214  4.270179e-04   \n","mean_income_1000m                           0.000773  0.000084  1.655252e-05   \n","__nlp__.троицк                              0.000737  0.000363  5.234521e-03   \n","__nlp__.зеленоград                          0.000690  0.000302  3.444998e-03   \n","mean_income_300m                            0.000645  0.000161  4.294521e-04   \n","pregnancy_websites_300m                     0.000611  0.000125  1.991233e-04   \n","children_goods_for_walks_and_travel_300m    0.000597  0.000139  3.240168e-04   \n","__nlp__.боровское                           0.000567  0.000169  8.354882e-04   \n","address.word_count                          0.000501  0.000197  2.359398e-03   \n","anime_1000m                                 0.000395  0.000162  2.717358e-03   \n","baby_food_1000m                             0.000354  0.000195  7.664168e-03   \n","address.symbol_count..                      0.000351  0.000165  4.478139e-03   \n","__nlp__.арбат                               0.000297  0.000303  4.707519e-02   \n","__nlp__.балашиха                            0.000279  0.000149  6.852329e-03   \n","bars_1000m                                  0.000261  0.000147  8.304146e-03   \n","\n","                                          n  p99_high   p99_low  \n","category                                  5  0.196789  0.183273  \n","name                                      5  0.107314  0.083398  \n","id                                        5  0.017202  0.006469  \n","coordinates                               5  0.011320  0.004957  \n","address                                   5  0.008659  0.002519  \n","__nlp__.москва                            5  0.001301  0.000418  \n","mean_income_1000m                         5  0.000946  0.000600  \n","__nlp__.троицк                            5  0.001484 -0.000010  \n","__nlp__.зеленоград                        5  0.001311  0.000069  \n","mean_income_300m                          5  0.000977  0.000314  \n","pregnancy_websites_300m                   5  0.000868  0.000353  \n","children_goods_for_walks_and_travel_300m  5  0.000882  0.000312  \n","__nlp__.боровское                         5  0.000914  0.000220  \n","address.word_count                        5  0.000907  0.000096  \n","anime_1000m                               5  0.000728  0.000063  \n","baby_food_1000m                           5  0.000755 -0.000047  \n","address.symbol_count..                    5  0.000692  0.000011  \n","__nlp__.арбат                             5  0.000922 -0.000328  \n","__nlp__.балашиха                          5  0.000585 -0.000027  \n","bars_1000m                                5  0.000564 -0.000042  "]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"execution_count":54},{"id":"dfacfb9c-b9fd-48c4-bbfb-1eabf772afe2","cell_type":"code","source":"important_features = fi[fi[\"importance\"] > 0].index.tolist()\nlen(important_features)\n","metadata":{},"outputs":[{"data":{"text/plain":["726"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"execution_count":55},{"id":"04ead45c-3b57-4a1a-963b-d57d9ff83bd8","cell_type":"code","source":"train_ag_imp = train_ag[important_features + [TARGET_COL]].copy()\ntest_ag_imp  = test_ag[important_features].copy()\n\ntrain_ag_imp.shape, test_ag_imp.shape\n","metadata":{},"outputs":[{"data":{"text/plain":["((41105, 727), (9276, 726))"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"execution_count":56},{"id":"67760612-3089-40ee-b970-953f0aff6507","cell_type":"code","source":"hyperparams_slim = {\n    \"CAT\": {\n        \"iterations\": 4000,\n        \"depth\": 7,\n        \"learning_rate\": 0.01,\n    },\n    \"GBM\": [\n        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM_slim\"}},\n    ],\n}\n\npredictor_slim = TabularPredictor(\n    label=TARGET_COL,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\"),\n).fit(\n    train_data=train_ag_imp,\n    time_limit=1200,\n    presets=\"medium_quality_faster_train\",\n    hyperparameters=hyperparams_slim,\n    ag_args_fit={\"num_gpus\": 1},\n)","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_220420\"\n","Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.4.0\n","Python Version:     3.12.11\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n","CPU Count:          62\n","Memory Avail:       423.48 GB / 503.46 GB (84.1%)\n","Disk Space Avail:   126.92 GB / 130.00 GB (97.6%)\n","===================================================\n","Presets specified: ['medium_quality_faster_train']\n","Beginning AutoGluon training ... Time limit = 1200s\n","AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_220420\"\n","Train Data Rows:    41105\n","Train Data Columns: 726\n","Label Column:       target\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    433659.80 MB\n","\tTrain Data (Original)  Memory Usage: 121.33 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 411 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('category', []) :   4 | ['category', 'name', 'coordinates', 'address']\n","\t\t('float', [])    : 273 | ['mean_income_1000m', 'mean_income_300m', 'pregnancy_websites_300m', 'children_goods_for_walks_and_travel_300m', 'anime_1000m', ...]\n","\t\t('int', [])      : 449 | ['id', '__nlp__.москва', '__nlp__.троицк', '__nlp__.зеленоград', '__nlp__.боровское', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :   4 | ['category', 'name', 'coordinates', 'address']\n","\t\t('float', [])     : 273 | ['mean_income_1000m', 'mean_income_300m', 'pregnancy_websites_300m', 'children_goods_for_walks_and_travel_300m', 'anime_1000m', ...]\n","\t\t('int', [])       :  38 | ['id', '__nlp__.москва', 'address.word_count', 'address.symbol_count..', '__nlp__.мытищи', ...]\n","\t\t('int', ['bool']) : 411 | ['__nlp__.троицк', '__nlp__.зеленоград', '__nlp__.боровское', '__nlp__.арбат', '__nlp__.балашиха', ...]\n","\t4.3s = Fit runtime\n","\t726 features in original data used to generate 726 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 105.22 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 4.43s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.060819851599562096, Train Rows: 38605, Val Rows: 2500\n","User-specified model hyperparameters to be fit:\n","{\n","\t'CAT': [{'iterations': 4000, 'depth': 7, 'learning_rate': 0.01}],\n","\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_slim'}}],\n","}\n","Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_slim ... Training model for up to 1195.57s of the 1195.57s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_slim to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoost ... Training model for up to 1195.21s of the 1195.21s of remaining time.\n","\tFitting with cpus=62, gpus=1, mem=1.5/423.3 GB\n","\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-0.9622\t = Validation score   (-mean_squared_error)\n","\t50.96s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1144.12s of remaining time.\n","\tEnsemble Weights: {'CatBoost': 1.0}\n","\t-0.9622\t = Validation score   (-mean_squared_error)\n","\t0.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 56.06s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 52511.8 rows/s (2500 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_220420\")\n"]}],"execution_count":57},{"id":"97d4aea5-244b-4258-b02b-b7c3cce53caf","cell_type":"code","source":"test_pred_base = predictor.predict(test_ag)\ntest_pred_slim = predictor_slim.predict(test_ag_imp)\n\ntest_pred_blend = 0.5 * test_pred_base.values + 0.5 * test_pred_slim.values\n","metadata":{},"outputs":[],"execution_count":58},{"id":"d5142bd8-96c3-4a8d-b0e7-e5b9f7d952c8","cell_type":"code","source":"if ID_COL is not None and ID_COL in test.columns:\n    sub_base = test[[ID_COL]].copy()\n    sub_slim = test[[ID_COL]].copy()\n    sub_blend = test[[ID_COL]].copy()\nelse:\n    sub_base = pd.DataFrame()\n    sub_slim = pd.DataFrame()\n    sub_blend = pd.DataFrame()\n\nsub_base[TARGET_COL] = test_pred_base\nsub_slim[TARGET_COL] = test_pred_slim\nsub_blend[TARGET_COL] = test_pred_blend\n\nsub_base.to_csv(\"submission_ag_base.csv\", index=False)\nsub_slim.to_csv(\"submission_ag_slim.csv\", index=False)\nsub_blend.to_csv(\"submission_ag_blend.csv\", index=False)\n\nsub_blend.head()\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21472</td>\n","      <td>3.402225</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9837</td>\n","      <td>3.115150</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41791</td>\n","      <td>3.925786</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18441</td>\n","      <td>3.096871</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>49348</td>\n","      <td>2.726351</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    target\n","0  21472  3.402225\n","1   9837  3.115150\n","2  41791  3.925786\n","3  18441  3.096871\n","4  49348  2.726351"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"execution_count":59},{"id":"f4abd345-cf01-430e-9640-710f5f40781a","cell_type":"code","source":"'''сейчас попробую взять еще толще модели, а то скор сильно не меняется'''","metadata":{},"outputs":[],"execution_count":null},{"id":"3b1cdcba-a25a-48db-9ba8-30d0d9ad965d","cell_type":"code","source":"heavy_hps = {\n    \"GBM\": [\n        {\n            \"extra_trees\": False,\n            \"ag_args\": {\"name_suffix\": \"GBM_main\"},\n            \"num_leaves\": 64,\n            \"feature_fraction\": 0.9,\n            \"bagging_fraction\": 0.9,\n            \"bagging_freq\": 1,\n        },\n        {\n            \"extra_trees\": True,\n            \"ag_args\": {\"name_suffix\": \"GBM_xt\"},\n            \"num_leaves\": 128,\n            \"feature_fraction\": 0.8,\n            \"bagging_fraction\": 0.8,\n            \"bagging_freq\": 1,\n        },\n    ],\n    \"CAT\": [\n        {\n            \"iterations\": 6000,\n            \"depth\": 8,\n            \"learning_rate\": 0.03,\n            \"l2_leaf_reg\": 3.0,\n            \"border_count\": 254,\n            \"random_strength\": 0.5,\n            \"bagging_temperature\": 0.8,\n            \"ag_args\": {\"name_suffix\": \"CAT_main\"},\n        },\n        {\n            \"iterations\": 8000,\n            \"depth\": 10,\n            \"learning_rate\": 0.02,\n            \"l2_leaf_reg\": 4.0,\n            \"border_count\": 254,\n            \"random_strength\": 0.3,\n            \"bagging_temperature\": 0.5,\n            \"ag_args\": {\"name_suffix\": \"CAT_deep\"},\n        },\n    ],\n    \"XGB\": {\n        \"max_depth\": 8,\n        \"subsample\": 0.9,\n        \"colsample_bytree\": 0.9,\n        \"n_estimators\": 4000,\n        \"learning_rate\": 0.03,\n    },\n    \"NN_TORCH\": {\n        \"ag_args\": {\"name_suffix\": \"NN_heavy\"},\n        \"layers\": \"128-64-64\",\n        \"dropout_prob\": 0.1,\n    },\n}\n","metadata":{},"outputs":[],"execution_count":60},{"id":"845a2649-65d2-4b34-b999-7ff4fd6ca40c","cell_type":"code","source":"from autogluon.tabular import TabularPredictor\n\nheavy_time_limit = CONFIG.get(\"heavy_time_limit_sec\", 7200)  # 2 часа, под задачу можно меньше/больше\n\npredictor_heavy = TabularPredictor(\n    label=TARGET_COL,\n    problem_type=CONFIG.get(\"task_type\", \"regression\"),\n    eval_metric=CONFIG.get(\"metric\", \"rmse\"),\n).fit(\n    train_data=train_ag,\n    time_limit=heavy_time_limit,\n    presets=\"best_quality\",          # heavy режим\n    num_bag_folds=5,                 # бэггинг по фолдам\n    num_bag_sets=2,                  # повторение бэггинга\n    num_stack_levels=2,              # двухуровневый stacking\n    hyperparameters=heavy_hps,\n    ag_args_fit={\"num_gpus\": 1},\n)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_221138\"\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.4.0\n","Python Version:     3.12.11\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n","CPU Count:          62\n","Memory Avail:       427.52 GB / 503.46 GB (84.9%)\n","Disk Space Avail:   126.78 GB / 130.00 GB (97.5%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=2\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n","/venv/main/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1444: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.10.0,<2.45.0\"`')\n","  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n","\t\tContext path: \"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\"\n","Running DyStack sub-fit ...\n","Beginning AutoGluon training ... Time limit = 1800s\n","AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\"\n","Train Data Rows:    36537\n","Train Data Columns: 916\n","Label Column:       target\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    437501.30 MB\n","\tTrain Data (Original)  Memory Usage: 122.13 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 594 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tUnused Original Features (Count: 26): ['__nlp__.11 стр москва', '__nlp__.12 корп москва', '__nlp__.13 корп москва', '__nlp__.1с1 москва', '__nlp__.20 корп москва', '__nlp__.22 стр москва', '__nlp__.23а', '__nlp__.30 стр', '__nlp__.32 корп москва', '__nlp__.бул корп москва', '__nlp__.городской округ подольск', '__nlp__.калужское шоссе', '__nlp__.киевское шоссе', '__nlp__.комсомольский просп', '__nlp__.кутузовский просп', '__nlp__.ореховый бул', '__nlp__.пр 12', '__nlp__.просп вернадского', '__nlp__.просп мира', '__nlp__.семёновская ул', '__nlp__.стр 12 москва', '__nlp__.территория', '__nlp__.ул академика', '__nlp__.ул александры', '__nlp__.центральная ул', '__nlp__.южная ул']\n","\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n","\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n","\t\tThese features do not need to be present at inference time.\n","\t\t('int', []) : 26 | ['__nlp__.11 стр москва', '__nlp__.12 корп москва', '__nlp__.13 корп москва', '__nlp__.1с1 москва', '__nlp__.20 корп москва', ...]\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('category', []) :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])    : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])      : 608 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])       :  40 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\t\t('int', ['bool']) : 568 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n","\t4.7s = Fit runtime\n","\t890 features in original data used to generate 890 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 100.53 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 4.89s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","User-specified model hyperparameters to be fit:\n","{\n","\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_main'}, 'num_leaves': 64, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1}, {'extra_trees': True, 'ag_args': {'name_suffix': 'GBM_xt'}, 'num_leaves': 128, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1}],\n","\t'CAT': [{'iterations': 6000, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 3.0, 'border_count': 254, 'random_strength': 0.5, 'bagging_temperature': 0.8, 'ag_args': {'name_suffix': 'CAT_main'}}, {'iterations': 8000, 'depth': 10, 'learning_rate': 0.02, 'l2_leaf_reg': 4.0, 'border_count': 254, 'random_strength': 0.3, 'bagging_temperature': 0.5, 'ag_args': {'name_suffix': 'CAT_deep'}}],\n","\t'XGB': [{'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'n_estimators': 4000, 'learning_rate': 0.03}],\n","\t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_heavy'}, 'layers': '128-64-64', 'dropout_prob': 0.1}],\n","}\n","AutoGluon will fit 3 stack levels (L1 to L3) ...\n","Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L1 ... Training model for up to 797.62s of the 1795.10s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L1 ... Training model for up to 797.23s of the 1794.70s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L1 ... Training model for up to 796.82s of the 1794.30s of remaining time.\n","Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.10.0,<2.45.0\"`\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0314\t = Validation score   (-root_mean_squared_error)\n","\t426.5s\t = Training   runtime\n","\t0.64s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L1 ... Training model for up to 368.77s of the 1366.25s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0358\t = Validation score   (-root_mean_squared_error)\n","\t324.49s\t = Training   runtime\n","\t0.46s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 42.96s of the 1040.43s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L1 ... Training model for up to 41.39s of the 1038.87s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1037.85s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_main_BAG_L1': 1.0}\n","\t-1.0314\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting 6 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L2 ... Training model for up to 691.71s of the 1037.81s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L2 ... Training model for up to 691.26s of the 1037.36s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L2 ... Training model for up to 690.79s of the 1036.89s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0257\t = Validation score   (-root_mean_squared_error)\n","\t183.68s\t = Training   runtime\n","\t0.55s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L2 ... Training model for up to 505.77s of the 851.87s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0247\t = Validation score   (-root_mean_squared_error)\n","\t290.18s\t = Training   runtime\n","\t0.45s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L2 ... Training model for up to 214.26s of the 560.36s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L2 ... Training model for up to 212.63s of the 558.73s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 557.65s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 1.0}\n","\t-1.0247\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting 6 L3 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L3 ... Training model for up to 557.62s of the 557.59s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L3 ... Training model for up to 557.10s of the 557.06s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L3 ... Training model for up to 556.66s of the 556.62s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0257\t = Validation score   (-root_mean_squared_error)\n","\t129.4s\t = Training   runtime\n","\t0.62s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L3 ... Training model for up to 425.86s of the 425.83s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0258\t = Validation score   (-root_mean_squared_error)\n","\t211.42s\t = Training   runtime\n","\t0.42s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L3 ... Training model for up to 213.15s of the 213.11s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L3 ... Training model for up to 211.62s of the 211.58s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 210.57s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.941, 'CatBoostCAT_deep_BAG_L3': 0.059}\n","\t-1.0247\t = Validation score   (-root_mean_squared_error)\n","\t0.02s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 1589.57s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 2901.9 rows/s (7308 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\")\n","Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n","Leaderboard on holdout data (DyStack):\n","                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0      WeightedEnsemble_L4      -1.020582  -1.024687  root_mean_squared_error        1.347988       2.518853  1436.298435                 0.001827                0.000630           0.018928            4       True          9\n","1  CatBoostCAT_deep_BAG_L2      -1.020604  -1.024688  root_mean_squared_error        0.847170       1.545372  1041.173695                 0.264493                0.447902         290.183823            2       True          5\n","2      WeightedEnsemble_L3      -1.020604  -1.024688  root_mean_squared_error        0.848729       1.545838  1041.182635                 0.001559                0.000465           0.008940            3       True          6\n","3  CatBoostCAT_deep_BAG_L3      -1.020867  -1.025821  root_mean_squared_error        1.346161       2.518223  1436.279507                 0.239977                0.419555         211.420836            3       True          8\n","4  CatBoostCAT_main_BAG_L2      -1.021309  -1.025741  root_mean_squared_error        0.841690       1.650766   934.674849                 0.259014                0.553296         183.684977            2       True          4\n","5  CatBoostCAT_main_BAG_L3      -1.021463  -1.025715  root_mean_squared_error        1.338814       2.723049  1354.260983                 0.232631                0.624382         129.402311            3       True          7\n","6  CatBoostCAT_main_BAG_L1      -1.026909  -1.031446  root_mean_squared_error        0.321155       0.636704   426.495583                 0.321155                0.636704         426.495583            1       True          1\n","7      WeightedEnsemble_L2      -1.026909  -1.031446  root_mean_squared_error        0.323346       0.637138   426.504266                 0.002191                0.000434           0.008683            2       True          3\n","8  CatBoostCAT_deep_BAG_L1      -1.029161  -1.035799  root_mean_squared_error        0.261522       0.460766   324.494289                 0.261522                0.460766         324.494289            1       True          2\n","\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t1592s\t = DyStack   runtime |\t5608s\t = Remaining runtime\n","Starting main fit with num_stack_levels=2.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n","Beginning AutoGluon training ... Time limit = 5608s\n","AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_221138\"\n","Train Data Rows:    41105\n","Train Data Columns: 916\n","Label Column:       target\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    437969.33 MB\n","\tTrain Data (Original)  Memory Usage: 137.40 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 593 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('category', []) :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])    : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])      : 634 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n","\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n","\t\t('int', [])       :  41 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n","\t\t('int', ['bool']) : 593 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n","\t5.3s = Fit runtime\n","\t916 features in original data used to generate 916 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 114.16 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 5.46s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","User-specified model hyperparameters to be fit:\n","{\n","\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_main'}, 'num_leaves': 64, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1}, {'extra_trees': True, 'ag_args': {'name_suffix': 'GBM_xt'}, 'num_leaves': 128, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1}],\n","\t'CAT': [{'iterations': 6000, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 3.0, 'border_count': 254, 'random_strength': 0.5, 'bagging_temperature': 0.8, 'ag_args': {'name_suffix': 'CAT_main'}}, {'iterations': 8000, 'depth': 10, 'learning_rate': 0.02, 'l2_leaf_reg': 4.0, 'border_count': 254, 'random_strength': 0.3, 'bagging_temperature': 0.5, 'ag_args': {'name_suffix': 'CAT_deep'}}],\n","\t'XGB': [{'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'n_estimators': 4000, 'learning_rate': 0.03}],\n","\t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_heavy'}, 'layers': '128-64-64', 'dropout_prob': 0.1}],\n","}\n","AutoGluon will fit 3 stack levels (L1 to L3) ...\n","Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L1 ... Training model for up to 2489.58s of the 5602.95s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L1 ... Training model for up to 2489.11s of the 5602.49s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L1 ... Training model for up to 2488.64s of the 5602.01s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0259\t = Validation score   (-root_mean_squared_error)\n","\t538.83s\t = Training   runtime\n","\t0.55s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L1 ... Training model for up to 1948.19s of the 5061.56s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0222\t = Validation score   (-root_mean_squared_error)\n","\t1653.11s\t = Training   runtime\n","\t0.83s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 292.80s of the 3406.18s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L1 ... Training model for up to 291.20s of the 3404.57s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3403.52s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L1': 1.0}\n","\t-1.0222\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting 6 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L2 ... Training model for up to 2268.43s of the 3403.48s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L2 ... Training model for up to 2267.99s of the 3403.04s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L2 ... Training model for up to 2267.56s of the 3402.61s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0195\t = Validation score   (-root_mean_squared_error)\n","\t175.95s\t = Training   runtime\n","\t0.72s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L2 ... Training model for up to 2090.07s of the 3225.12s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0193\t = Validation score   (-root_mean_squared_error)\n","\t518.58s\t = Training   runtime\n","\t0.75s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L2 ... Training model for up to 1569.84s of the 2704.89s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L2 ... Training model for up to 1568.24s of the 2703.29s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L2 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2702.25s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.9, 'CatBoostCAT_main_BAG_L2': 0.1}\n","\t-1.0193\t = Validation score   (-root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting 6 L3 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_main_BAG_L3 ... Training model for up to 2702.21s of the 2702.19s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_main_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: LightGBMGBM_xt_BAG_L3 ... Training model for up to 2701.79s of the 2701.77s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_xt_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_main_BAG_L3 ... Training model for up to 2701.38s of the 2701.37s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0204\t = Validation score   (-root_mean_squared_error)\n","\t154.95s\t = Training   runtime\n","\t0.68s\t = Validation runtime\n","Fitting model: CatBoostCAT_deep_BAG_L3 ... Training model for up to 2544.97s of the 2544.95s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0205\t = Validation score   (-root_mean_squared_error)\n","\t461.0s\t = Training   runtime\n","\t0.72s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L3 ... Training model for up to 2082.38s of the 2082.36s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused XGBoost_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n","Fitting model: NeuralNetTorchNN_heavy_BAG_L3 ... Training model for up to 2080.79s of the 2080.77s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L3 to fail during training (ImportError)... Skipping this model.\n","\t\tUnable to import dependency torch\n","A quick tip is to install via `pip install torch`.\n","The minimum torch version is currently 2.2.\n","Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 2079.70s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.909, 'CatBoostCAT_deep_BAG_L1': 0.091}\n","\t-1.0193\t = Validation score   (-root_mean_squared_error)\n","\t0.02s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 3528.86s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 3871.3 rows/s (8221 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138\")\n"]}],"execution_count":61},{"id":"3b5d707e-e031-4347-8aa1-69336fe77ff2","cell_type":"code","source":"extra_hps_heavy = {\n    \"CAT\": {\n        \"iterations\": 8000,\n        \"depth\": 8,\n        \"learning_rate\": 0.008,\n        \"l2_leaf_reg\": 3.0,\n        \"ag_args\": {\"name_suffix\": \"CAT_extra\"},\n    },\n    \"GBM\": [\n        {\n            \"extra_trees\": False,\n            \"ag_args\": {\"name_suffix\": \"GBM_extra\"},\n            \"num_leaves\": 128,\n            \"feature_fraction\": 0.85,\n            \"bagging_fraction\": 0.85,\n            \"bagging_freq\": 1,\n        },\n    ],\n}\n\npredictor_heavy = predictor_heavy.fit_extra(\n    hyperparameters=extra_hps_heavy,\n    ag_args_fit={\"num_gpus\": 1},\n    time_limit=1800,\n)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMGBM_extra_BAG_L1 ... Training model for up to 1800.00s of the 1800.00s of remaining time.\n","\tWarning: Exception caused LightGBMGBM_extra_BAG_L1 to fail during training (ImportError)... Skipping this model.\n","\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n","Fitting model: CatBoostCAT_extra_BAG_L1 ... Training model for up to 1799.58s of the 1799.58s of remaining time.\n","\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t-1.0326\t = Validation score   (-root_mean_squared_error)\n","\t867.98s\t = Training   runtime\n","\t0.63s\t = Validation runtime\n","Fitting model: WeightedEnsemble_2_L2 ... Training model for up to 360.00s of the 929.56s of remaining time.\n","\tEnsemble Weights: {'CatBoostCAT_extra_BAG_L1': 1.0}\n","\t-1.0326\t = Validation score   (-root_mean_squared_error)\n","\t0.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138\")\n"]}],"execution_count":62},{"id":"190eb0b3-e770-4803-a3a6-24bb3eb39cb2","cell_type":"code","source":"refit_models = predictor_heavy.refit_full()  # вернёт список имён моделей\nrefit_models\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n","\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n","\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n","\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n","Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_main_BAG_L1_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t47.04s\t = Training   runtime\n","Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_deep_BAG_L1_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t155.07s\t = Training   runtime\n","Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_extra_BAG_L1_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t83.0s\t = Training   runtime\n","Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L1': 1.0}\n","\t0.01s\t = Training   runtime\n","Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_main_BAG_L2_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t4.93s\t = Training   runtime\n","Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_deep_BAG_L2_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t9.55s\t = Training   runtime\n","Fitting model: WeightedEnsemble_2_L2_FULL | Skipping fit via cloning parent ...\n","\tEnsemble Weights: {'CatBoostCAT_extra_BAG_L1': 1.0}\n","\t0.0s\t = Training   runtime\n","Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.9, 'CatBoostCAT_main_BAG_L2': 0.1}\n","\t0.01s\t = Training   runtime\n","Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_main_BAG_L3_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t4.49s\t = Training   runtime\n","Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n","Fitting model: CatBoostCAT_deep_BAG_L3_FULL ...\n","\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\t8.46s\t = Training   runtime\n","Fitting model: WeightedEnsemble_L4_FULL | Skipping fit via cloning parent ...\n","\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.909, 'CatBoostCAT_deep_BAG_L1': 0.091}\n","\t0.02s\t = Training   runtime\n","Updated best model to \"WeightedEnsemble_L4_FULL\" (Previously \"WeightedEnsemble_L4\"). AutoGluon will default to using \"WeightedEnsemble_L4_FULL\" for predict() and predict_proba().\n","Refit complete, total runtime = 315.99s ... Best model: \"WeightedEnsemble_L4_FULL\"\n"]},{"data":{"text/plain":["{'CatBoostCAT_main_BAG_L1': 'CatBoostCAT_main_BAG_L1_FULL',\n"," 'CatBoostCAT_deep_BAG_L1': 'CatBoostCAT_deep_BAG_L1_FULL',\n"," 'CatBoostCAT_extra_BAG_L1': 'CatBoostCAT_extra_BAG_L1_FULL',\n"," 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL',\n"," 'CatBoostCAT_main_BAG_L2': 'CatBoostCAT_main_BAG_L2_FULL',\n"," 'CatBoostCAT_deep_BAG_L2': 'CatBoostCAT_deep_BAG_L2_FULL',\n"," 'WeightedEnsemble_2_L2': 'WeightedEnsemble_2_L2_FULL',\n"," 'WeightedEnsemble_L3': 'WeightedEnsemble_L3_FULL',\n"," 'CatBoostCAT_main_BAG_L3': 'CatBoostCAT_main_BAG_L3_FULL',\n"," 'CatBoostCAT_deep_BAG_L3': 'CatBoostCAT_deep_BAG_L3_FULL',\n"," 'WeightedEnsemble_L4': 'WeightedEnsemble_L4_FULL'}"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"execution_count":63},{"id":"aeef6e40-a33f-4137-aedc-d3bda5b91e0a","cell_type":"code","source":"lb_heavy = predictor_heavy.leaderboard(train_ag, silent=True)\nlb_heavy\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_test</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_test</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_test_marginal</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CatBoostCAT_deep_BAG_L3_FULL</td>\n","      <td>-0.916279</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.599813</td>\n","      <td>NaN</td>\n","      <td>225.043656</td>\n","      <td>0.099124</td>\n","      <td>NaN</td>\n","      <td>8.463934</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CatBoostCAT_main_BAG_L3_FULL</td>\n","      <td>-0.923221</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.584995</td>\n","      <td>NaN</td>\n","      <td>221.072683</td>\n","      <td>0.084306</td>\n","      <td>NaN</td>\n","      <td>4.492962</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CatBoostCAT_deep_BAG_L2_FULL</td>\n","      <td>-0.923662</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.411435</td>\n","      <td>NaN</td>\n","      <td>211.649469</td>\n","      <td>0.100992</td>\n","      <td>NaN</td>\n","      <td>9.546101</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>WeightedEnsemble_L3_FULL</td>\n","      <td>-0.924691</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.501887</td>\n","      <td>NaN</td>\n","      <td>216.589046</td>\n","      <td>0.001198</td>\n","      <td>NaN</td>\n","      <td>0.009325</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>WeightedEnsemble_L4_FULL</td>\n","      <td>-0.925978</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.413476</td>\n","      <td>NaN</td>\n","      <td>211.667761</td>\n","      <td>0.002040</td>\n","      <td>NaN</td>\n","      <td>0.018292</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CatBoostCAT_main_BAG_L2_FULL</td>\n","      <td>-0.935022</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.399697</td>\n","      <td>NaN</td>\n","      <td>207.033620</td>\n","      <td>0.089254</td>\n","      <td>NaN</td>\n","      <td>4.930252</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CatBoostCAT_deep_BAG_L3</td>\n","      <td>-0.943104</td>\n","      <td>-1.020547</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.916770</td>\n","      <td>3.570393</td>\n","      <td>3347.472876</td>\n","      <td>0.467275</td>\n","      <td>0.723779</td>\n","      <td>460.999281</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>CatBoostCAT_main_BAG_L3</td>\n","      <td>-0.944375</td>\n","      <td>-1.020356</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.881808</td>\n","      <td>3.521692</td>\n","      <td>3041.426079</td>\n","      <td>0.432313</td>\n","      <td>0.675078</td>\n","      <td>154.952484</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoostCAT_deep_BAG_L2</td>\n","      <td>-0.946427</td>\n","      <td>-1.019281</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.014383</td>\n","      <td>2.123481</td>\n","      <td>2710.522289</td>\n","      <td>0.443499</td>\n","      <td>0.746373</td>\n","      <td>518.578130</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>-0.946615</td>\n","      <td>-1.019280</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.451519</td>\n","      <td>2.847040</td>\n","      <td>2886.482920</td>\n","      <td>0.002024</td>\n","      <td>0.000426</td>\n","      <td>0.009325</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>WeightedEnsemble_L4</td>\n","      <td>-0.947829</td>\n","      <td>-1.019257</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.016348</td>\n","      <td>2.123899</td>\n","      <td>2710.540581</td>\n","      <td>0.001966</td>\n","      <td>0.000418</td>\n","      <td>0.018292</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CatBoostCAT_main_BAG_L2</td>\n","      <td>-0.948376</td>\n","      <td>-1.019471</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.005996</td>\n","      <td>2.100241</td>\n","      <td>2367.895465</td>\n","      <td>0.435112</td>\n","      <td>0.723133</td>\n","      <td>175.951306</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>CatBoostCAT_deep_BAG_L1_FULL</td>\n","      <td>-0.954988</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.110367</td>\n","      <td>NaN</td>\n","      <td>155.067148</td>\n","      <td>0.110367</td>\n","      <td>NaN</td>\n","      <td>155.067148</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>WeightedEnsemble_L2_FULL</td>\n","      <td>-0.954988</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.112044</td>\n","      <td>NaN</td>\n","      <td>155.076736</td>\n","      <td>0.001678</td>\n","      <td>NaN</td>\n","      <td>0.009588</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>CatBoostCAT_main_BAG_L1_FULL</td>\n","      <td>-0.964836</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.200077</td>\n","      <td>NaN</td>\n","      <td>47.036220</td>\n","      <td>0.200077</td>\n","      <td>NaN</td>\n","      <td>47.036220</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>CatBoostCAT_deep_BAG_L1</td>\n","      <td>-0.965217</td>\n","      <td>-1.022203</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.798954</td>\n","      <td>0.827065</td>\n","      <td>1653.112687</td>\n","      <td>0.798954</td>\n","      <td>0.827065</td>\n","      <td>1653.112687</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-0.965217</td>\n","      <td>-1.022203</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.800689</td>\n","      <td>0.827510</td>\n","      <td>1653.122275</td>\n","      <td>0.001735</td>\n","      <td>0.000446</td>\n","      <td>0.009588</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>CatBoostCAT_main_BAG_L1</td>\n","      <td>-0.973938</td>\n","      <td>-1.025913</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.771930</td>\n","      <td>0.550043</td>\n","      <td>538.831471</td>\n","      <td>0.771930</td>\n","      <td>0.550043</td>\n","      <td>538.831471</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>CatBoostCAT_extra_BAG_L1_FULL</td>\n","      <td>-0.989324</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.130311</td>\n","      <td>NaN</td>\n","      <td>83.004028</td>\n","      <td>0.130311</td>\n","      <td>NaN</td>\n","      <td>83.004028</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>WeightedEnsemble_2_L2_FULL</td>\n","      <td>-0.989324</td>\n","      <td>NaN</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.131992</td>\n","      <td>NaN</td>\n","      <td>83.006668</td>\n","      <td>0.001681</td>\n","      <td>NaN</td>\n","      <td>0.002641</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>CatBoostCAT_extra_BAG_L1</td>\n","      <td>-1.000057</td>\n","      <td>-1.032590</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.115262</td>\n","      <td>0.632822</td>\n","      <td>867.975810</td>\n","      <td>1.115262</td>\n","      <td>0.632822</td>\n","      <td>867.975810</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>WeightedEnsemble_2_L2</td>\n","      <td>-1.000057</td>\n","      <td>-1.032590</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.117133</td>\n","      <td>0.633230</td>\n","      <td>867.978451</td>\n","      <td>0.001871</td>\n","      <td>0.000409</td>\n","      <td>0.002641</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            model  score_test  score_val  \\\n","0    CatBoostCAT_deep_BAG_L3_FULL   -0.916279        NaN   \n","1    CatBoostCAT_main_BAG_L3_FULL   -0.923221        NaN   \n","2    CatBoostCAT_deep_BAG_L2_FULL   -0.923662        NaN   \n","3        WeightedEnsemble_L3_FULL   -0.924691        NaN   \n","4        WeightedEnsemble_L4_FULL   -0.925978        NaN   \n","5    CatBoostCAT_main_BAG_L2_FULL   -0.935022        NaN   \n","6         CatBoostCAT_deep_BAG_L3   -0.943104  -1.020547   \n","7         CatBoostCAT_main_BAG_L3   -0.944375  -1.020356   \n","8         CatBoostCAT_deep_BAG_L2   -0.946427  -1.019281   \n","9             WeightedEnsemble_L3   -0.946615  -1.019280   \n","10            WeightedEnsemble_L4   -0.947829  -1.019257   \n","11        CatBoostCAT_main_BAG_L2   -0.948376  -1.019471   \n","12   CatBoostCAT_deep_BAG_L1_FULL   -0.954988        NaN   \n","13       WeightedEnsemble_L2_FULL   -0.954988        NaN   \n","14   CatBoostCAT_main_BAG_L1_FULL   -0.964836        NaN   \n","15        CatBoostCAT_deep_BAG_L1   -0.965217  -1.022203   \n","16            WeightedEnsemble_L2   -0.965217  -1.022203   \n","17        CatBoostCAT_main_BAG_L1   -0.973938  -1.025913   \n","18  CatBoostCAT_extra_BAG_L1_FULL   -0.989324        NaN   \n","19     WeightedEnsemble_2_L2_FULL   -0.989324        NaN   \n","20       CatBoostCAT_extra_BAG_L1   -1.000057  -1.032590   \n","21          WeightedEnsemble_2_L2   -1.000057  -1.032590   \n","\n","                eval_metric  pred_time_test  pred_time_val     fit_time  \\\n","0   root_mean_squared_error        0.599813            NaN   225.043656   \n","1   root_mean_squared_error        0.584995            NaN   221.072683   \n","2   root_mean_squared_error        0.411435            NaN   211.649469   \n","3   root_mean_squared_error        0.501887            NaN   216.589046   \n","4   root_mean_squared_error        0.413476            NaN   211.667761   \n","5   root_mean_squared_error        0.399697            NaN   207.033620   \n","6   root_mean_squared_error        2.916770       3.570393  3347.472876   \n","7   root_mean_squared_error        2.881808       3.521692  3041.426079   \n","8   root_mean_squared_error        2.014383       2.123481  2710.522289   \n","9   root_mean_squared_error        2.451519       2.847040  2886.482920   \n","10  root_mean_squared_error        2.016348       2.123899  2710.540581   \n","11  root_mean_squared_error        2.005996       2.100241  2367.895465   \n","12  root_mean_squared_error        0.110367            NaN   155.067148   \n","13  root_mean_squared_error        0.112044            NaN   155.076736   \n","14  root_mean_squared_error        0.200077            NaN    47.036220   \n","15  root_mean_squared_error        0.798954       0.827065  1653.112687   \n","16  root_mean_squared_error        0.800689       0.827510  1653.122275   \n","17  root_mean_squared_error        0.771930       0.550043   538.831471   \n","18  root_mean_squared_error        0.130311            NaN    83.004028   \n","19  root_mean_squared_error        0.131992            NaN    83.006668   \n","20  root_mean_squared_error        1.115262       0.632822   867.975810   \n","21  root_mean_squared_error        1.117133       0.633230   867.978451   \n","\n","    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n","0                  0.099124                     NaN           8.463934   \n","1                  0.084306                     NaN           4.492962   \n","2                  0.100992                     NaN           9.546101   \n","3                  0.001198                     NaN           0.009325   \n","4                  0.002040                     NaN           0.018292   \n","5                  0.089254                     NaN           4.930252   \n","6                  0.467275                0.723779         460.999281   \n","7                  0.432313                0.675078         154.952484   \n","8                  0.443499                0.746373         518.578130   \n","9                  0.002024                0.000426           0.009325   \n","10                 0.001966                0.000418           0.018292   \n","11                 0.435112                0.723133         175.951306   \n","12                 0.110367                     NaN         155.067148   \n","13                 0.001678                     NaN           0.009588   \n","14                 0.200077                     NaN          47.036220   \n","15                 0.798954                0.827065        1653.112687   \n","16                 0.001735                0.000446           0.009588   \n","17                 0.771930                0.550043         538.831471   \n","18                 0.130311                     NaN          83.004028   \n","19                 0.001681                     NaN           0.002641   \n","20                 1.115262                0.632822         867.975810   \n","21                 0.001871                0.000409           0.002641   \n","\n","    stack_level  can_infer  fit_order  \n","0             3       True         21  \n","1             3       True         20  \n","2             2       True         17  \n","3             3       True         19  \n","4             4       True         22  \n","5             2       True         16  \n","6             3       True          8  \n","7             3       True          7  \n","8             2       True          5  \n","9             3       True          6  \n","10            4       True          9  \n","11            2       True          4  \n","12            1       True         13  \n","13            2       True         15  \n","14            1       True         12  \n","15            1       True          2  \n","16            2       True          3  \n","17            1       True          1  \n","18            1       True         14  \n","19            2       True         18  \n","20            1       True         10  \n","21            2       True         11  "]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"execution_count":64},{"id":"627f0944-bc16-4f5e-a97e-fe176e7c869c","cell_type":"code","source":"fi_heavy = predictor_heavy.feature_importance(train_ag)\nfi_heavy.head(30)\n","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Computing feature importance via permutation shuffling for 916 features using 5000 rows with 5 shuffle sets...\n","\t1222.19s\t= Expected runtime (244.44s per shuffle set)\n","\t160.98s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","      <th>stddev</th>\n","      <th>p_value</th>\n","      <th>n</th>\n","      <th>p99_high</th>\n","      <th>p99_low</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>category</th>\n","      <td>0.256087</td>\n","      <td>0.006250</td>\n","      <td>4.254124e-08</td>\n","      <td>5</td>\n","      <td>0.268956</td>\n","      <td>0.243218</td>\n","    </tr>\n","    <tr>\n","      <th>name</th>\n","      <td>0.143222</td>\n","      <td>0.009931</td>\n","      <td>2.756245e-06</td>\n","      <td>5</td>\n","      <td>0.163670</td>\n","      <td>0.122774</td>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <td>0.026039</td>\n","      <td>0.003964</td>\n","      <td>6.249724e-05</td>\n","      <td>5</td>\n","      <td>0.034201</td>\n","      <td>0.017877</td>\n","    </tr>\n","    <tr>\n","      <th>coordinates</th>\n","      <td>0.009665</td>\n","      <td>0.001618</td>\n","      <td>9.073447e-05</td>\n","      <td>5</td>\n","      <td>0.012996</td>\n","      <td>0.006335</td>\n","    </tr>\n","    <tr>\n","      <th>address</th>\n","      <td>0.007237</td>\n","      <td>0.001181</td>\n","      <td>8.226482e-05</td>\n","      <td>5</td>\n","      <td>0.009669</td>\n","      <td>0.004805</td>\n","    </tr>\n","    <tr>\n","      <th>mean_income_1000m</th>\n","      <td>0.004080</td>\n","      <td>0.000457</td>\n","      <td>1.859026e-05</td>\n","      <td>5</td>\n","      <td>0.005022</td>\n","      <td>0.003139</td>\n","    </tr>\n","    <tr>\n","      <th>mean_income_300m</th>\n","      <td>0.004065</td>\n","      <td>0.000653</td>\n","      <td>7.712692e-05</td>\n","      <td>5</td>\n","      <td>0.005409</td>\n","      <td>0.002721</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__.москва</th>\n","      <td>0.003000</td>\n","      <td>0.000750</td>\n","      <td>4.327484e-04</td>\n","      <td>5</td>\n","      <td>0.004545</td>\n","      <td>0.001455</td>\n","    </tr>\n","    <tr>\n","      <th>address.symbol_count..</th>\n","      <td>0.002978</td>\n","      <td>0.000774</td>\n","      <td>5.027841e-04</td>\n","      <td>5</td>\n","      <td>0.004572</td>\n","      <td>0.001383</td>\n","    </tr>\n","    <tr>\n","      <th>homes_300m</th>\n","      <td>0.002896</td>\n","      <td>0.000545</td>\n","      <td>1.432752e-04</td>\n","      <td>5</td>\n","      <td>0.004017</td>\n","      <td>0.001775</td>\n","    </tr>\n","    <tr>\n","      <th>address.digit_ratio</th>\n","      <td>0.002861</td>\n","      <td>0.000074</td>\n","      <td>5.269784e-08</td>\n","      <td>5</td>\n","      <td>0.003012</td>\n","      <td>0.002709</td>\n","    </tr>\n","    <tr>\n","      <th>children_goods_for_walks_and_travel_300m</th>\n","      <td>0.002739</td>\n","      <td>0.000588</td>\n","      <td>2.400257e-04</td>\n","      <td>5</td>\n","      <td>0.003950</td>\n","      <td>0.001528</td>\n","    </tr>\n","    <tr>\n","      <th>address.symbol_ratio.</th>\n","      <td>0.002380</td>\n","      <td>0.000130</td>\n","      <td>1.058161e-06</td>\n","      <td>5</td>\n","      <td>0.002648</td>\n","      <td>0.002113</td>\n","    </tr>\n","    <tr>\n","      <th>garden_supplies_300m</th>\n","      <td>0.002287</td>\n","      <td>0.000516</td>\n","      <td>2.900566e-04</td>\n","      <td>5</td>\n","      <td>0.003349</td>\n","      <td>0.001226</td>\n","    </tr>\n","    <tr>\n","      <th>pregnancy_websites_300m</th>\n","      <td>0.002091</td>\n","      <td>0.000402</td>\n","      <td>1.558369e-04</td>\n","      <td>5</td>\n","      <td>0.002919</td>\n","      <td>0.001264</td>\n","    </tr>\n","    <tr>\n","      <th>childrens_sports_300m</th>\n","      <td>0.001936</td>\n","      <td>0.000483</td>\n","      <td>4.294483e-04</td>\n","      <td>5</td>\n","      <td>0.002931</td>\n","      <td>0.000941</td>\n","    </tr>\n","    <tr>\n","      <th>manicure_300m</th>\n","      <td>0.001917</td>\n","      <td>0.000472</td>\n","      <td>4.090548e-04</td>\n","      <td>5</td>\n","      <td>0.002890</td>\n","      <td>0.000944</td>\n","    </tr>\n","    <tr>\n","      <th>age_&gt;55_300m</th>\n","      <td>0.001594</td>\n","      <td>0.000251</td>\n","      <td>7.102597e-05</td>\n","      <td>5</td>\n","      <td>0.002110</td>\n","      <td>0.001078</td>\n","    </tr>\n","    <tr>\n","      <th>childrens_websites_1000m</th>\n","      <td>0.001506</td>\n","      <td>0.000129</td>\n","      <td>6.376947e-06</td>\n","      <td>5</td>\n","      <td>0.001771</td>\n","      <td>0.001240</td>\n","    </tr>\n","    <tr>\n","      <th>address.word_count</th>\n","      <td>0.001493</td>\n","      <td>0.000516</td>\n","      <td>1.464618e-03</td>\n","      <td>5</td>\n","      <td>0.002555</td>\n","      <td>0.000432</td>\n","    </tr>\n","    <tr>\n","      <th>__nlp__._total_</th>\n","      <td>0.001414</td>\n","      <td>0.000144</td>\n","      <td>1.256272e-05</td>\n","      <td>5</td>\n","      <td>0.001709</td>\n","      <td>0.001118</td>\n","    </tr>\n","    <tr>\n","      <th>homes_1000m</th>\n","      <td>0.001383</td>\n","      <td>0.000118</td>\n","      <td>6.389504e-06</td>\n","      <td>5</td>\n","      <td>0.001627</td>\n","      <td>0.001139</td>\n","    </tr>\n","    <tr>\n","      <th>address.special_ratio</th>\n","      <td>0.001382</td>\n","      <td>0.000213</td>\n","      <td>6.616075e-05</td>\n","      <td>5</td>\n","      <td>0.001821</td>\n","      <td>0.000943</td>\n","    </tr>\n","    <tr>\n","      <th>childrens_sports_1000m</th>\n","      <td>0.001370</td>\n","      <td>0.000185</td>\n","      <td>3.895437e-05</td>\n","      <td>5</td>\n","      <td>0.001751</td>\n","      <td>0.000989</td>\n","    </tr>\n","    <tr>\n","      <th>mortgage_300m</th>\n","      <td>0.001317</td>\n","      <td>0.000348</td>\n","      <td>5.363154e-04</td>\n","      <td>5</td>\n","      <td>0.002034</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <th>laser_hair_removal_300m</th>\n","      <td>0.001315</td>\n","      <td>0.000403</td>\n","      <td>9.345924e-04</td>\n","      <td>5</td>\n","      <td>0.002144</td>\n","      <td>0.000486</td>\n","    </tr>\n","    <tr>\n","      <th>works_300m</th>\n","      <td>0.001301</td>\n","      <td>0.000192</td>\n","      <td>5.504926e-05</td>\n","      <td>5</td>\n","      <td>0.001695</td>\n","      <td>0.000906</td>\n","    </tr>\n","    <tr>\n","      <th>computer_games_300m</th>\n","      <td>0.001238</td>\n","      <td>0.000218</td>\n","      <td>1.100289e-04</td>\n","      <td>5</td>\n","      <td>0.001686</td>\n","      <td>0.000790</td>\n","    </tr>\n","    <tr>\n","      <th>anime_1000m</th>\n","      <td>0.001236</td>\n","      <td>0.000222</td>\n","      <td>1.187991e-04</td>\n","      <td>5</td>\n","      <td>0.001693</td>\n","      <td>0.000780</td>\n","    </tr>\n","    <tr>\n","      <th>childrens_transport_300m</th>\n","      <td>0.001222</td>\n","      <td>0.000302</td>\n","      <td>4.111978e-04</td>\n","      <td>5</td>\n","      <td>0.001843</td>\n","      <td>0.000601</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          importance    stddev       p_value  \\\n","category                                    0.256087  0.006250  4.254124e-08   \n","name                                        0.143222  0.009931  2.756245e-06   \n","id                                          0.026039  0.003964  6.249724e-05   \n","coordinates                                 0.009665  0.001618  9.073447e-05   \n","address                                     0.007237  0.001181  8.226482e-05   \n","mean_income_1000m                           0.004080  0.000457  1.859026e-05   \n","mean_income_300m                            0.004065  0.000653  7.712692e-05   \n","__nlp__.москва                              0.003000  0.000750  4.327484e-04   \n","address.symbol_count..                      0.002978  0.000774  5.027841e-04   \n","homes_300m                                  0.002896  0.000545  1.432752e-04   \n","address.digit_ratio                         0.002861  0.000074  5.269784e-08   \n","children_goods_for_walks_and_travel_300m    0.002739  0.000588  2.400257e-04   \n","address.symbol_ratio.                       0.002380  0.000130  1.058161e-06   \n","garden_supplies_300m                        0.002287  0.000516  2.900566e-04   \n","pregnancy_websites_300m                     0.002091  0.000402  1.558369e-04   \n","childrens_sports_300m                       0.001936  0.000483  4.294483e-04   \n","manicure_300m                               0.001917  0.000472  4.090548e-04   \n","age_>55_300m                                0.001594  0.000251  7.102597e-05   \n","childrens_websites_1000m                    0.001506  0.000129  6.376947e-06   \n","address.word_count                          0.001493  0.000516  1.464618e-03   \n","__nlp__._total_                             0.001414  0.000144  1.256272e-05   \n","homes_1000m                                 0.001383  0.000118  6.389504e-06   \n","address.special_ratio                       0.001382  0.000213  6.616075e-05   \n","childrens_sports_1000m                      0.001370  0.000185  3.895437e-05   \n","mortgage_300m                               0.001317  0.000348  5.363154e-04   \n","laser_hair_removal_300m                     0.001315  0.000403  9.345924e-04   \n","works_300m                                  0.001301  0.000192  5.504926e-05   \n","computer_games_300m                         0.001238  0.000218  1.100289e-04   \n","anime_1000m                                 0.001236  0.000222  1.187991e-04   \n","childrens_transport_300m                    0.001222  0.000302  4.111978e-04   \n","\n","                                          n  p99_high   p99_low  \n","category                                  5  0.268956  0.243218  \n","name                                      5  0.163670  0.122774  \n","id                                        5  0.034201  0.017877  \n","coordinates                               5  0.012996  0.006335  \n","address                                   5  0.009669  0.004805  \n","mean_income_1000m                         5  0.005022  0.003139  \n","mean_income_300m                          5  0.005409  0.002721  \n","__nlp__.москва                            5  0.004545  0.001455  \n","address.symbol_count..                    5  0.004572  0.001383  \n","homes_300m                                5  0.004017  0.001775  \n","address.digit_ratio                       5  0.003012  0.002709  \n","children_goods_for_walks_and_travel_300m  5  0.003950  0.001528  \n","address.symbol_ratio.                     5  0.002648  0.002113  \n","garden_supplies_300m                      5  0.003349  0.001226  \n","pregnancy_websites_300m                   5  0.002919  0.001264  \n","childrens_sports_300m                     5  0.002931  0.000941  \n","manicure_300m                             5  0.002890  0.000944  \n","age_>55_300m                              5  0.002110  0.001078  \n","childrens_websites_1000m                  5  0.001771  0.001240  \n","address.word_count                        5  0.002555  0.000432  \n","__nlp__._total_                           5  0.001709  0.001118  \n","homes_1000m                               5  0.001627  0.001139  \n","address.special_ratio                     5  0.001821  0.000943  \n","childrens_sports_1000m                    5  0.001751  0.000989  \n","mortgage_300m                             5  0.002034  0.000600  \n","laser_hair_removal_300m                   5  0.002144  0.000486  \n","works_300m                                5  0.001695  0.000906  \n","computer_games_300m                       5  0.001686  0.000790  \n","anime_1000m                               5  0.001693  0.000780  \n","childrens_transport_300m                  5  0.001843  0.000601  "]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"execution_count":65},{"id":"8f32734a-c150-48bb-b2b7-ceb0a02bf92c","cell_type":"code","source":"test_pred_heavy = predictor_heavy.predict(test_ag)\ntest_pred_heavy.head()\n","metadata":{},"outputs":[{"data":{"text/plain":["0    3.433025\n","1    3.425081\n","2    4.002472\n","3    3.274601\n","4    2.883332\n","Name: target, dtype: float32"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"execution_count":66},{"id":"24b22877-b11f-4c2e-b458-407fbae3a6b1","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"d319e347-1b29-48e0-8963-4169e79695fd","cell_type":"code","source":"# Предсказания medium (если predictor ещё есть)\ntry:\n    test_pred_medium = predictor.predict(test_ag)\nexcept NameError:\n    test_pred_medium = None\n\nif ID_COL is not None and ID_COL in test.columns:\n    sub_heavy = test[[ID_COL]].copy()\n    sub_blend = test[[ID_COL]].copy()\nelse:\n    sub_heavy = pd.DataFrame()\n    sub_blend = pd.DataFrame()\n\nsub_heavy[TARGET_COL] = test_pred_heavy\n\nif test_pred_medium is not None:\n    test_pred_blend = 0.5 * test_pred_heavy.values + 0.5 * test_pred_medium.values\n    sub_blend[TARGET_COL] = test_pred_blend\nelse:\n    sub_blend[TARGET_COL] = test_pred_heavy.values\n\nsub_heavy.to_csv(\"submission_ag_heavy.csv\", index=False)\nsub_blend.to_csv(\"submission_ag_heavy_blend.csv\", index=False)\n\nsub_heavy.head()\n","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21472</td>\n","      <td>3.433025</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9837</td>\n","      <td>3.425081</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41791</td>\n","      <td>4.002472</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18441</td>\n","      <td>3.274601</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>49348</td>\n","      <td>2.883332</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    target\n","0  21472  3.433025\n","1   9837  3.425081\n","2  41791  4.002472\n","3  18441  3.274601\n","4  49348  2.883332"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"execution_count":67},{"id":"f3fc05a3-f9cd-4890-a598-c716421bcf80","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}