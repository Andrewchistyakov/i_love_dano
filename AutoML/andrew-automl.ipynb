{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959b3ff7",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f89ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Transported\"\n",
    "TRAIN_PATH = \"titanic/train.csv\"\n",
    "TEST_PATH = \"titanic/test.csv\"\n",
    "SUBMIT_NAME = \"submission.csv\"\n",
    "ID_COL = \"Id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce965f3a",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423ed912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: autogluon.tabular==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[tabpfn]==1.4.0) (1.4.0)\n",
      "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.16.3)\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2.3.3)\n",
      "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.6.1)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.5)\n",
      "Requirement already satisfied: autogluon.core==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.4.0)\n",
      "Requirement already satisfied: autogluon.features==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.4.0)\n",
      "Requirement already satisfied: tabpfn<2.2,>=2.0.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[tabpfn]==1.4.0) (2.1.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2.32.5)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.10.7)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.40.74)\n",
      "Requirement already satisfied: autogluon.common==1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.4.0)\n",
      "Requirement already satisfied: pyarrow<21.0.0,>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (20.0.0)\n",
      "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (7.0.0)\n",
      "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.6.0)\n",
      "Requirement already satisfied: torch<3,>=2.1 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2.9.1)\n",
      "Requirement already satisfied: typing_extensions>=4.12.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (4.15.0)\n",
      "Requirement already satisfied: einops<0.9,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.17.3)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2.12.4)\n",
      "Requirement already satisfied: pydantic-settings>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2.12.0)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.3.0)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.74 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.40.74)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1,>=0.0.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (3.20.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1,>=0.0.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2025.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1,>=0.0.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1,>=0.0.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.10.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=2.0.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (3.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular==1.4.0->autogluon.tabular[tabpfn]==1.4.0) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.1->tabpfn<2.2,>=2.0.9->autogluon.tabular[tabpfn]==1.4.0) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Install all dependencies for AutoGluon 'extreme' preset\n",
    "# ----------------------------\n",
    "\n",
    "# Core AutoGluon\n",
    "%pip install autogluon.tabular --quiet\n",
    "\n",
    "%pip install autogluon.tabular[tabpfn]==1.4.0\n",
    "\n",
    "# Optional: specific installs if needed (sometimes helps)\n",
    "%pip install catboost lightgbm xgboost fastai torch --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f4b3c",
   "metadata": {},
   "source": [
    "## fitting (presets='extreme', 'best', 'high', 'good') \n",
    "### !!! only 'extreme' works for me but they say it works 4x faster than any other and is SOTA\n",
    "### try others maybe it is only my problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_182727\"\n",
      "Preset alias specified: 'extreme' maps to 'extreme_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #49~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Nov  6 17:42:15 UTC 2\n",
      "CPU Count:          31\n",
      "Memory Avail:       98.65 GB / 503.46 GB (19.6%)\n",
      "Disk Space Avail:   2.47 GB / 16.00 GB (15.4%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Presets specified: ['extreme']\n",
      "`extreme` preset uses a dynamic portfolio based on dataset size...\n",
      "\tDetected data size: small (<=30000 samples), using `zeroshot_2025_tabfm` portfolio.\n",
      "\t\tNote: `zeroshot_2025_tabfm` portfolio requires a CUDA compatible GPU for best performance.\n",
      "\t\tMake sure you have all the relevant dependencies installed: `pip install autogluon.tabular[tabarena]`.\n",
      "\t\tIt is strongly recommended to use a machine with 64+ GB memory and a CUDA compatible GPU with 32+ GB vRAM when using this preset. \n",
      "\t\tThis portfolio will download foundation model weights from HuggingFace during training. Ensure you have an internet connection or have pre-downloaded the weights to use these models.\n",
      "\t\tThis portfolio was meta-learned with TabArena: https://tabarena.ai\n",
      "Using hyperparameters preset: hyperparameters='zeroshot_2025_tabfm'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=3, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"/workspace/andrew/AutogluonModels/ag-20251116_182727\"\n",
      "Train Data Rows:    8693\n",
      "Train Data Columns: 13\n",
      "Label Column:       Transported\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [False, True]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    101025.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['PassengerId']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['PassengerId']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
      "\t\t('object', []) : 6 | ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 6 | ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', ...]\n",
      "\t\t('float', [])    : 6 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (21 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'TABPFNV2': [{'ag_args': {'name_suffix': '_r143', 'priority': -1}, 'average_before_softmax': False, 'classification_model_path': 'tabpfn-v2-classifier-od3j1g5m.ckpt', 'inference_config/FINGERPRINT_FEATURE': False, 'inference_config/OUTLIER_REMOVAL_STD': None, 'inference_config/POLYNOMIAL_FEATURES': 'no', 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'safepower', 'subsample_features': -1}, {'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'quantile_uni', 'subsample_features': -1}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': [None, 'power'], 'inference_config/SUBSAMPLE_SAMPLES': 0.99, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor-wyl4o83o.ckpt', 'softmax_temperature': 0.75}, {'ag_args': {'name_suffix': '_r94', 'priority': -3}, 'average_before_softmax': True, 'classification_model_path': 'tabpfn-v2-classifier-vutqq28w.ckpt', 'inference_config/FINGERPRINT_FEATURE': True, 'inference_config/OUTLIER_REMOVAL_STD': None, 'inference_config/POLYNOMIAL_FEATURES': 'no', 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'ordinal_very_common_categories_shuffled', 'global_transformer_name': None, 'name': 'quantile_uni', 'subsample_features': 0.99}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': [None], 'inference_config/SUBSAMPLE_SAMPLES': None, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor-5wof9ojf.ckpt', 'softmax_temperature': 0.9}, {'ag_args': {'name_suffix': '_r181', 'priority': -4}, 'average_before_softmax': False, 'classification_model_path': 'tabpfn-v2-classifier-llderlii.ckpt', 'inference_config/FINGERPRINT_FEATURE': False, 'inference_config/OUTLIER_REMOVAL_STD': 9.0, 'inference_config/POLYNOMIAL_FEATURES': 50, 'inference_config/PREPROCESS_TRANSFORMS': [{'append_original': True, 'categorical_name': 'onehot', 'global_transformer_name': 'svd', 'name': 'quantile_uni_coarse', 'subsample_features': 0.99}], 'inference_config/REGRESSION_Y_PREPROCESS_TRANSFORMS': ['power'], 'inference_config/SUBSAMPLE_SAMPLES': None, 'model_type': 'single', 'n_ensemble_repeats': 4, 'regression_model_path': 'tabpfn-v2-regressor.ckpt', 'softmax_temperature': 0.95}],\n",
      "\t'GBM': [{'ag_args': {'name_suffix': '_r33', 'priority': -2}, 'bagging_fraction': 0.9625293420216, 'bagging_freq': 1, 'cat_l2': 0.1236875455555, 'cat_smooth': 68.8584757332856, 'extra_trees': False, 'feature_fraction': 0.6189215809382, 'lambda_l1': 0.1641757352921, 'lambda_l2': 0.6937755557881, 'learning_rate': 0.0154031028561, 'max_cat_to_onehot': 17, 'min_data_in_leaf': 1, 'min_data_per_group': 30, 'num_leaves': 68}, {'ag_args': {'name_suffix': '_r21', 'priority': -16}, 'bagging_fraction': 0.7218730663234, 'bagging_freq': 1, 'cat_l2': 0.0296205152578, 'cat_smooth': 0.0010255271303, 'extra_trees': False, 'feature_fraction': 0.4557131604374, 'lambda_l1': 0.5219704038237, 'lambda_l2': 0.1070959487853, 'learning_rate': 0.0055891584996, 'max_cat_to_onehot': 71, 'min_data_in_leaf': 50, 'min_data_per_group': 10, 'num_leaves': 30}, {'ag_args': {'name_suffix': '_r11', 'priority': -19}, 'bagging_fraction': 0.775784726514, 'bagging_freq': 1, 'cat_l2': 0.3888471449178, 'cat_smooth': 0.0057144748021, 'extra_trees': True, 'feature_fraction': 0.7732354787904, 'lambda_l1': 0.2211002452568, 'lambda_l2': 1.1318405980187, 'learning_rate': 0.0090151778542, 'max_cat_to_onehot': 15, 'min_data_in_leaf': 4, 'min_data_per_group': 15, 'num_leaves': 2}],\n",
      "\t'CAT': [{'ag_args': {'priority': -5}}, {'ag_args': {'name_suffix': '_r51', 'priority': -10}, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'colsample_bylevel': 0.8771035272558, 'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.0107286863021, 'leaf_estimation_iterations': 2, 'learning_rate': 0.0058424016622, 'max_bin': 254, 'max_ctr_complexity': 4, 'model_size_reg': 0.1307400355809, 'one_hot_max_size': 23, 'subsample': 0.809527841437}, {'ag_args': {'name_suffix': '_r10', 'priority': -12}, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'colsample_bylevel': 0.8994502668431, 'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.8187025215896, 'leaf_estimation_iterations': 7, 'learning_rate': 0.005177304142, 'max_bin': 254, 'max_ctr_complexity': 4, 'model_size_reg': 0.5247386875068, 'one_hot_max_size': 53, 'subsample': 0.8705228845742}],\n",
      "\t'TABM': [{'ag_args': {'name_suffix': '_r184', 'priority': -6}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 864, 'd_embedding': 24, 'dropout': 0.0, 'gradient_clipping_norm': 1.0, 'lr': 0.0019256819924656217, 'n_blocks': 3, 'num_emb_n_bins': 3, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.0}, {'ag_args': {'name_suffix': '_r69', 'priority': -7}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 848, 'd_embedding': 28, 'dropout': 0.40215621636031007, 'gradient_clipping_norm': 1.0, 'lr': 0.0010413640454559532, 'n_blocks': 3, 'num_emb_n_bins': 18, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.0}, {'ag_args': {'name_suffix': '_r52', 'priority': -11}, 'amp': False, 'arch_type': 'tabm-mini', 'batch_size': 'auto', 'd_block': 1024, 'd_embedding': 32, 'dropout': 0.0, 'gradient_clipping_norm': 1.0, 'lr': 0.0006297851297842611, 'n_blocks': 4, 'num_emb_n_bins': 22, 'num_emb_type': 'pwl', 'patience': 16, 'share_training_batches': False, 'tabm_k': 32, 'weight_decay': 0.06900108498839816}],\n",
      "\t'TABICL': [{'ag_args': {'priority': -8}}],\n",
      "\t'XGB': [{'ag_args': {'name_suffix': '_r171', 'priority': -9}, 'colsample_bylevel': 0.9213705632288, 'colsample_bynode': 0.6443385965381, 'enable_categorical': True, 'grow_policy': 'lossguide', 'learning_rate': 0.0068171645251, 'max_cat_to_onehot': 8, 'max_depth': 6, 'max_leaves': 10, 'min_child_weight': 0.0507304250576, 'reg_alpha': 4.2446346389037, 'reg_lambda': 1.4800570021253, 'subsample': 0.9656290596647}, {'ag_args': {'name_suffix': '_r40', 'priority': -18}, 'colsample_bylevel': 0.6377491713202, 'colsample_bynode': 0.9237625621103, 'enable_categorical': True, 'grow_policy': 'lossguide', 'learning_rate': 0.0112462621131, 'max_cat_to_onehot': 33, 'max_depth': 10, 'max_leaves': 35, 'min_child_weight': 0.1403464856034, 'reg_alpha': 3.4960653958503, 'reg_lambda': 1.3062320805235, 'subsample': 0.6948898835178}],\n",
      "\t'MITRA': [{'n_estimators': 1, 'fine_tune': True, 'fine_tune_steps': 50, 'ag.num_gpus': 1, 'ag_args': {'priority': -21}}],\n",
      "}\n",
      "Warning: MitraModel hyperparameter \"ag.num_gpus\" is present in both `ag_args_fit` and `hyperparameters`. Will use `hyperparameters` value.\n",
      "Fitting 21 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: TabPFNv2_r143_BAG_L1 ... Training model for up to 3599.81s of the 3599.80s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=31, gpus=1)\n",
      "\tBuilt with PriorLabs-TabPFN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import os\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "predictor = TabularPredictor(label='Transported').fit(\n",
    "    train_data=train_df,\n",
    "    presets='extreme', \n",
    "    ag_args_fit={'num_gpus': 1},\n",
    "    num_bag_folds=3\n",
    "    )\n",
    "predictions = predictor.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab45eb0",
   "metadata": {},
   "source": [
    "## review and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296804ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Leaderboard =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>53.063031</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>53.063031</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>53.095845</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>5.694801</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>5.694801</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.778161</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>0.693195</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>0.693195</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.777011</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.054792</td>\n",
       "      <td>0.660572</td>\n",
       "      <td>0.054792</td>\n",
       "      <td>0.660572</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.773563</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.053060</td>\n",
       "      <td>0.661132</td>\n",
       "      <td>0.053060</td>\n",
       "      <td>0.661132</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.071172</td>\n",
       "      <td>62.665939</td>\n",
       "      <td>0.071172</td>\n",
       "      <td>62.665939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val   fit_time  \\\n",
       "0       NeuralNetTorch   0.810345    accuracy       0.017097  53.063031   \n",
       "1  WeightedEnsemble_L2   0.810345    accuracy       0.017715  53.095845   \n",
       "2             CatBoost   0.800000    accuracy       0.007343   5.694801   \n",
       "3     RandomForestGini   0.778161    accuracy       0.052479   0.693195   \n",
       "4       ExtraTreesEntr   0.777011    accuracy       0.054792   0.660572   \n",
       "5     RandomForestEntr   0.773563    accuracy       0.053060   0.661132   \n",
       "6       ExtraTreesGini   0.772414    accuracy       0.071172  62.665939   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.017097          53.063031            1       True   \n",
       "1                0.000618           0.032814            2       True   \n",
       "2                0.007343           5.694801            1       True   \n",
       "3                0.052479           0.693195            1       True   \n",
       "4                0.054792           0.660572            1       True   \n",
       "5                0.053060           0.661132            1       True   \n",
       "6                0.071172          62.665939            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          7  \n",
       "2          3  \n",
       "3          1  \n",
       "4          5  \n",
       "5          2  \n",
       "6          4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training Summary =====\n",
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch   0.810345    accuracy       0.017097  53.063031                0.017097          53.063031            1       True          6\n",
      "1  WeightedEnsemble_L2   0.810345    accuracy       0.017715  53.095845                0.000618           0.032814            2       True          7\n",
      "2             CatBoost   0.800000    accuracy       0.007343   5.694801                0.007343           5.694801            1       True          3\n",
      "3     RandomForestGini   0.778161    accuracy       0.052479   0.693195                0.052479           0.693195            1       True          1\n",
      "4       ExtraTreesEntr   0.777011    accuracy       0.054792   0.660572                0.054792           0.660572            1       True          5\n",
      "5     RandomForestEntr   0.773563    accuracy       0.053060   0.661132                0.053060           0.661132            1       True          2\n",
      "6       ExtraTreesGini   0.772414    accuracy       0.071172  62.665939                0.071172          62.665939            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'RFModel', 'CatBoostModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 6 | ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', ...]\n",
      "('float', [])    : 6 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
      "*** End of fit() summary ***\n",
      "\n",
      "===== Making Predictions for Submission =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved to submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n===== Leaderboard =====\")\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "display(lb)\n",
    "\n",
    "print(\"\\n===== Training Summary =====\")\n",
    "predictor.fit_summary(show_plot=True)\n",
    "\n",
    "print(\"\\n===== Making Predictions for Submission =====\")\n",
    "test_pred = predictor.predict(test_df)\n",
    "\n",
    "# If prediction is a dataframe (multi-class probs), turn into single column prediction\n",
    "if isinstance(test_pred, pd.DataFrame):\n",
    "    # take class with max probability\n",
    "    test_pred = test_pred.idxmax(axis=1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],  # change to test id column if exists\n",
    "    'Transported': test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to submission.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23d6f7",
   "metadata": {},
   "source": [
    "## then catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b928f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "made features\n",
      "starting training\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# ============================\n",
    "# 1. Load your dataset\n",
    "# ============================\n",
    "\n",
    "\n",
    "# Change these paths\n",
    "train_path = TRAIN_PATH\n",
    "test_path = TEST_PATH\n",
    "\n",
    "# Read CSVs\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print('data loaded')\n",
    "\n",
    "# ============================\n",
    "# 2. Define target and features\n",
    "# ============================\n",
    "\n",
    "# Change these column names\n",
    "target_col = TARGET\n",
    "id_col = ID_COL  # or whatever your ID column is\n",
    "feature_cols = [c for c in train_df.columns if c not in [target_col, id_col]]\n",
    "\n",
    "# If you have categorical columns, list them here\n",
    "categorical_cols = [c for c in feature_cols if train_df[c].dtype == 'object' or train_df[c].dtype.name == 'category']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_df[col] = train_df[col].astype(str).fillna('nan')\n",
    "    test_df[col] = test_df[col].astype(str).fillna('nan')\n",
    "\n",
    "print('made features')\n",
    "\n",
    "# ============================\n",
    "# 3. Split train/validation\n",
    "# ============================\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train_df[feature_cols], train_df[target_col], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 4. Initialize CatBoost model\n",
    "# ============================\n",
    "\n",
    "# Use CatBoostRegressor for regression or CatBoostClassifier for classification\n",
    "model_type = \"classification\"  # change to \"classification\" if needed\n",
    "\n",
    "if model_type == \"regression\":\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        task_type=\"GPU\",  # use CPU if no GPU\n",
    "        verbose=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "else:\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        eval_metric='Accuracy',\n",
    "        random_seed=42,\n",
    "        task_type=\"GPU\",\n",
    "        verbose=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "# ============================\n",
    "# 5. Train the model\n",
    "# ============================\n",
    "print('starting training')\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_cols)\n",
    "valid_pool = Pool(X_valid, y_valid, cat_features=categorical_cols)\n",
    "\n",
    "model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50)\n",
    "\n",
    "# ============================\n",
    "# 6. Evaluate on validation\n",
    "# ============================\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "if model_type == \"regression\":\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "else:\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 7. Predict on test set\n",
    "# ============================\n",
    "\n",
    "test_pred = model.predict(test_df[feature_cols])\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    id_col: test_df[id_col],\n",
    "    target_col: test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(SUBMIT_NAME, index=False)\n",
    "print(f\"Submission saved to {SUBMIT_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d862b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
