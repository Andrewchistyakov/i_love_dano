{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_EMB_BASE = True\n",
    "DO_T1_TAB   = True\n",
    "DO_T2_FUS   = True\n",
    "DO_SEG_OOF  = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# [STEP 0] ИМПОРТЫ И ПУТИ\n",
    "import os, io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Корень проекта (там должны лежать parquet, sample_submission_f.csv и папки с картинками)\n",
    "PROJ = Path(\".\").resolve()\n",
    "\n",
    "TRAIN_PARQUET = PROJ / \"train_dataset.parquet\"\n",
    "TEST_PARQUET  = PROJ / \"test_dataset.parquet\"\n",
    "SAMPLE_CSV    = PROJ / \"sample_submission_f.csv\"\n",
    "\n",
    "TRAIN_IMG_DIR = PROJ / \"train_images\"\n",
    "TEST_IMG_DIR  = PROJ / \"test_images\"\n",
    "\n",
    "CHUNK_DIR_TRAIN = PROJ / \"emb_chunks_train\"\n",
    "CHUNK_DIR_TEST  = PROJ / \"emb_chunks_test\"\n",
    "CHUNK_DIR_TRAIN.mkdir(exist_ok=True)\n",
    "CHUNK_DIR_TEST.mkdir(exist_ok=True)\n",
    "\n",
    "CKPT_LIST_TRAIN = PROJ / \"_processed_train.txt\"\n",
    "CKPT_LIST_TEST  = PROJ / \"_processed_test.txt\"\n",
    "\n",
    "# Проверяем\n",
    "assert TRAIN_PARQUET.exists()\n",
    "assert TEST_PARQUET.exists()\n",
    "assert SAMPLE_CSV.exists()\n",
    "assert TRAIN_IMG_DIR.exists()\n",
    "assert TEST_IMG_DIR.exists()\n",
    "\n",
    "# Устройство: MPS для Mac, иначе CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (70000, 35) Test: (25000, 34)\n"
     ]
    }
   ],
   "source": [
    "# [STEP 1] ЗАГРУЗКА ТАБЛИЦ\n",
    "train = pd.read_parquet(TRAIN_PARQUET, engine=\"pyarrow\")\n",
    "test  = pd.read_parquet(TEST_PARQUET, engine=\"pyarrow\")\n",
    "\n",
    "id_col = \"ID\"\n",
    "target_col = \"price_TARGET\"\n",
    "\n",
    "print(\"Train:\", train.shape, \"Test:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>equipment</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drive_type</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>doors_number</th>\n",
       "      <th>color</th>\n",
       "      <th>pts</th>\n",
       "      <th>audiosistema</th>\n",
       "      <th>diski</th>\n",
       "      <th>...</th>\n",
       "      <th>fary_mult</th>\n",
       "      <th>multimedia_navigacia_mult</th>\n",
       "      <th>obogrev_mult</th>\n",
       "      <th>pamyat_nastroek_mult</th>\n",
       "      <th>podushki_bezopasnosti_mult</th>\n",
       "      <th>pomosh_pri_vozhdenii_mult</th>\n",
       "      <th>protivoygonnaya_sistema_mult</th>\n",
       "      <th>salon_mult</th>\n",
       "      <th>upravlenie_klimatom_mult</th>\n",
       "      <th>price_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58146</td>\n",
       "      <td>Базовая</td>\n",
       "      <td>Седан</td>\n",
       "      <td>Передний</td>\n",
       "      <td>Бензин</td>\n",
       "      <td>4</td>\n",
       "      <td>Синий</td>\n",
       "      <td>Дубликат</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112144</td>\n",
       "      <td>Базовая</td>\n",
       "      <td>Универсал</td>\n",
       "      <td>Задний</td>\n",
       "      <td>Бензин</td>\n",
       "      <td>5</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>None</td>\n",
       "      <td>14\"</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Сигнализация]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120705</td>\n",
       "      <td>None</td>\n",
       "      <td>Внедорожник</td>\n",
       "      <td>Полный</td>\n",
       "      <td>Гибрид</td>\n",
       "      <td>5</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Электронный</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[Противотуманные, Омыватели фар, Адаптивное ос...</td>\n",
       "      <td>[CD привод, MP3, Радио, TV, Экран, Управление ...</td>\n",
       "      <td>[Передних сидений, Задних сидений, Зеркал, Зад...</td>\n",
       "      <td>[Сиденья водителя, Задних сидений, Зеркал, Рул...</td>\n",
       "      <td>[Фронтальная для водителя, Коленные, Шторки, Б...</td>\n",
       "      <td>[Автопарковщик, Датчик дождя, Датчик света, Па...</td>\n",
       "      <td>[Сигнализация, Центральный замок, Иммобилайзер...</td>\n",
       "      <td>[Кожаный руль, Люк]</td>\n",
       "      <td>[Управление на руле, Атермальное остекление]</td>\n",
       "      <td>7251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291392</td>\n",
       "      <td>Titanium</td>\n",
       "      <td>Седан</td>\n",
       "      <td>Передний</td>\n",
       "      <td>Бензин</td>\n",
       "      <td>4</td>\n",
       "      <td>Серебряный</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>6 колонок</td>\n",
       "      <td>16\"</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[CD привод, MP3, Радио, TV, Экран, Управление ...</td>\n",
       "      <td>[Передних сидений, Заднего стекла]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Фронтальная для водителя, Коленные, Шторки, Б...</td>\n",
       "      <td>[Датчик дождя, Датчик света, Парктроник задний...</td>\n",
       "      <td>[Сигнализация, Центральный замок]</td>\n",
       "      <td>[Кожаный руль]</td>\n",
       "      <td>[Управление на руле]</td>\n",
       "      <td>1067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35742</td>\n",
       "      <td>Базовая</td>\n",
       "      <td>Седан</td>\n",
       "      <td>Передний</td>\n",
       "      <td>Бензин</td>\n",
       "      <td>4</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Оригинал</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>54000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID equipment    body_type drive_type engine_type  doors_number  \\\n",
       "0   58146   Базовая        Седан   Передний      Бензин             4   \n",
       "1  112144   Базовая    Универсал     Задний      Бензин             5   \n",
       "2  120705      None  Внедорожник     Полный      Гибрид             5   \n",
       "3  291392  Titanium        Седан   Передний      Бензин             4   \n",
       "4   35742   Базовая        Седан   Передний      Бензин             4   \n",
       "\n",
       "        color          pts audiosistema diski  ...  \\\n",
       "0       Синий     Дубликат         None  None  ...   \n",
       "1     Бежевый     Оригинал         None   14\"  ...   \n",
       "2      Чёрный  Электронный         None  None  ...   \n",
       "3  Серебряный     Оригинал    6 колонок   16\"  ...   \n",
       "4      Чёрный     Оригинал         None  None  ...   \n",
       "\n",
       "                                           fary_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [Противотуманные, Омыватели фар, Адаптивное ос...   \n",
       "3                                             [None]   \n",
       "4                                             [None]   \n",
       "\n",
       "                           multimedia_navigacia_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [CD привод, MP3, Радио, TV, Экран, Управление ...   \n",
       "3  [CD привод, MP3, Радио, TV, Экран, Управление ...   \n",
       "4                                             [None]   \n",
       "\n",
       "                                        obogrev_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [Передних сидений, Задних сидений, Зеркал, Зад...   \n",
       "3                 [Передних сидений, Заднего стекла]   \n",
       "4                                             [None]   \n",
       "\n",
       "                                pamyat_nastroek_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [Сиденья водителя, Задних сидений, Зеркал, Рул...   \n",
       "3                                             [None]   \n",
       "4                                             [None]   \n",
       "\n",
       "                          podushki_bezopasnosti_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [Фронтальная для водителя, Коленные, Шторки, Б...   \n",
       "3  [Фронтальная для водителя, Коленные, Шторки, Б...   \n",
       "4                                             [None]   \n",
       "\n",
       "                           pomosh_pri_vozhdenii_mult  \\\n",
       "0                                             [None]   \n",
       "1                                             [None]   \n",
       "2  [Автопарковщик, Датчик дождя, Датчик света, Па...   \n",
       "3  [Датчик дождя, Датчик света, Парктроник задний...   \n",
       "4                                             [None]   \n",
       "\n",
       "                        protivoygonnaya_sistema_mult           salon_mult  \\\n",
       "0                                             [None]               [None]   \n",
       "1                                     [Сигнализация]               [None]   \n",
       "2  [Сигнализация, Центральный замок, Иммобилайзер...  [Кожаный руль, Люк]   \n",
       "3                  [Сигнализация, Центральный замок]       [Кожаный руль]   \n",
       "4                                             [None]               [None]   \n",
       "\n",
       "                       upravlenie_klimatom_mult  price_TARGET  \n",
       "0                                        [None]         51000  \n",
       "1                                        [None]        195000  \n",
       "2  [Управление на руле, Атермальное остекление]       7251000  \n",
       "3                          [Управление на руле]       1067000  \n",
       "4                                        [None]         54000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [STEP 2] ФИЧИ (табличные)\n",
    "num_cols  = [\"doors_number\",\"crashes_count\",\"owners_count\",\"mileage\",\"latitude\",\"longitude\"]\n",
    "cat_cols  = [\"equipment\",\"body_type\",\"drive_type\",\"engine_type\",\"color\",\"pts\",\n",
    "             \"steering_wheel\",\"audiosistema\",\"diski\",\"electropodemniki\",\"fary\",\n",
    "             \"salon\",\"upravlenie_klimatom\",\"usilitel_rul\"]\n",
    "multi_cols = [\"aktivnaya_bezopasnost_mult\",\"audiosistema_mult\",\"shini_i_diski_mult\",\n",
    "              \"electroprivod_mult\",\"fary_mult\",\"multimedia_navigacia_mult\",\"obogrev_mult\",\n",
    "              \"pamyat_nastroek_mult\",\"podushki_bezopasnosti_mult\",\"pomosh_pri_vozhdenii_mult\",\n",
    "              \"protivoygonnaya_sistema_mult\",\"salon_mult\",\"upravlenie_klimatom_mult\"]\n",
    "\n",
    "# числовые\n",
    "for c in num_cols:\n",
    "    train[c] = pd.to_numeric(train[c], errors=\"coerce\").fillna(-1)\n",
    "    test[c]  = pd.to_numeric(test[c], errors=\"coerce\").fillna(-1)\n",
    "\n",
    "# категориальные\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].fillna(\"Unknown\").astype(str)\n",
    "    test[c]  = test[c].fillna(\"Unknown\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded: (70000, 421) (25000, 421)\n"
     ]
    }
   ],
   "source": [
    "# [STEP 3] MULTI-COLS → ONE-HOT (top-N)\n",
    "from collections import Counter\n",
    "\n",
    "def split_listlike(s):\n",
    "    if s is None: return []\n",
    "    if isinstance(s, (list, tuple, set)): return [str(x).strip() for x in s if str(x).strip() not in (\"\", \"None\", \"[None]\")]\n",
    "    s = str(s).strip().replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace('\"',\"\")\n",
    "    if s in (\"\", \"None\", \"[None]\"): return []\n",
    "    return [p.strip() for p in s.split(\",\") if p.strip() not in (\"\", \"None\")]\n",
    "\n",
    "def expand_multicolumns(df, cols, topN=400, vocab_map=None, fit=True):\n",
    "    if fit:\n",
    "        cnt = Counter()\n",
    "        for c in cols:\n",
    "            cnt.update(x for row in df[c].map(split_listlike) for x in row)\n",
    "        vocab = [k for k,_ in cnt.most_common(topN)]\n",
    "        vocab_map = {k:i for i,k in enumerate(vocab)}\n",
    "    else:\n",
    "        vocab = list(vocab_map.keys())\n",
    "\n",
    "    X = np.zeros((len(df), len(vocab)), dtype=np.int8)\n",
    "    for i, row in enumerate(df[cols].itertuples(index=False)):\n",
    "        bag = set()\n",
    "        for val in row: bag.update(split_listlike(val))\n",
    "        for opt in bag:\n",
    "            if opt in vocab_map:\n",
    "                X[i, vocab_map[opt]] = 1\n",
    "\n",
    "    return pd.DataFrame(X, index=df.index, columns=[f\"m_{v}\" for v in vocab]), vocab_map\n",
    "\n",
    "mtrain, vocab_map = expand_multicolumns(train, multi_cols, fit=True)\n",
    "mtest,  _         = expand_multicolumns(test,  multi_cols, vocab_map=vocab_map, fit=False)\n",
    "\n",
    "train_exp = pd.concat([train[[id_col]+num_cols+cat_cols], mtrain], axis=1)\n",
    "test_exp  = pd.concat([test[[id_col]+num_cols+cat_cols],  mtest],  axis=1)\n",
    "print(\"Expanded:\", train_exp.shape, test_exp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9761456\ttest: 0.9706357\tbest: 0.9706357 (0)\ttotal: 75.6ms\tremaining: 6m 17s\n",
      "200:\tlearn: 0.4769189\ttest: 0.4979249\tbest: 0.4979249 (200)\ttotal: 12s\tremaining: 4m 47s\n",
      "400:\tlearn: 0.4486526\ttest: 0.4818907\tbest: 0.4818907 (400)\ttotal: 23.7s\tremaining: 4m 31s\n",
      "600:\tlearn: 0.4326295\ttest: 0.4762329\tbest: 0.4762329 (600)\ttotal: 35.8s\tremaining: 4m 21s\n",
      "800:\tlearn: 0.4205640\ttest: 0.4731046\tbest: 0.4731046 (800)\ttotal: 47.9s\tremaining: 4m 11s\n",
      "1000:\tlearn: 0.4102259\ttest: 0.4717161\tbest: 0.4717161 (1000)\ttotal: 1m\tremaining: 4m\n",
      "1200:\tlearn: 0.4010198\ttest: 0.4704237\tbest: 0.4704237 (1200)\ttotal: 1m 12s\tremaining: 3m 49s\n",
      "1400:\tlearn: 0.3925431\ttest: 0.4692284\tbest: 0.4692284 (1400)\ttotal: 1m 24s\tremaining: 3m 37s\n",
      "1600:\tlearn: 0.3849826\ttest: 0.4683723\tbest: 0.4683723 (1600)\ttotal: 1m 37s\tremaining: 3m 26s\n",
      "1800:\tlearn: 0.3783611\ttest: 0.4679684\tbest: 0.4679163 (1784)\ttotal: 1m 50s\tremaining: 3m 15s\n",
      "2000:\tlearn: 0.3719208\ttest: 0.4674675\tbest: 0.4674675 (2000)\ttotal: 2m 3s\tremaining: 3m 4s\n",
      "2200:\tlearn: 0.3659351\ttest: 0.4671304\tbest: 0.4671281 (2197)\ttotal: 2m 16s\tremaining: 2m 53s\n",
      "2400:\tlearn: 0.3602090\ttest: 0.4668977\tbest: 0.4668977 (2400)\ttotal: 2m 28s\tremaining: 2m 41s\n",
      "2600:\tlearn: 0.3547810\ttest: 0.4668019\tbest: 0.4667787 (2582)\ttotal: 2m 41s\tremaining: 2m 28s\n",
      "2800:\tlearn: 0.3496036\ttest: 0.4666542\tbest: 0.4665842 (2740)\ttotal: 2m 54s\tremaining: 2m 16s\n",
      "3000:\tlearn: 0.3444303\ttest: 0.4665017\tbest: 0.4664610 (2944)\ttotal: 3m 6s\tremaining: 2m 4s\n",
      "3200:\tlearn: 0.3400255\ttest: 0.4663770\tbest: 0.4663645 (3195)\ttotal: 3m 19s\tremaining: 1m 52s\n",
      "3400:\tlearn: 0.3352793\ttest: 0.4663318\tbest: 0.4662919 (3309)\ttotal: 3m 32s\tremaining: 1m 39s\n",
      "3600:\tlearn: 0.3306867\ttest: 0.4663839\tbest: 0.4662824 (3452)\ttotal: 3m 45s\tremaining: 1m 27s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.4662824054\n",
      "bestIteration = 3452\n",
      "\n",
      "Shrink model to first 3453 iterations.\n",
      "VALID medianAPE (tabular): 0.25394135544057167\n"
     ]
    }
   ],
   "source": [
    "# [STEP 4] БАЗОВЫЙ CATBOOST (Табличные)\n",
    "def to_log(y): return np.log1p(y)\n",
    "def from_log(y): return np.expm1(y)\n",
    "def median_ape(y_true, y_pred):\n",
    "    ape = np.abs(y_pred - y_true) / np.clip(y_true, 1e-9, None)\n",
    "    return np.median(ape)\n",
    "\n",
    "train_mask = train.index < int(0.85*len(train))\n",
    "valid_mask = ~train_mask\n",
    "\n",
    "X_tr = train_exp.loc[train_mask].drop(columns=[id_col])\n",
    "X_va = train_exp.loc[valid_mask].drop(columns=[id_col])\n",
    "y_tr = to_log(train.loc[train_mask, target_col].values)\n",
    "y_va = to_log(train.loc[valid_mask, target_col].values)\n",
    "\n",
    "cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols if c in X_tr.columns]\n",
    "pool_tr = Pool(X_tr, y_tr, cat_features=cat_idx)\n",
    "pool_va = Pool(X_va, y_va, cat_features=cat_idx)\n",
    "\n",
    "cb_tab = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\", depth=10, learning_rate=0.05,\n",
    "    iterations=5000, od_type=\"Iter\", od_wait=200,\n",
    "    random_seed=42, verbose=200\n",
    ")\n",
    "cb_tab.fit(pool_tr, eval_set=pool_va)\n",
    "\n",
    "pred_va_tab = from_log(cb_tab.predict(pool_va))\n",
    "val_medAPE_tab = median_ape(train.loc[valid_mask, target_col], pred_va_tab)\n",
    "print(\"VALID medianAPE (tabular):\", val_medAPE_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 02:57:03,705] A new study created in memory with name: no-name-9b607f44-c6ba-4948-82ce-b57df630cbe5\n",
      "Best trial: 0. Best value: 0.273032:   2%|▎         | 1/40 [00:50<32:32, 50.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 02:57:53,777] Trial 0 finished with value: 0.2730316946732103 and parameters: {'depth': 7, 'learning_rate': 0.03562262385685697, 'l2_leaf_reg': 3.558302467297511, 'bagging_temperature': 0.06175383446705274, 'rsm': 0.9668053333634705, 'random_strength': 1.377941309288312}. Best is trial 0 with value: 0.2730316946732103.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.271462:   5%|▌         | 2/40 [01:41<32:16, 50.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 02:58:45,356] Trial 1 finished with value: 0.27146157869614007 and parameters: {'depth': 7, 'learning_rate': 0.08373456948979954, 'l2_leaf_reg': 8.516456404218069, 'bagging_temperature': 0.3021700357148615, 'rsm': 0.9644358086249386, 'random_strength': 1.5412626395873874}. Best is trial 1 with value: 0.27146157869614007.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.268546:   8%|▊         | 3/40 [03:05<40:41, 65.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:00:09,239] Trial 2 finished with value: 0.2685455301917272 and parameters: {'depth': 9, 'learning_rate': 0.046196142562088496, 'l2_leaf_reg': 2.9756750122852633, 'bagging_temperature': 0.5567454913488928, 'rsm': 0.8840354137567983, 'random_strength': 0.8844576941948337}. Best is trial 2 with value: 0.2685455301917272.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.268546:  10%|█         | 4/40 [04:19<41:35, 69.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:01:23,668] Trial 3 finished with value: 0.2690160978753884 and parameters: {'depth': 8, 'learning_rate': 0.04882760771868774, 'l2_leaf_reg': 2.7360820703677198, 'bagging_temperature': 0.25997338214668425, 'rsm': 0.9184391014538555, 'random_strength': 0.9567275561398292}. Best is trial 2 with value: 0.2685455301917272.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  12%|█▎        | 5/40 [06:16<50:21, 86.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:03:20,179] Trial 4 finished with value: 0.2679063439535001 and parameters: {'depth': 10, 'learning_rate': 0.06446258915141861, 'l2_leaf_reg': 4.744085752464073, 'bagging_temperature': 0.6099029822140482, 'rsm': 0.9965911020298823, 'random_strength': 1.6700322788137818}. Best is trial 4 with value: 0.2679063439535001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  15%|█▌        | 6/40 [06:51<39:01, 68.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:03:55,121] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  18%|█▊        | 7/40 [07:49<35:58, 65.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:04:53,453] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  20%|██        | 8/40 [08:34<31:20, 58.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:05:37,921] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  22%|██▎       | 9/40 [10:17<37:37, 72.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:07:21,681] Trial 8 finished with value: 0.2689662175934525 and parameters: {'depth': 10, 'learning_rate': 0.03833698769458851, 'l2_leaf_reg': 6.000571607901351, 'bagging_temperature': 0.7952361392788685, 'rsm': 0.8670402951330227, 'random_strength': 1.6513981964420252}. Best is trial 4 with value: 0.2679063439535001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.267906:  25%|██▌       | 10/40 [11:17<34:17, 68.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:08:20,769] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  28%|██▊       | 11/40 [13:10<39:46, 82.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:10:14,199] Trial 10 finished with value: 0.2663007765887189 and parameters: {'depth': 10, 'learning_rate': 0.06466753348741862, 'l2_leaf_reg': 4.986095343730952, 'bagging_temperature': 0.4731878364294065, 'rsm': 0.9955992183399607, 'random_strength': 1.7834660196350933}. Best is trial 10 with value: 0.2663007765887189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  30%|███       | 12/40 [15:02<42:36, 91.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:12:06,037] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  32%|███▎      | 13/40 [16:18<39:00, 86.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:13:22,068] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  35%|███▌      | 14/40 [18:08<40:41, 93.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:15:12,672] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  38%|███▊      | 15/40 [19:12<35:21, 84.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:16:16,541] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  40%|████      | 16/40 [21:16<38:34, 96.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:18:19,899] Trial 15 finished with value: 0.268151228102235 and parameters: {'depth': 10, 'learning_rate': 0.0568255832048168, 'l2_leaf_reg': 4.5338364767378, 'bagging_temperature': 0.6635767778893444, 'rsm': 0.9842180224802932, 'random_strength': 1.2322101403268149}. Best is trial 10 with value: 0.2663007765887189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  42%|████▎     | 17/40 [23:16<39:44, 103.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:20:20,436] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  45%|████▌     | 18/40 [24:04<31:53, 86.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:21:08,490] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  48%|████▊     | 19/40 [25:09<28:03, 80.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:22:12,734] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  50%|█████     | 20/40 [27:13<31:08, 93.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:24:17,077] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  52%|█████▎    | 21/40 [28:20<27:02, 85.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:25:23,777] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  55%|█████▌    | 22/40 [30:23<29:00, 96.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:27:26,814] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  57%|█████▊    | 23/40 [32:28<29:49, 105.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:29:32,066] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  60%|██████    | 24/40 [33:49<26:09, 98.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:30:53,467] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  62%|██████▎   | 25/40 [35:14<23:29, 93.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:32:17,730] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  65%|██████▌   | 26/40 [36:21<20:04, 86.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:33:25,205] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  68%|██████▊   | 27/40 [37:42<18:18, 84.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:34:46,140] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  70%|███████   | 28/40 [38:49<15:52, 79.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:35:53,479] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  72%|███████▎  | 29/40 [40:12<14:45, 80.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:37:16,664] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  75%|███████▌  | 30/40 [41:01<11:49, 70.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:38:05,334] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  78%|███████▊  | 31/40 [43:02<12:52, 85.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:40:05,986] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  80%|████████  | 32/40 [44:39<11:53, 89.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:41:42,792] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  82%|████████▎ | 33/40 [45:43<09:31, 81.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:42:47,118] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  85%|████████▌ | 34/40 [46:20<06:49, 68.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:43:23,810] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  88%|████████▊ | 35/40 [48:21<07:00, 84.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:45:25,330] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  90%|█████████ | 36/40 [49:28<05:16, 79.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:46:32,224] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  92%|█████████▎| 37/40 [51:25<04:30, 90.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:48:28,833] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  95%|█████████▌| 38/40 [52:03<02:29, 74.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:49:07,007] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301:  98%|█████████▊| 39/40 [53:14<01:13, 73.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:50:18,350] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.266301: 100%|██████████| 40/40 [54:56<00:00, 82.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 03:52:00,104] Trial 39 pruned. \n",
      "TAB-lite best medianAPE (sub, CV): 0.2663007765887189\n",
      "TAB-lite best params: {'depth': 10, 'learning_rate': 0.06466753348741862, 'l2_leaf_reg': 4.986095343730952, 'bagging_temperature': 0.4731878364294065, 'rsm': 0.9955992183399607, 'random_strength': 1.7834660196350933}\n",
      "0:\tlearn: 0.9701018\ttotal: 77.2ms\tremaining: 2m 34s\n",
      "200:\tlearn: 0.4750052\ttotal: 13.8s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.4480871\ttotal: 28.1s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.4323454\ttotal: 42.9s\tremaining: 1m 39s\n",
      "800:\tlearn: 0.4203027\ttotal: 58s\tremaining: 1m 26s\n",
      "1000:\tlearn: 0.4102792\ttotal: 1m 13s\tremaining: 1m 12s\n",
      "1200:\tlearn: 0.4012831\ttotal: 1m 28s\tremaining: 58.8s\n",
      "1400:\tlearn: 0.3929938\ttotal: 1m 43s\tremaining: 44.4s\n",
      "1600:\tlearn: 0.3855942\ttotal: 1m 59s\tremaining: 29.7s\n",
      "1800:\tlearn: 0.3793007\ttotal: 2m 14s\tremaining: 14.9s\n",
      "1999:\tlearn: 0.3730631\ttotal: 2m 29s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1634c0e00>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === ПАРАМЕТРЫ ПОДБОРА (ПРАВЬ ТУТ) ===\n",
    "N_SUB = 30000            # было 20000; можно 40000 если хватает RAM\n",
    "CV_FOLDS = 3             # можно 5 для более честной оценки\n",
    "ITER_OBJ = 1200          # было 600; сколько итераций в КАЖДОМ trial у CatBoost\n",
    "N_TRIALS = 40            # было 15; сколько проб у Optuna\n",
    "OD_WAIT = 80             # ранняя остановка в trial'ах\n",
    "FINAL_ITERS = 2000       # финальный fit cb_tab на ВСЁМ train\n",
    "# =====================================\n",
    "\n",
    "# сабсэмпл\n",
    "rng = np.random.RandomState(42)\n",
    "sub_idx = rng.choice(len(train), size=min(N_SUB, len(train)), replace=False)\n",
    "X_sub = X_tab_all.iloc[sub_idx].reset_index(drop=True)\n",
    "y_sub = y_all[sub_idx]\n",
    "\n",
    "cvk = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "if HAS_OPTUNA:\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=max(2, CV_FOLDS-1))\n",
    "    def objective_tab_lite(trial):\n",
    "        params = {\n",
    "            \"loss_function\": \"RMSE\",\n",
    "            \"depth\": trial.suggest_int(\"depth\", 7, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.09, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 2.0, 15.0, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 0.8),\n",
    "            \"rsm\": trial.suggest_float(\"rsm\", 0.85, 1.0),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 0.8, 1.8),\n",
    "            \"iterations\": ITER_OBJ,     # <— увеличено\n",
    "            \"od_type\": \"Iter\",\n",
    "            \"od_wait\": OD_WAIT,\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": False,\n",
    "            \"thread_count\": -1\n",
    "        }\n",
    "        oof = np.full(len(X_sub), np.nan, dtype=float)\n",
    "        fold = 0\n",
    "        for tr_idx, va_idx in cvk.split(X_sub):\n",
    "            fold += 1\n",
    "            X_tr, X_va = X_sub.iloc[tr_idx], X_sub.iloc[va_idx]\n",
    "            y_tr, y_va = y_sub[tr_idx], y_sub[va_idx]\n",
    "            cat_idx_tr = [X_tr.columns.get_loc(c) for c in cat_cols if c in X_tr.columns]\n",
    "            cat_idx_va = [X_va.columns.get_loc(c) for c in cat_cols if c in X_va.columns]\n",
    "            m = CatBoostRegressor(**params)\n",
    "            m.fit(Pool(X_tr, to_log(y_tr), cat_features=cat_idx_tr),\n",
    "                  eval_set=Pool(X_va, to_log(y_va), cat_features=cat_idx_va))\n",
    "            pred_va = from_log(m.predict(Pool(X_va, cat_features=cat_idx_va)))\n",
    "            oof[va_idx] = pred_va\n",
    "            trial.report(median_ape(y_va, pred_va), step=fold)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        return median_ape(y_sub, oof)\n",
    "\n",
    "    study_tab_lite = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "    study_tab_lite.optimize(objective_tab_lite, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    best_params = study_tab_lite.best_trial.params\n",
    "    print(\"TAB-lite best medianAPE (sub, CV):\", study_tab_lite.best_value)\n",
    "    print(\"TAB-lite best params:\", best_params)\n",
    "else:\n",
    "    best_params = dict(\n",
    "        depth=10, learning_rate=0.05, l2_leaf_reg=8.0,\n",
    "        bagging_temperature=0.3, rsm=0.9, random_strength=1.0,\n",
    "        iterations=ITER_OBJ, od_type=\"Iter\", od_wait=OD_WAIT\n",
    "    )\n",
    "\n",
    "# финальный CatBoost на всём train — увеличиваем iterations\n",
    "cb_tab = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\", random_seed=42, verbose=200, thread_count=-1,\n",
    "    **{**best_params, \"iterations\": FINAL_ITERS}\n",
    ")\n",
    "cb_tab.fit(Pool(X_tab_all, to_log(y_all), cat_features=cat_idx_tab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for embeddings: mps\n"
     ]
    }
   ],
   "source": [
    "# [STEP 5] UNIVERSAL IMAGE EMBEDDING EXTRACTOR (DIR -> PARQUET CHUNKS) + AGGREGATOR\n",
    "\n",
    "import os, io\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch, torchvision as tv\n",
    "\n",
    "# ---- device ----\n",
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_grad_enabled(False)\n",
    "print(\"Device for embeddings:\", device)\n",
    "\n",
    "# ---- tiny backbone by default ----\n",
    "backbone_tiny = tv.models.convnext_tiny(weights=tv.models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "backbone_tiny.classifier = torch.nn.Identity()\n",
    "backbone_tiny.eval().to(device)\n",
    "tfm_tiny = tv.models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "def embed_batch(x: torch.Tensor, model: torch.nn.Module) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        f = model(x)\n",
    "        if isinstance(f, (list, tuple)):\n",
    "            f = f[0]\n",
    "        if f.ndim == 4:\n",
    "            f = torch.flatten(f, 1)   # (N, C, 1, 1) -> (N, C)\n",
    "        elif f.ndim == 3:\n",
    "            f = f.mean(dim=-1)\n",
    "        return f.detach().cpu().numpy()\n",
    "\n",
    "def parse_id_from_name(name: str) -> int:\n",
    "    return int(Path(name).stem.split(\"_\")[0])\n",
    "\n",
    "def load_processed_list(ckpt_path: Path):\n",
    "    if ckpt_path.exists():\n",
    "        return {line.strip() for line in ckpt_path.open()}\n",
    "    return set()\n",
    "\n",
    "def append_processed_list(ckpt_path: Path, names):\n",
    "    with ckpt_path.open(\"a\") as f:\n",
    "        for n in names:\n",
    "            f.write(n + \"\\n\")\n",
    "\n",
    "def next_chunk_path(chunk_dir: Path, split: str, idx: int):\n",
    "    return chunk_dir / f\"emb_{split}_chunk_{idx:05d}.parquet\"\n",
    "\n",
    "def extract_embeddings_from_dir(img_dir: Path, chunk_dir: Path, ckpt_path: Path,\n",
    "                                split_name=\"train\", batch_size=128, chunk_size=6000,\n",
    "                                backbone: torch.nn.Module = backbone_tiny,\n",
    "                                transforms = tfm_tiny):\n",
    "    \"\"\"\n",
    "    STEP 5.1 — Пробегаем папку с .jpg, считаем эмбеддинги батчами, пишем чанки parquet (ID + features + filename).\n",
    "    Возобновляемость: пропускаем файлы из ckpt-списка.\n",
    "    \"\"\"\n",
    "    chunk_dir.mkdir(exist_ok=True)\n",
    "    processed = load_processed_list(ckpt_path)\n",
    "    all_files = sorted([f for f in img_dir.iterdir() if f.suffix.lower() == \".jpg\"])\n",
    "    wrote_total, chunk_idx = 0, len(list(chunk_dir.glob(\"*.parquet\")))\n",
    "\n",
    "    buf_imgs, buf_ids, buf_names = [], [], []\n",
    "    feats_chunks = []\n",
    "    pbar = tqdm(all_files, desc=f\"Embeddings {split_name} ({img_dir.name})\")\n",
    "    for fp in pbar:\n",
    "        fname = fp.name\n",
    "        if fname in processed: \n",
    "            continue\n",
    "        try:\n",
    "            car_id = parse_id_from_name(fname)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        im = Image.open(fp).convert(\"RGB\")\n",
    "        x = transforms(im)\n",
    "        buf_imgs.append(x); buf_ids.append(car_id); buf_names.append(fname)\n",
    "\n",
    "        if len(buf_imgs) >= batch_size:\n",
    "            xb = torch.stack(buf_imgs).to(device)\n",
    "            fb = embed_batch(xb, backbone)\n",
    "            feats_chunks.append((buf_ids.copy(), buf_names.copy(), fb.copy()))\n",
    "            buf_imgs.clear(); buf_ids.clear(); buf_names.clear()\n",
    "\n",
    "        current_count = wrote_total + sum(len(ids) for ids,_,_ in feats_chunks) + len(buf_imgs)\n",
    "        if current_count // chunk_size > wrote_total // chunk_size and feats_chunks:\n",
    "            # сбрасываем на диск\n",
    "            all_ids, all_names, all_f = [], [], []\n",
    "            for ids, names, f in feats_chunks:\n",
    "                all_ids.extend(ids); all_names.extend(names); all_f.append(f)\n",
    "            all_f = np.concatenate(all_f, axis=0)\n",
    "            df = pd.DataFrame(all_f); df.insert(0, \"ID\", all_ids); df[\"filename\"] = all_names\n",
    "            outp = next_chunk_path(chunk_dir, split_name, chunk_idx)\n",
    "            df.to_parquet(outp, index=False)\n",
    "            chunk_idx += 1\n",
    "            append_processed_list(ckpt_path, all_names)\n",
    "            wrote_total += len(all_names)\n",
    "            feats_chunks.clear()\n",
    "            pbar.set_postfix(saved=wrote_total)\n",
    "\n",
    "    # остаток\n",
    "    if buf_imgs:\n",
    "        xb = torch.stack(buf_imgs).to(device)\n",
    "        fb = embed_batch(xb, backbone)\n",
    "        feats_chunks.append((buf_ids.copy(), buf_names.copy(), fb.copy()))\n",
    "        buf_imgs.clear(); buf_ids.clear(); buf_names.clear()\n",
    "\n",
    "    if feats_chunks:\n",
    "        all_ids, all_names, all_f = [], [], []\n",
    "        for ids, names, f in feats_chunks:\n",
    "            all_ids.extend(ids); all_names.extend(names); all_f.append(f)\n",
    "        all_f = np.concatenate(all_f, axis=0)\n",
    "        df = pd.DataFrame(all_f); df.insert(0, \"ID\", all_ids); df[\"filename\"] = all_names\n",
    "        outp = next_chunk_path(chunk_dir, split_name, chunk_idx)\n",
    "        df.to_parquet(outp, index=False)\n",
    "        append_processed_list(ckpt_path, all_names)\n",
    "        wrote_total += len(all_names)\n",
    "\n",
    "    print(f\"[{split_name}] DONE -> {chunk_dir} | processed: {wrote_total}\")\n",
    "\n",
    "def load_and_aggregate_chunks(chunk_dir: Path, id_col=\"ID\"):\n",
    "    \"\"\"\n",
    "    STEP 5.2 — Чтение всех parquet-чанков и агрегация по ID: mean + std.\n",
    "    \"\"\"\n",
    "    files = sorted(chunk_dir.glob(\"*.parquet\"))\n",
    "    assert files, f\"Нет parquet-файлов в {chunk_dir}\"\n",
    "    dfs = [pd.read_parquet(p) for p in files]\n",
    "    big = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    feat_cols = [c for c in big.columns if c not in (id_col, \"filename\")]\n",
    "    grp = big.groupby(id_col)[feat_cols]\n",
    "    agg = pd.concat([grp.mean().add_prefix(\"img_mean_\"),\n",
    "                     grp.std().fillna(0).add_prefix(\"img_std_\")], axis=1).reset_index()\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /Users/arutyunoff/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338M/338M [00:10<00:00, 32.3MB/s] \n",
      "Embeddings train_base (train_images):  31%|███       | 84991/273873 [3:54:24<8:40:55,  6.04it/s, saved=84096] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# запускаем (можно на ночь)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DO_EMB_BASE:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mextract_embeddings_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_IMG_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_DIR_TRAIN_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCKPT_LIST_TRAIN_B\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                                \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackbone_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfm_base\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     extract_embeddings_from_dir(TEST_IMG_DIR,  CHUNK_DIR_TEST_B,  CKPT_LIST_TEST_B,\n\u001b[32m     21\u001b[39m                                 split_name=\u001b[33m\"\u001b[39m\u001b[33mtest_base\u001b[39m\u001b[33m\"\u001b[39m, batch_size=\u001b[32m128\u001b[39m, chunk_size=\u001b[32m6000\u001b[39m,\n\u001b[32m     22\u001b[39m                                 backbone=backbone_base, transforms=tfm_base)\n\u001b[32m     24\u001b[39m     img_feat_train_b = load_and_aggregate_chunks(CHUNK_DIR_TRAIN_B)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mextract_embeddings_from_dir\u001b[39m\u001b[34m(img_dir, chunk_dir, ckpt_path, split_name, batch_size, chunk_size, backbone, transforms)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf_imgs) >= batch_size:\n\u001b[32m     78\u001b[39m     xb = torch.stack(buf_imgs).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     fb = \u001b[43membed_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     feats_chunks.append((buf_ids.copy(), buf_names.copy(), fb.copy()))\n\u001b[32m     81\u001b[39m     buf_imgs.clear(); buf_ids.clear(); buf_names.clear()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36membed_batch\u001b[39m\u001b[34m(x, model)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m f.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m     29\u001b[39m     f = f.mean(dim=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# [STEP V1] CONVNEXT-BASE EMBEDDINGS (optional but recommended overnight)\n",
    "\n",
    "# папки для чанков/чекпоинтов Base\n",
    "CHUNK_DIR_TRAIN_B = PROJ / \"emb_chunks_train_cnvb\"; CHUNK_DIR_TRAIN_B.mkdir(exist_ok=True)\n",
    "CHUNK_DIR_TEST_B  = PROJ / \"emb_chunks_test_cnvb\";  CHUNK_DIR_TEST_B.mkdir(exist_ok=True)\n",
    "CKPT_LIST_TRAIN_B = PROJ / \"_processed_train_cnvb.txt\"\n",
    "CKPT_LIST_TEST_B  = PROJ / \"_processed_test_cnvb.txt\"\n",
    "\n",
    "# backbone base\n",
    "backbone_base = tv.models.convnext_base(weights=tv.models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
    "backbone_base.classifier = torch.nn.Identity()\n",
    "backbone_base.eval().to(device)\n",
    "tfm_base = tv.models.ConvNeXt_Base_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "# запускаем (можно на ночь)\n",
    "if DO_EMB_BASE:\n",
    "    extract_embeddings_from_dir(TRAIN_IMG_DIR, CHUNK_DIR_TRAIN_B, CKPT_LIST_TRAIN_B,\n",
    "                                split_name=\"train_base\", batch_size=128, chunk_size=6000,\n",
    "                                backbone=backbone_base, transforms=tfm_base)\n",
    "    extract_embeddings_from_dir(TEST_IMG_DIR,  CHUNK_DIR_TEST_B,  CKPT_LIST_TEST_B,\n",
    "                                split_name=\"test_base\", batch_size=128, chunk_size=6000,\n",
    "                                backbone=backbone_base, transforms=tfm_base)\n",
    "\n",
    "    img_feat_train_b = load_and_aggregate_chunks(CHUNK_DIR_TRAIN_B)\n",
    "    img_feat_test_b  = load_and_aggregate_chunks(CHUNK_DIR_TEST_B)\n",
    "    print(\"Base image feats:\", img_feat_train_b.shape, img_feat_test_b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feats: (70000, 1537) (25000, 1537)\n"
     ]
    }
   ],
   "source": [
    "# [STEP 6] АГРЕГАЦИЯ ЭМБЕДДИНГОВ\n",
    "def load_and_aggregate_chunks(chunk_dir: Path, id_col=\"ID\"):\n",
    "    files = sorted(chunk_dir.glob(\"*.parquet\"))\n",
    "    dfs = [pd.read_parquet(p) for p in files]\n",
    "    big = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    feat_cols = [c for c in big.columns if c not in (id_col,\"filename\")]\n",
    "    grp = big.groupby(id_col)[feat_cols]\n",
    "    agg_mean = grp.mean().add_prefix(\"img_mean_\")\n",
    "    agg_std  = grp.std().fillna(0).add_prefix(\"img_std_\")\n",
    "    return pd.concat([agg_mean, agg_std], axis=1).reset_index()\n",
    "\n",
    "img_feat_train = load_and_aggregate_chunks(CHUNK_DIR_TRAIN)\n",
    "img_feat_test  = load_and_aggregate_chunks(CHUNK_DIR_TEST)\n",
    "print(\"Image feats:\", img_feat_train.shape, img_feat_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9776214\ttest: 0.9729582\tbest: 0.9729582 (0)\ttotal: 635ms\tremaining: 52m 52s\n",
      "200:\tlearn: 0.3767605\ttest: 0.4236425\tbest: 0.4236425 (200)\ttotal: 2m 16s\tremaining: 54m 24s\n",
      "400:\tlearn: 0.3130972\ttest: 0.4034035\tbest: 0.4034035 (400)\ttotal: 4m 51s\tremaining: 55m 41s\n",
      "600:\tlearn: 0.2677465\ttest: 0.3957662\tbest: 0.3957662 (600)\ttotal: 7m 21s\tremaining: 53m 51s\n",
      "800:\tlearn: 0.2323946\ttest: 0.3919557\tbest: 0.3919557 (800)\ttotal: 9m 56s\tremaining: 52m 6s\n",
      "1000:\tlearn: 0.2031443\ttest: 0.3894679\tbest: 0.3894679 (1000)\ttotal: 12m 38s\tremaining: 50m 31s\n",
      "1200:\tlearn: 0.1783893\ttest: 0.3879333\tbest: 0.3879333 (1200)\ttotal: 15m 15s\tremaining: 48m 16s\n",
      "1400:\tlearn: 0.1564435\ttest: 0.3865915\tbest: 0.3865859 (1394)\ttotal: 17m 59s\tremaining: 46m 14s\n",
      "1600:\tlearn: 0.1375072\ttest: 0.3857179\tbest: 0.3856994 (1589)\ttotal: 20m 51s\tremaining: 44m 16s\n",
      "1800:\tlearn: 0.1209416\ttest: 0.3851273\tbest: 0.3851273 (1800)\ttotal: 23m 37s\tremaining: 41m 57s\n",
      "2000:\tlearn: 0.1061339\ttest: 0.3847285\tbest: 0.3847206 (1998)\ttotal: 26m 16s\tremaining: 39m 22s\n",
      "2200:\tlearn: 0.0936436\ttest: 0.3843437\tbest: 0.3843437 (2200)\ttotal: 28m 57s\tremaining: 36m 50s\n",
      "2400:\tlearn: 0.0824939\ttest: 0.3840981\tbest: 0.3840981 (2400)\ttotal: 31m 41s\tremaining: 34m 18s\n",
      "2600:\tlearn: 0.0726190\ttest: 0.3838961\tbest: 0.3838884 (2589)\ttotal: 34m 20s\tremaining: 31m 40s\n",
      "2800:\tlearn: 0.0640416\ttest: 0.3836417\tbest: 0.3836417 (2800)\ttotal: 36m 47s\tremaining: 28m 53s\n",
      "3000:\tlearn: 0.0565513\ttest: 0.3835574\tbest: 0.3835557 (2999)\ttotal: 39m 22s\tremaining: 26m 13s\n",
      "3200:\tlearn: 0.0498694\ttest: 0.3834667\tbest: 0.3834527 (3173)\ttotal: 41m 58s\tremaining: 23m 35s\n",
      "3400:\tlearn: 0.0440344\ttest: 0.3834301\tbest: 0.3834193 (3389)\ttotal: 44m 42s\tremaining: 21m 1s\n",
      "3600:\tlearn: 0.0390237\ttest: 0.3833460\tbest: 0.3833393 (3566)\ttotal: 47m 11s\tremaining: 18m 19s\n",
      "3800:\tlearn: 0.0346018\ttest: 0.3832998\tbest: 0.3832957 (3762)\ttotal: 49m 46s\tremaining: 15m 42s\n",
      "4000:\tlearn: 0.0306194\ttest: 0.3832272\tbest: 0.3832234 (3972)\ttotal: 52m 24s\tremaining: 13m 5s\n",
      "4200:\tlearn: 0.0272552\ttest: 0.3831970\tbest: 0.3831958 (4199)\ttotal: 55m 3s\tremaining: 10m 28s\n",
      "4400:\tlearn: 0.0241538\ttest: 0.3831303\tbest: 0.3831298 (4399)\ttotal: 57m 44s\tremaining: 7m 51s\n",
      "4600:\tlearn: 0.0215312\ttest: 0.3831032\tbest: 0.3831018 (4579)\ttotal: 1h 25s\tremaining: 5m 14s\n",
      "4800:\tlearn: 0.0191597\ttest: 0.3830685\tbest: 0.3830681 (4799)\ttotal: 1h 3m 8s\tremaining: 2m 37s\n",
      "4999:\tlearn: 0.0169810\ttest: 0.3830569\tbest: 0.3830499 (4944)\ttotal: 1h 5m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3830498571\n",
      "bestIteration = 4944\n",
      "\n",
      "Shrink model to first 4945 iterations.\n",
      "VALID medianAPE (fusion): 0.22729424612487212\n"
     ]
    }
   ],
   "source": [
    "# [STEP 7] FUSION CatBoost\n",
    "train_join = train_exp.merge(img_feat_train, on=id_col, how=\"left\").fillna(0)\n",
    "test_join  = test_exp.merge(img_feat_test,  on=id_col, how=\"left\").fillna(0)\n",
    "# [STEP T2] OPTUNA + 5-FOLD OOF FOR FUSION CATBOOST\n",
    "\n",
    "X_fus = train_join.drop(columns=[id_col]).copy()\n",
    "y_all = train[target_col].values.copy()\n",
    "cat_idx_fus = [X_fus.columns.get_loc(c) for c in cat_cols if c in X_fus.columns]\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective_fus(trial):\n",
    "    params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"depth\": trial.suggest_int(\"depth\", 6, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.12, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 20.0, log=True),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.5, 2.5),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"rsm\": trial.suggest_float(\"rsm\", 0.6, 1.0),\n",
    "        \"iterations\": 8000,\n",
    "        \"od_type\": \"Iter\",\n",
    "        \"od_wait\": trial.suggest_int(\"od_wait\", 200, 600),\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    oof = np.zeros(len(X_fus))\n",
    "    for tr_idx, va_idx in cv.split(X_fus):\n",
    "        X_tr, X_va = X_fus.iloc[tr_idx], X_fus.iloc[va_idx]\n",
    "        y_tr, y_va = y_all[tr_idx], y_all[va_idx]\n",
    "        m = CatBoostRegressor(**params)\n",
    "        m.fit(Pool(X_tr, to_log(y_tr), cat_features=cat_idx_fus),\n",
    "              eval_set=Pool(X_va, to_log(y_va), cat_features=cat_idx_fus))\n",
    "        oof[va_idx] = from_log(m.predict(Pool(X_va, cat_features=cat_idx_fus)))\n",
    "    return median_ape(y_all, oof)\n",
    "\n",
    "study_fus = optuna.create_study(direction=\"minimize\")\n",
    "study_fus.optimize(objective_fus, n_trials=80, show_progress_bar=True)\n",
    "print(\"BEST FUS params:\", study_fus.best_trial.params, \"medianAPE:\", study_fus.best_value)\n",
    "\n",
    "# финальная fusion-модель на всём train\n",
    "best_fus = CatBoostRegressor(**{**study_fus.best_trial.params,\n",
    "                                \"loss_function\":\"RMSE\",\"iterations\":8000,\n",
    "                                \"od_type\":\"Iter\",\"random_seed\":42,\"verbose\":200})\n",
    "best_fus.fit(Pool(X_fus, to_log(y_all), cat_features=cat_idx_fus))\n",
    "\n",
    "\n",
    "X_trj = train_join.loc[train_mask].drop(columns=[id_col])\n",
    "X_vaj = train_join.loc[valid_mask].drop(columns=[id_col])\n",
    "pool_trj = Pool(X_trj, y_tr, cat_features=cat_idx)\n",
    "pool_vaj = Pool(X_vaj, y_va, cat_features=cat_idx)\n",
    "\n",
    "cb_fusion = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\", depth=10, learning_rate=0.05,\n",
    "    iterations=5000, od_type=\"Iter\", od_wait=200,\n",
    "    random_seed=42, verbose=200\n",
    ")\n",
    "cb_fusion.fit(pool_trj, eval_set=pool_vaj)\n",
    "\n",
    "pred_va_fusion = from_log(cb_fusion.predict(pool_vaj))\n",
    "val_medAPE_fusion = median_ape(train.loc[valid_mask, target_col], pred_va_fusion)\n",
    "print(\"VALID medianAPE (fusion):\", val_medAPE_fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сегментные веса (фрагмент): {'Седан': 0.7974897986676626, 'Минивэн': 0.5019377502545568, 'Фургон': 0.3266626961816229, 'Внедорожник': 0.5196959284591325, 'Хетчбэк': 0.8934386424876263, 'Универсал': 0.5375304408970908, 'Лифтбек': 0.8079228081536266, 'Микроавтобус': 0.7674456358531248}\n",
      "✔️ submission_ensemble_segmented.csv готов\n"
     ]
    }
   ],
   "source": [
    "# [STEP A1] GET OOF PREDS (TAB & FUSION) WITH BEST PARAMS\n",
    "\n",
    "def get_oof_preds(model_params, X, y, cat_idx, cv):\n",
    "    oof = np.zeros(len(X))\n",
    "    models = []\n",
    "    for tr_idx, va_idx in cv.split(X):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "        m = CatBoostRegressor(**model_params, loss_function=\"RMSE\", iterations=8000,\n",
    "                              od_type=\"Iter\", random_seed=42, verbose=False)\n",
    "        m.fit(Pool(X_tr, to_log(y_tr), cat_features=cat_idx),\n",
    "              eval_set=Pool(X_va, to_log(y_va), cat_features=cat_idx))\n",
    "        oof[va_idx] = from_log(m.predict(Pool(X_va, cat_features=cat_idx)))\n",
    "        models.append(m)\n",
    "    return oof, models\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_tab, tab_models = get_oof_preds(study_tab.best_trial.params, X_tab, y_all, cat_idx_tab, cv)\n",
    "oof_fus, fus_models = get_oof_preds(study_fus.best_trial.params, X_fus, y_all, cat_idx_fus, cv)\n",
    "\n",
    "print(\"OOF TAB medianAPE:\", median_ape(y_all, oof_tab))\n",
    "print(\"OOF FUS medianAPE:\", median_ape(y_all, oof_fus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [STEP A2] SEGMENTED ENSEMBLE WITH SHRINKAGE (USING OOF) + SUBMISSION\n",
    "\n",
    "def best_w_ternary(p1, p2, y, iters=60):\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(iters):\n",
    "        m1 = lo + (hi - lo)/3; m2 = hi - (hi - lo)/3\n",
    "        s1 = median_ape(y, (1-m1)*p1 + m1*p2)\n",
    "        s2 = median_ape(y, (1-m2)*p1 + m2*p2)\n",
    "        if s1 < s2: hi = m2\n",
    "        else:       lo = m1\n",
    "    w = (lo+hi)/2\n",
    "    return float(w), float(median_ape(y, (1-w)*p1 + w*p2))\n",
    "\n",
    "# глобальный вес по OOF\n",
    "w_glob, val_glob = best_w_ternary(oof_tab, oof_fus, y_all, iters=80)\n",
    "print(f\"GLOBAL w_fusion={w_glob:.3f} | OOF medianAPE={val_glob:.5f}\")\n",
    "\n",
    "# сегментный ключ (пример: body_type*engine_type*drive_type + бины по mileage)\n",
    "seg_cols_cat = [\"body_type\",\"engine_type\",\"drive_type\"]\n",
    "seg_key_all = train[seg_cols_cat].astype(str).agg(\"|\".join, axis=1)\n",
    "mileage_bins = pd.qcut(train[\"mileage\"], q=[0,.2,.4,.6,.8,1.0], duplicates='drop').astype(str)\n",
    "seg_key_all = (seg_key_all + \"||\" + mileage_bins).astype(str)\n",
    "\n",
    "seg2w = {}\n",
    "min_n = 150\n",
    "shrink_k = 400.0\n",
    "\n",
    "for key, idx in pd.Series(seg_key_all).groupby(seg_key_all):\n",
    "    idx = idx.index.values\n",
    "    if len(idx) < 30: \n",
    "        continue\n",
    "    w_raw, _ = best_w_ternary(oof_tab[idx], oof_fus[idx], y_all[idx], iters=40)\n",
    "    alpha = len(idx) / (len(idx) + shrink_k)\n",
    "    w_smooth = alpha*w_raw + (1-alpha)*w_glob\n",
    "    if len(idx) < min_n:\n",
    "        w_smooth = 0.5*w_smooth + 0.5*w_glob\n",
    "    seg2w[key] = float(w_smooth)\n",
    "\n",
    "# тестовые предсказания как среднее по fold-моделям\n",
    "from catboost import Pool\n",
    "pred_test_tab = np.mean([from_log(m.predict(Pool(test_exp.drop(columns=[id_col]), cat_features=cat_idx_tab)))\n",
    "                         for m in tab_models], axis=0)\n",
    "pred_test_fus = np.mean([from_log(m.predict(Pool(test_join.drop(columns=[id_col]), cat_features=cat_idx_fus)))\n",
    "                         for m in fus_models], axis=0)\n",
    "\n",
    "# сегментные веса на тесте\n",
    "seg_key_test = test[seg_cols_cat].astype(str).agg(\"|\".join, axis=1)\n",
    "test_bins = pd.qcut(test[\"mileage\"], q=[0,.2,.4,.6,.8,1.0], duplicates='drop').astype(str)\n",
    "seg_key_test = (seg_key_test + \"||\" + test_bins).astype(str)\n",
    "\n",
    "w_vec = np.array([seg2w.get(k, w_glob) for k in seg_key_test], dtype=float)\n",
    "pred_test_seg = (1.0 - w_vec)*pred_test_tab + w_vec*pred_test_fus\n",
    "\n",
    "# сборка по sample (жёсткий формат ID,target)\n",
    "pred_df = pd.DataFrame({\"ID\": test[id_col].astype(int).values, \"target\": pred_test_seg.astype(float)})\n",
    "sub = sample[[\"ID\"]].merge(pred_df, on=\"ID\", how=\"left\")\n",
    "assert list(sub.columns) == [\"ID\",\"target\"] and len(sub)==len(sample)\n",
    "sub.to_csv(\"submission_ensemble_segmented_oof.csv\", index=False, sep=\",\", float_format=\"%.6f\")\n",
    "print(\"✔️ submission_ensemble_segmented_oof.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [STEP 8C] ТОЧНЫЙ ВЕС АНСАМБЛЯ (ТЕРНАРНЫЙ ПОИСК ПО medianAPE)\n",
    "import numpy as np\n",
    "\n",
    "y_va_true = train.loc[valid_mask, target_col].values\n",
    "\n",
    "def median_ape(y, yhat):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    return np.median(np.abs(yhat - y) / np.clip(y, 1e-9, None))\n",
    "\n",
    "def best_w_ternary(p1, p2, y, iters=60):\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(iters):\n",
    "        m1 = lo + (hi - lo) / 3\n",
    "        m2 = hi - (hi - lo) / 3\n",
    "        s1 = median_ape(y, (1-m1)*p1 + m1*p2)\n",
    "        s2 = median_ape(y, (1-m2)*p1 + m2*p2)\n",
    "        if s1 < s2: hi = m2\n",
    "        else:       lo = m1\n",
    "    w = (lo + hi) / 2\n",
    "    val = median_ape(y, (1-w)*p1 + w*p2)\n",
    "    return float(w), float(val)\n",
    "\n",
    "w_opt, val_medape_opt = best_w_ternary(pred_va_tab, pred_va_fusion, y_va_true)\n",
    "print(f\"🔧 w_fusion (ternary) = {w_opt:.4f}  |  VAL medianAPE = {val_medape_opt:.5f}  |  Score ≈ {1/(1+val_medape_opt):.4f}\")\n",
    "\n",
    "# применяем к тесту\n",
    "pred_test_ens = (1.0 - w_opt) * pred_test_tab + w_opt * pred_test_fusion\n",
    "# [STEP 8C FINAL] СОХРАНЕНИЕ SUBMISSION ПОСЛЕ ТЕРНАРНОГО ПОИСКА ВЕСА\n",
    "\n",
    "# применяем на тесте оптимальный вес\n",
    "pred_test_ens = (1.0 - w_opt) * pred_test_tab + w_opt * pred_test_fusion\n",
    "\n",
    "# собираем в таблицу с ID\n",
    "pred_df_ens = pd.DataFrame({\n",
    "    \"ID\": test[id_col].astype(int).values,\n",
    "    \"target\": pred_test_ens.astype(float)\n",
    "})\n",
    "\n",
    "# подгоняем под sample_submission (чтобы ID совпадали по порядку)\n",
    "sub_ens = sample[[\"ID\"]].merge(pred_df_ens, on=\"ID\", how=\"left\")\n",
    "\n",
    "# сохраняем в CSV\n",
    "sub_ens[[\"ID\", \"target\"]].to_csv(\"submission_ensemble_8C.csv\",\n",
    "                                 index=False, sep=\",\", float_format=\"%.6f\")\n",
    "\n",
    "print(f\"✔️ submission_ensemble_8C.csv сохранён (w_fusion={w_opt:.4f}, w_tab={1-w_opt:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
