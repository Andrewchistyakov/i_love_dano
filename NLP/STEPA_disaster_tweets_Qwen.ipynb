{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e73cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b8a4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a2c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = train.drop(columns=['target'])\n",
    "y = train['target']\n",
    "\n",
    "# Сделайте разделение даты на трейн и валидацию с помощью train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f997eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds),\n",
    "        \"recall\": recall_score(labels, preds)\n",
    "    }\n",
    "\n",
    "\n",
    "# BertForSequenceClassification автоматически добавляет линейный слой на клс модели с выбранным количеством лейблов\n",
    "#TO DO\n",
    "'''\n",
    "Обучите берт используя Trainer, после чего создайте сабмит с его предсказаниеями и проверьте результат на кагле\n",
    "'''\n",
    "\n",
    "# используйте эти параметры обучения\n",
    "training_args = TrainingArguments(\n",
    "    # Основные параметры\n",
    "    output_dir='./bert-binary-classifier',  # Директория для сохранения\n",
    "    \n",
    "    # Параметры обучения\n",
    "    num_train_epochs=3,                     # Количество эпох\n",
    "    per_device_train_batch_size=1,         # Размер батча для обучения\n",
    "    per_device_eval_batch_size=1,          # Размер батча для валидации\n",
    "    learning_rate=2e-5,                     # Learning rate\n",
    "    warmup_ratio = 0.1,                     # 10% от общего числа шагов для вармапа или warmup_steps = int(0.1 * total_training_steps)\n",
    "    lr_scheduler_type = 'cosine',           # Можете посмотреть на них в \n",
    "                                            # https://www.kaggle.com/code/snnclsr/learning-rate-schedulers \n",
    "                                            # соответсвующий ему будет get_cosine_schedule_with_warmup\n",
    "    gradient_accumulation_steps=8,\n",
    "    # Сохранение и логирование\n",
    "    logging_dir='./logs',                   # Директория для логов\n",
    "    logging_steps=20,                      # Частота логирования\n",
    "    save_steps=200,                         # Частота сохранения\n",
    "    save_total_limit=2,                     # Максимум чекпоинтов\n",
    "    save_strategy='steps',                  # Стратегия сохранения\n",
    "    \n",
    "    # Валидация\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=200,            # Стратегия валидации\n",
    "    load_best_model_at_end=True,            # Загружать лучшую модель\n",
    "    metric_for_best_model='f1',             # Метрика для выбора лучшей\n",
    "    greater_is_better=True,                 # Больше значение = лучше\n",
    "    # воспроизводимость\n",
    "    seed=42,                                # Seed для воспроизводимости\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8f2298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742b89e7576e4dbba112580013232f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39043265fd0448a192a3ed4c79005bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": X_train['text'].tolist(), \"label\": y_train.tolist()})\n",
    "val_dataset  = Dataset.from_dict({\"text\": X_val['text'].tolist(), \"label\": y_val.tolist()})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04036177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import os\n",
    "\n",
    "# model_path = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "model_path = \"bert-binary-classifier/checkpoint-2283\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0943f04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2283' max='2283' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2283/2283 1:36:09, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.618200</td>\n",
       "      <td>0.428719</td>\n",
       "      <td>0.815496</td>\n",
       "      <td>0.739574</td>\n",
       "      <td>0.927907</td>\n",
       "      <td>0.614792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.440700</td>\n",
       "      <td>0.653211</td>\n",
       "      <td>0.782666</td>\n",
       "      <td>0.771251</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.859784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.797111</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>0.731608</td>\n",
       "      <td>0.827427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.480926</td>\n",
       "      <td>0.819435</td>\n",
       "      <td>0.778047</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>0.742681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.714095</td>\n",
       "      <td>0.831254</td>\n",
       "      <td>0.780529</td>\n",
       "      <td>0.875479</td>\n",
       "      <td>0.704160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.577508</td>\n",
       "      <td>0.826658</td>\n",
       "      <td>0.786062</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.747304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.795798</td>\n",
       "      <td>0.772827</td>\n",
       "      <td>0.734722</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.837163</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.863884</td>\n",
       "      <td>0.733436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.916678</td>\n",
       "      <td>0.820749</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.794671</td>\n",
       "      <td>0.781202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.867684</td>\n",
       "      <td>0.833224</td>\n",
       "      <td>0.797448</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.770416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.867435</td>\n",
       "      <td>0.833880</td>\n",
       "      <td>0.797438</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.767334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "def train():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2532af5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3998e2b3dddc482d9a7c01d4e35d6737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_dict({\"text\": test[\"text\"].tolist()})\n",
    "\n",
    "# токенизируем (обязательно!)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda examples: tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # как при обучении!\n",
    "        max_length=512\n",
    "    ),\n",
    "    batched=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ad528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def predict_argmax(test_dataset, model, tokenizer,\n",
    "                   device=\"cuda\", batch_size=16) -> list[float]:\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=\"max_length\",  # строго до max_length\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Predicting\"):\n",
    "            # Собираем только tensor-поля и исключаем метки, если они есть\n",
    "            model_inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in batch.items()\n",
    "                if isinstance(v, torch.Tensor) and k not in (\"label\", \"labels\")\n",
    "            }\n",
    "\n",
    "            logits = model(**model_inputs).logits\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]  # вероятность класса 1\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85889b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 96/96 [1:11:00<00:00, 44.38s/it] \n"
     ]
    }
   ],
   "source": [
    "# val_dataset = val_dataset.remove_columns(\"label\")\n",
    "# val_dataset = val_dataset.remove_columns(\"text\")\n",
    "\n",
    "val_preds = predict_argmax(test_dataset=val_dataset, model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "799c3256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.8299999999999996 with F1: 0.7986906710310966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for t in np.arange(0.1, 0.9, 0.01):\n",
    "    preds_bin = (val_preds >= t).astype(int)\n",
    "    f1 = f1_score(y_val, preds_bin)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(\"Best threshold:\", best_threshold, \"with F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445a5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_with_threshold(predictions, test_df, threshold=0.65):\n",
    "    predictions = (np.array(predictions) >= threshold).astype(int)\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"target\": predictions\n",
    "    })\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    submission_df.to_csv(f\"Submission_{timestamp}.csv\", index=False)\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6cec7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 204/204 [02:07<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = predict_argmax(test_dataset=test_dataset, model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28eb0648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_submission_with_threshold(test_preds, test, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
