{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da84b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae8097",
   "metadata": {},
   "source": [
    "2. Конфиг (пути, колонки, тип задачи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d32967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к train/test таблицам\n",
    "train_path = \"train.csv\"\n",
    "test_path = \"test.csv\"\n",
    "\n",
    "# Название колонки с ID картинки\n",
    "IMAGE_ID_COL = \"Id\"     # поменяй, если у тебя другой столбец\n",
    "\n",
    "# Название колонки с таргетом\n",
    "TARGET_COL = \"Pawpularity\"         # сюда поставь имя своей целевой переменной\n",
    "\n",
    "# Тип задачи: \"regression\" или \"classification\"\n",
    "TASK_TYPE = \"regression\"      # если классификация, поставь \"classification\"\n",
    "\n",
    "# Папки с картинками\n",
    "train_images_dir = \"train\"\n",
    "test_images_dir = \"test\"\n",
    "\n",
    "# Расширение картинок\n",
    "# Если в таблице image_id уже содержит \".jpg\", поставь IMAGE_EXT = \"\"\n",
    "IMAGE_EXT = \".jpg\"\n",
    "\n",
    "# Имя файла сабмита\n",
    "submission_path = \"submission.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e210a06",
   "metadata": {},
   "source": [
    "3. Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40c5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9912, 14)\n",
      "Test shape: (8, 13)\n",
      "Train columns: ['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity']\n",
      "Test columns: ['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "print(\"Train columns:\", train.columns.tolist())\n",
    "print(\"Test columns:\", test.columns.tolist())\n",
    "# Если в IMAGE_ID_COL уже лежит something.jpg, можно сделать IMAGE_EXT = \"\" и не дописывать расширение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ecc73",
   "metadata": {},
   "source": [
    "4. Настройка устройства (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afed753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b8ebd",
   "metadata": {},
   "source": [
    "**ФОТКИ**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1a17a",
   "metadata": {},
   "source": [
    "5. Загружаем ResNet и режем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cbb719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем предобученную ResNet50\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Обрезаем последний полносвязный слой, чтобы модель возвращала эмбеддинг (2048 чисел)\n",
    "resnet.fc = nn.Identity()\n",
    "\n",
    "# Переносим модель на GPU/CPU\n",
    "resnet.to(device)\n",
    "\n",
    "# Включаем eval-режим (инференс, без обучения)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2e8fd",
   "metadata": {},
   "source": [
    "6. Трансформации для картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ab1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ec75f",
   "metadata": {},
   "source": [
    "7. Функция: получить L2-нормализованный эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f65172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_embedding(image_path):\n",
    "    \"\"\"\n",
    "    1. Загружает картинку по пути image_path.\n",
    "    2. Применяет стандартные трансформации под ResNet.\n",
    "    3. Прогоняет через ResNet на GPU/CPU.\n",
    "    4. Возвращает L2-нормализованный вектор (numpy, shape = (2048,)).\n",
    "    \"\"\"\n",
    "    # Загружаем изображение и приводим к RGB\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Применяем трансформации\n",
    "    image = image_transform(image)\n",
    "    \n",
    "    # Добавляем batch dimension: [C, H, W] -> [1, C, H, W]\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    # Переносим на устройство\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # Прогоняем через модель\n",
    "    with torch.no_grad():\n",
    "        emb_tensor = resnet(image)   # shape: [1, 2048]\n",
    "    \n",
    "    # Переводим в numpy и убираем размер батча\n",
    "    emb = emb_tensor.cpu().numpy().reshape(-1)  # shape: (2048,)\n",
    "    \n",
    "    # L2-нормализация\n",
    "    norm = np.linalg.norm(emb)\n",
    "    if norm > 0:\n",
    "        emb = emb / norm\n",
    "    \n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148d05b",
   "metadata": {},
   "source": [
    "8. Извлекаем эмбеддинги для train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9f9edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train embeddings: 100%|██████████| 9912/9912 [02:19<00:00, 71.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: (9912, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "\n",
    "for image_id in tqdm(train[IMAGE_ID_COL], desc=\"Train embeddings\"):\n",
    "    # Если в image_id уже есть \".jpg\", используем IMAGE_EXT = \"\"\n",
    "    img_name = str(image_id) + IMAGE_EXT\n",
    "    img_path = os.path.join(train_images_dir, img_name)\n",
    "    \n",
    "    emb = get_normalized_embedding(img_path)\n",
    "    train_embeddings.append(emb)\n",
    "\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "print(\"Train embeddings shape:\", train_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a0d4a",
   "metadata": {},
   "source": [
    "9. Извлекаем эмбеддинги для test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b05de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test embeddings: 100%|██████████| 8/8 [00:00<00:00, 113.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (8, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = []\n",
    "\n",
    "for image_id in tqdm(test[IMAGE_ID_COL], desc=\"Test embeddings\"):\n",
    "    img_name = str(image_id) + IMAGE_EXT\n",
    "    img_path = os.path.join(test_images_dir, img_name)\n",
    "    \n",
    "    emb = get_normalized_embedding(img_path)\n",
    "    test_embeddings.append(emb)\n",
    "\n",
    "test_embeddings = np.array(test_embeddings)\n",
    "\n",
    "print(\"Test embeddings shape:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4b51e",
   "metadata": {},
   "source": [
    "10. Добавляем эмбеддинги в таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e6552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train full shape: (9912, 2062)\n",
      "Test full shape: (8, 2061)\n"
     ]
    }
   ],
   "source": [
    "emb_dim = train_embeddings.shape[1]\n",
    "emb_cols = [f\"f_{i}\" for i in range(emb_dim)]\n",
    "\n",
    "train_emb_df = pd.DataFrame(train_embeddings, columns=emb_cols)\n",
    "test_emb_df = pd.DataFrame(test_embeddings, columns=emb_cols)\n",
    "\n",
    "train_full = pd.concat([train.reset_index(drop=True), train_emb_df], axis=1)\n",
    "test_full = pd.concat([test.reset_index(drop=True), test_emb_df], axis=1)\n",
    "\n",
    "print(\"Train full shape:\", train_full.shape)\n",
    "print(\"Test full shape:\", test_full.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abfced",
   "metadata": {},
   "source": [
    "11. (Опционально) фича косинусной похожести до среднего эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c5b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added feature cos_sim_to_mean\n"
     ]
    }
   ],
   "source": [
    "# Считаем средний эмбеддинг по train\n",
    "mean_emb = train_embeddings.mean(axis=0)\n",
    "\n",
    "# L2-нормализуем центр\n",
    "mean_norm = np.linalg.norm(mean_emb)\n",
    "if mean_norm > 0:\n",
    "    mean_emb = mean_emb / mean_norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Косинусная похожесть между двумя векторами a и b.\n",
    "    a и b могут быть уже нормализованы, но мы перестрахуемся.\n",
    "    \"\"\"\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    value = np.dot(a, b) / denom\n",
    "    return value\n",
    "\n",
    "# Добавляем фичу для train\n",
    "train_cos_sim = []\n",
    "for emb in train_embeddings:\n",
    "    sim = cosine_similarity(emb, mean_emb)\n",
    "    train_cos_sim.append(sim)\n",
    "\n",
    "train_full[\"cos_sim_to_mean\"] = train_cos_sim\n",
    "\n",
    "# Добавляем фичу для test\n",
    "test_cos_sim = []\n",
    "for emb in test_embeddings:\n",
    "    sim = cosine_similarity(emb, mean_emb)\n",
    "    test_cos_sim.append(sim)\n",
    "\n",
    "test_full[\"cos_sim_to_mean\"] = test_cos_sim\n",
    "\n",
    "print(\"Added feature cos_sim_to_mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69292493",
   "metadata": {},
   "source": [
    "12. Явно задаём списки фич по типам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434a697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Id  Subject Focus  Eyes  Face  Near  \\\n",
       "0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n",
       "1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n",
       "2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n",
       "3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n",
       "4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n",
       "...                                ...            ...   ...   ...   ...   \n",
       "9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n",
       "9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n",
       "9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n",
       "9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n",
       "9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n",
       "\n",
       "      Action  Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          0          0      1        0      0          0     0     0   \n",
       "1          0          0      0        0      0          0     0     0   \n",
       "2          0          0      0        0      1          1     0     0   \n",
       "3          0          0      0        0      0          0     0     0   \n",
       "4          0          0      1        0      0          0     0     0   \n",
       "...      ...        ...    ...      ...    ...        ...   ...   ...   \n",
       "9907       0          0      0        0      0          0     0     1   \n",
       "9908       0          0      0        0      0          0     0     0   \n",
       "9909       0          0      0        0      1          1     0     0   \n",
       "9910       0          0      0        0      1          0     0     0   \n",
       "9911       0          0      0        0      0          0     0     0   \n",
       "\n",
       "      Pawpularity  \n",
       "0              63  \n",
       "1              42  \n",
       "2              28  \n",
       "3              15  \n",
       "4              72  \n",
       "...           ...  \n",
       "9907           15  \n",
       "9908           70  \n",
       "9909           20  \n",
       "9910           20  \n",
       "9911           30  \n",
       "\n",
       "[9912 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "347d3f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего фич: 2061\n",
      "Первые 10 фич: ['f_0', 'f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9']\n"
     ]
    }
   ],
   "source": [
    "#Тут важное место: как раз про категориальные фичи — их оставляем строками и отмечаем индексы колонок, а не значения.\n",
    "# Эмбеддинги (все колонки, начинающиеся с \"f_\")\n",
    "embedding_features = []\n",
    "for col in train_full.columns:\n",
    "    if col.startswith(\"f_\"):\n",
    "        embedding_features.append(col)\n",
    "\n",
    "# Числовые фичи (пример — добавь свои)\n",
    "numeric_features = [\n",
    "    # \"price\",\n",
    "    # \"age\",\n",
    "]\n",
    "\n",
    "# Бинарные фичи (0/1)\n",
    "binary_features = [\n",
    "    # \"is_new\",\n",
    "    # \"has_discount\",\n",
    "    'Subject Focus',\n",
    "    'Eyes',\n",
    "    'Face',\n",
    "    'Near',\n",
    "    'Action',\n",
    "    'Accessory',\n",
    "    'Group',\n",
    "    'Collage',\n",
    "    'Human',\n",
    "    'Occlusion',\n",
    "    'Info',\n",
    "    'Blur'\n",
    "]\n",
    "\n",
    "# Фичи расстояний (если добавил cos_sim_to_mean — он числовой)\n",
    "distance_features = [\n",
    "    \"cos_sim_to_mean\"  # убери, если не использовал блок с косинусом\n",
    "]\n",
    "\n",
    "# Категориальные фичи (ОБЯЗАТЕЛЬНО ОСТАВИТЬ ИХ СТРОКАМИ)\n",
    "categorical_features = [\n",
    "    # \"color\",\n",
    "    # \"store_type\",\n",
    "]\n",
    "\n",
    "# Собираем общий список фич в правильном порядке\n",
    "feature_cols = []\n",
    "feature_cols.extend(embedding_features)\n",
    "feature_cols.extend(numeric_features)\n",
    "feature_cols.extend(binary_features)\n",
    "feature_cols.extend(distance_features)\n",
    "feature_cols.extend(categorical_features)\n",
    "\n",
    "print(\"Всего фич:\", len(feature_cols))\n",
    "print(\"Первые 10 фич:\", feature_cols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336a87d",
   "metadata": {},
   "source": [
    "13. Индексы категориальных фичей (именно колонок, не значений!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b515e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категориальные столбцы: []\n",
      "Индексы категориальных столбцов: []\n"
     ]
    }
   ],
   "source": [
    "cat_feature_indices = []\n",
    "\n",
    "for cat_col in categorical_features:\n",
    "    if cat_col in feature_cols:\n",
    "        idx = feature_cols.index(cat_col)\n",
    "        cat_feature_indices.append(idx)\n",
    "\n",
    "print(\"Категориальные столбцы:\", categorical_features)\n",
    "print(\"Индексы категориальных столбцов:\", cat_feature_indices)\n",
    "#Здесь мы как раз делаем то, о чём говорили: передаём CatBoost индексы колонок, а сами значения оставляем строками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b82a88",
   "metadata": {},
   "source": [
    "14. Готовим X, y, train/valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc61754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_full[feature_cols]\n",
    "y = train_full[TARGET_COL]\n",
    "\n",
    "X_test = test_full[feature_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7432e2",
   "metadata": {},
   "source": [
    "если запускаешь блок с оптуной, то после вот этого(верхнего) шага - стоп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dddf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7929, 2061)\n",
      "X_valid shape: (1983, 2061)\n"
     ]
    }
   ],
   "source": [
    "# Для классификации лучше использовать stratify=y (но здесь пока простой split):\n",
    "if TASK_TYPE == \"classification\":\n",
    "    stratify_param = y\n",
    "else:\n",
    "    stratify_param = None\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=stratify_param\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39fe59",
   "metadata": {},
   "source": [
    "15. Создаём CatBoost Pool (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cafaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "valid_pool = Pool(\n",
    "    data=X_valid,\n",
    "    label=y_valid,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    data=X_test,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65700e6",
   "metadata": {},
   "source": [
    "16. Обучаем CatBoost на GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a392b6b",
   "metadata": {},
   "source": [
    "Вариант A: регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2494e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 20.3992422\ttest: 20.9437192\tbest: 20.9437192 (0)\ttotal: 153ms\tremaining: 3m 48s\n",
      "100:\tlearn: 17.6270768\ttest: 18.6580389\tbest: 18.6580389 (100)\ttotal: 13.5s\tremaining: 3m 6s\n",
      "200:\tlearn: 16.7546571\ttest: 18.4063336\tbest: 18.4063336 (200)\ttotal: 26.1s\tremaining: 2m 48s\n",
      "300:\tlearn: 16.1064923\ttest: 18.3234788\tbest: 18.3199075 (298)\ttotal: 38.8s\tremaining: 2m 34s\n",
      "400:\tlearn: 15.4959616\ttest: 18.2638497\tbest: 18.2638497 (400)\ttotal: 51.4s\tremaining: 2m 20s\n",
      "500:\tlearn: 14.9246098\ttest: 18.2334244\tbest: 18.2313189 (487)\ttotal: 1m 4s\tremaining: 2m 7s\n",
      "600:\tlearn: 14.3902424\ttest: 18.2155794\tbest: 18.2144278 (565)\ttotal: 1m 16s\tremaining: 1m 53s\n",
      "700:\tlearn: 13.9271420\ttest: 18.1965719\tbest: 18.1923867 (680)\ttotal: 1m 28s\tremaining: 1m 41s\n",
      "800:\tlearn: 13.4811928\ttest: 18.1826251\tbest: 18.1805761 (765)\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "900:\tlearn: 13.0723778\ttest: 18.1747866\tbest: 18.1636985 (852)\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "1000:\tlearn: 12.6910641\ttest: 18.1604508\tbest: 18.1599779 (999)\ttotal: 2m 5s\tremaining: 1m 2s\n",
      "1100:\tlearn: 12.3282615\ttest: 18.1583646\tbest: 18.1571001 (1058)\ttotal: 2m 18s\tremaining: 50s\n",
      "1200:\tlearn: 11.9742104\ttest: 18.1430655\tbest: 18.1392442 (1179)\ttotal: 2m 29s\tremaining: 37.3s\n",
      "1300:\tlearn: 11.6199147\ttest: 18.1561505\tbest: 18.1392442 (1179)\ttotal: 2m 42s\tremaining: 24.8s\n",
      "1400:\tlearn: 11.2624932\ttest: 18.1530655\tbest: 18.1392442 (1179)\ttotal: 2m 54s\tremaining: 12.3s\n",
      "1499:\tlearn: 10.9558085\ttest: 18.1583299\tbest: 18.1392442 (1179)\ttotal: 3m 6s\tremaining: 0us\n",
      "bestTest = 18.13924419\n",
      "bestIteration = 1179\n",
      "Shrink model to first 1180 iterations.\n",
      "Validation RMSE: 18.1392\n",
      "Validation MAE:  13.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if TASK_TYPE == \"regression\":\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.03,\n",
    "        depth=6,\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        task_type=\"GPU\",   # использование GPU\n",
    "        devices=\"0\",\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=valid_pool)\n",
    "    \n",
    "    # Оценка\n",
    "    y_pred_valid = model.predict(valid_pool)\n",
    "    \n",
    "    rmse = mean_squared_error(y_valid, y_pred_valid, squared=False)\n",
    "    mae = mean_absolute_error(y_valid, y_pred_valid)\n",
    "    \n",
    "    print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "    print(f\"Validation MAE:  {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f349a",
   "metadata": {},
   "source": [
    "Вариант B: классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af83dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TASK_TYPE == \"classification\":\n",
    "#     model = CatBoostClassifier(\n",
    "#         iterations=500,\n",
    "#         learning_rate=0.05,\n",
    "#         depth=6,\n",
    "#         loss_function=\"Logloss\",\n",
    "#         eval_metric=\"AUC\",\n",
    "#         task_type=\"GPU\",   # использование GPU\n",
    "#         devices=\"0\",\n",
    "#         verbose=100\n",
    "#     )\n",
    "    \n",
    "#     model.fit(train_pool, eval_set=valid_pool)\n",
    "    \n",
    "#     # Предикт на валидации\n",
    "#     y_pred_proba_valid = model.predict_proba(valid_pool)[:, 1]  # для бинарной\n",
    "#     y_pred_label_valid = (y_pred_proba_valid > 0.5).astype(int)\n",
    "    \n",
    "#     acc = accuracy_score(y_valid, y_pred_label_valid)\n",
    "#     f1 = f1_score(y_valid, y_pred_label_valid, average=\"macro\")\n",
    "    \n",
    "#     print(f\"Validation ACC: {acc:.4f}\")\n",
    "#     print(f\"Validation F1-macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d770d3",
   "metadata": {},
   "source": [
    "17. Предсказания на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f019c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (8,)\n"
     ]
    }
   ],
   "source": [
    "if TASK_TYPE == \"regression\":\n",
    "    test_pred = model.predict(test_pool)\n",
    "\n",
    "elif TASK_TYPE == \"classification\":\n",
    "    # Для сабмита обычно полезны либо вероятности, либо классы.\n",
    "    # Здесь возьмём вероятности класса 1.\n",
    "    test_pred = model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "print(\"Test predictions shape:\", test_pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a4821",
   "metadata": {},
   "source": [
    "18. Сабмит id, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e3e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Id  Pawpularity\n",
      "0  4128bae22183829d2b5fea10effdb0c3    47.770455\n",
      "1  43a2262d7738e3d420d453815151079e    46.018941\n",
      "2  4e429cead1848a298432a0acad014c9d    50.059173\n",
      "3  80bc3ccafcc51b66303c2c263aa38486    49.549322\n",
      "4  8f49844c382931444e68dffbe20228f4    48.551166\n",
      "Saved submission to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"Id\"] = test[IMAGE_ID_COL]      # колонка id\n",
    "submission[\"Pawpularity\"] = test_pred       # колонка с предсказаниями\n",
    "\n",
    "print(submission.head())\n",
    "\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(\"Saved submission to:\", submission_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426f6f7",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0e1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7434, 14) (2478, 14)\n",
      "RMSE на тестовой выборке: 26.6983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "sample = pd.read_csv('submission.csv')\n",
    "\n",
    "train_df, test_df = train_test_split(train, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "\n",
    "# тут оценка метрики подставьте ваши предсказания в sample\n",
    "rmse = np.sqrt(np.mean((test_df['Pawpularity'] - sample['Pawpularity']) ** 2))\n",
    "print(f\"RMSE на тестовой выборке: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b8a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Id  Subject Focus  Eyes  Face  Near  \\\n",
       "0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n",
       "1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n",
       "2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n",
       "3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n",
       "4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n",
       "...                                ...            ...   ...   ...   ...   \n",
       "9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n",
       "9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n",
       "9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n",
       "9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n",
       "9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n",
       "\n",
       "      Action  Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          0          0      1        0      0          0     0     0   \n",
       "1          0          0      0        0      0          0     0     0   \n",
       "2          0          0      0        0      1          1     0     0   \n",
       "3          0          0      0        0      0          0     0     0   \n",
       "4          0          0      1        0      0          0     0     0   \n",
       "...      ...        ...    ...      ...    ...        ...   ...   ...   \n",
       "9907       0          0      0        0      0          0     0     1   \n",
       "9908       0          0      0        0      0          0     0     0   \n",
       "9909       0          0      0        0      1          1     0     0   \n",
       "9910       0          0      0        0      1          0     0     0   \n",
       "9911       0          0      0        0      0          0     0     0   \n",
       "\n",
       "      Pawpularity  \n",
       "0              63  \n",
       "1              42  \n",
       "2              28  \n",
       "3              15  \n",
       "4              72  \n",
       "...           ...  \n",
       "9907           15  \n",
       "9908           70  \n",
       "9909           20  \n",
       "9910           20  \n",
       "9911           30  \n",
       "\n",
       "[9912 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182ce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>47.770455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>46.018941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>50.059173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>49.549322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>48.551166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b03f7041962238a7c9d6537e22f9b017</td>\n",
       "      <td>50.513183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n",
       "      <td>49.052743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n",
       "      <td>50.560605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    47.770455\n",
       "1  43a2262d7738e3d420d453815151079e    46.018941\n",
       "2  4e429cead1848a298432a0acad014c9d    50.059173\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    49.549322\n",
       "4  8f49844c382931444e68dffbe20228f4    48.551166\n",
       "5  b03f7041962238a7c9d6537e22f9b017    50.513183\n",
       "6  c978013571258ed6d4637f6e8cc9d6a3    49.052743\n",
       "7  e0de453c1bffc20c22b072b34b54e50f    50.560605"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306e84e",
   "metadata": {},
   "source": [
    "**Блок: Optuna + KFold/StratifiedKFold + сабмит**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc6329",
   "metadata": {},
   "source": [
    "2.1. Подвыборка + сплит для Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d19b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna train shape: (2400, 2061)\n",
      "Optuna valid shape: (600, 2061)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# Берём подвыборку для Optuna (чтобы быстрее и безопаснее)\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=3000,      # 3k строк вполне достаточно для подбора\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "X_train_opt, X_valid_opt, y_train_opt, y_valid_opt = train_test_split(\n",
    "    X_sample,\n",
    "    y_sample,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_pool_opt = Pool(\n",
    "    data=X_train_opt,\n",
    "    label=y_train_opt,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "valid_pool_opt = Pool(\n",
    "    data=X_valid_opt,\n",
    "    label=y_valid_opt,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "print(\"Optuna train shape:\", X_train_opt.shape)\n",
    "print(\"Optuna valid shape:\", X_valid_opt.shape)\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b80d71",
   "metadata": {},
   "source": [
    "2.2. Objective на CPU + прогресс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ff6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    depth = trial.suggest_int(\"depth\", 4, 9)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True)\n",
    "    l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True)\n",
    "    random_strength = trial.suggest_float(\"random_strength\", 0.1, 2.0)\n",
    "    bagging_temperature = trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=400,               # на CPU + маленькая выборка это нормально\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        random_strength=random_strength,\n",
    "        bagging_temperature=bagging_temperature,\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        task_type=\"CPU\",             # <<< ВАЖНО: CPU, НЕ GPU\n",
    "        verbose=100,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=40\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool_opt, eval_set=valid_pool_opt)\n",
    "\n",
    "    y_pred_valid = model.predict(valid_pool_opt)\n",
    "    rmse = mean_squared_error(y_valid_opt, y_pred_valid, squared=False)\n",
    "\n",
    "    print(f\"[Trial {trial.number}] RMSE = {rmse:.4f}\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a139674",
   "metadata": {},
   "source": [
    "2.3. Запускаем Optuna (ограничение по времени и количеству трейлов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eca585",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=15,        # начни с 10–15, потом можно поднять\n",
    "    timeout=1200        # максимум ~20 минут\n",
    ")\n",
    "\n",
    "print(\"Лучшее значение RMSE:\", study.best_value)\n",
    "print(\"Лучшие параметры:\", study.best_trial.params)\n",
    "\n",
    "best_params = study.best_trial.params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33deb5c4",
   "metadata": {},
   "source": [
    "3. K-Fold уже на GPU с лучшими параметрами\n",
    "Теперь, когда best_params есть, делаем K-Fold по всему X, y.\n",
    "ЭТОТ блок ставим после Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(train_full))\n",
    "test_preds = np.zeros(len(test_full))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X, y):\n",
    "    fold += 1\n",
    "    print(f\"\\n===== Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "    X_tr = X.iloc[train_idx]\n",
    "    y_tr = y.iloc[train_idx]\n",
    "    X_val = X.iloc[valid_idx]\n",
    "    y_val = y.iloc[valid_idx]\n",
    "\n",
    "    train_pool_fold = Pool(\n",
    "        data=X_tr,\n",
    "        label=y_tr,\n",
    "        cat_features=cat_feature_indices\n",
    "    )\n",
    "\n",
    "    valid_pool_fold = Pool(\n",
    "        data=X_val,\n",
    "        label=y_val,\n",
    "        cat_features=cat_feature_indices\n",
    "    )\n",
    "\n",
    "    model_fold = CatBoostRegressor(\n",
    "        iterations=1000,                             # побольше, финальная модель\n",
    "        depth=best_params[\"depth\"],\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        l2_leaf_reg=best_params[\"l2_leaf_reg\"],\n",
    "        random_strength=best_params[\"random_strength\"],\n",
    "        bagging_temperature=best_params[\"bagging_temperature\"],\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        task_type=\"GPU\",                             # <<< здесь уже GPU\n",
    "        devices=\"0\",\n",
    "        verbose=100,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=60\n",
    "    )\n",
    "\n",
    "    model_fold.fit(train_pool_fold, eval_set=valid_pool_fold)\n",
    "\n",
    "    oof_fold = model_fold.predict(valid_pool_fold)\n",
    "    oof_preds[valid_idx] = oof_fold\n",
    "\n",
    "    test_pool = Pool(X_test, cat_features=cat_feature_indices)\n",
    "    test_fold = model_fold.predict(test_pool)\n",
    "    test_preds += test_fold / n_splits\n",
    "\n",
    "    del model_fold\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18251c3",
   "metadata": {},
   "source": [
    "OOF RMSE + сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_oof = mean_squared_error(y, oof_preds, squared=False)\n",
    "print(f\"\\nOOF RMSE (по {n_splits} фолдам): {rmse_oof:.4f}\")\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"Id\"] = test_full[\"Id\"]      # проверь имя колонки\n",
    "submission[\"Pawpularity\"] = test_preds\n",
    "\n",
    "submission.to_csv(\"submission_optuna_cpu_kfold_gpu.csv\", index=False)\n",
    "print(\"Saved submission_optuna_cpu_kfold_gpu.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
