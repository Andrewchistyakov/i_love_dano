{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c725351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import PIL\n",
    "import albumentations as A\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments, EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "from transformers import AutoImageProcessor, Swinv2ForImageClassification\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914efa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/efficientnet-b3\"\n",
    "run_name = \"./efficient-net-b3-random-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48dc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if  torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b50add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b950b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = AutoImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a3ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Степан\\AppData\\Local\\Temp\\ipykernel_17768\\1894441869.py:12: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5, 20), p=0.1),\n"
     ]
    }
   ],
   "source": [
    "# Аугментации\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n",
    "    ], p=0.3),\n",
    "\n",
    "    A.GaussianBlur(blur_limit=(3,5), p=0.1),\n",
    "    A.GaussNoise(var_limit=(5, 20), p=0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7904cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICDataset_train(Dataset):\n",
    "    def __init__(self, image_dir, df, preprocessor, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.preprocessor = preprocessor\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.df.iloc[idx]['image_name'] + '.jpg'\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "\n",
    "        with PIL.Image.open(image_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image))\n",
    "            image = augmented['image']\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                image = image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        inputs = self.preprocessor(image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "        label = int(self.df.iloc[idx]['target'])\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def show_image(self, idx):\n",
    "        image_name = self.df.iloc[idx]['image_name'] + '.jpg'\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "\n",
    "        with PIL.Image.open(image_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image))\n",
    "            image = augmented[\"image\"]\n",
    "        else:\n",
    "            image = np.array(image)\n",
    "\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Index: {idx}, Label: {self.df.iloc[idx]['target']}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069aaad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train, test_size=0.05, random_state=42, shuffle=True, stratify=train['target'])\n",
    "\n",
    "train_dataset = ISICDataset_train(\"train\", train_data, preprocessor, transform=train_transform)\n",
    "val_dataset = ISICDataset_train(\"train\", val_data, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e21bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EfficientNetForImageClassification.from_pretrained(\n",
    "#     model_name, \n",
    "#     use_safetensors=True,\n",
    "#     num_labels=2,\n",
    "#     ignore_mismatched_sizes=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка из чекпоинта \n",
    "\n",
    "model = EfficientNetForImageClassification.from_pretrained(\n",
    "    \"efficient-net-b3-random-sample/checkpoint-1200\", \n",
    "    use_safetensors=True,\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Пример заморозки backbone модели\n",
    "\n",
    "\n",
    "# for param in model.efficientnet.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyTrainer(Trainer):\n",
    "#     def get_train_dataloader(self):\n",
    "#         return DataLoader(\n",
    "#             self.train_dataset,\n",
    "#             batch_size=self.args.train_batch_size,\n",
    "#             shuffle=True,\n",
    "#             num_workers=self.args.dataloader_num_workers,\n",
    "#             prefetch_factor=4,          # <-- ваш параметр\n",
    "#             pin_memory=True,\n",
    "#             collate_fn=self.data_collator,\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = torch.tensor(pred.predictions)\n",
    "    labels = torch.tensor(pred.label_ids)\n",
    "    probs = torch.softmax(preds, dim=1)\n",
    "    pred_classes = torch.argmax(probs, dim=1)\n",
    "    f1 = f1_score(labels, pred_classes, average=\"weighted\")\n",
    "    auc = roc_auc_score(labels.numpy(), probs[:, 1].numpy())\n",
    "    precision = precision_score(labels, pred_classes, average=\"weighted\")\n",
    "    recall = recall_score(labels, pred_classes, average=\"weighted\")\n",
    "\n",
    "    # --- Пример КАСТОМНОЙ сложной метрики ---\n",
    "    num_classes = preds.shape[1]\n",
    "    ber_list = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        # True Positives и False Negatives для данного класса\n",
    "        tp = ((pred_classes == cls) & (labels == cls)).sum().item()\n",
    "        fn = ((pred_classes != cls) & (labels == cls)).sum().item()\n",
    "\n",
    "        # Добавим защиту от деления на ноль\n",
    "        if tp + fn > 0:\n",
    "            fn_rate = fn / (tp + fn)\n",
    "        else:\n",
    "            fn_rate = 0.0\n",
    "\n",
    "        ber_list.append(fn_rate)\n",
    "\n",
    "    # Финальная кастомная метрика\n",
    "    ber = sum(ber_list) / len(ber_list)\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc_roc\": auc,\n",
    "        \"balanced_error_rate\": ber\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Основные параметры\n",
    "    output_dir=run_name,  # Директория для сохранения\n",
    "    \n",
    "    # Параметры обучения\n",
    "    num_train_epochs=5,                     # Количество эпох\n",
    "    per_device_train_batch_size=24,         # Размер батча для обучения\n",
    "    per_device_eval_batch_size=24,          # Размер батча для валидации\n",
    "    learning_rate=3e-5,                     # Learning rate\n",
    "    warmup_ratio = 0.1,                     # 10% от общего числа шагов для вармапа или warmup_steps = int(0.1 * total_training_steps)\n",
    "    lr_scheduler_type = 'cosine',           # Можете посмотреть на них в \n",
    "                                            # https://www.kaggle.com/code/snnclsr/learning-rate-schedulers \n",
    "                                            # соответсвующий ему будет get_cosine_schedule_with_warmup\n",
    "    gradient_accumulation_steps=4,\n",
    "    # Сохранение и логирование\n",
    "    logging_dir='./logs',                   # Директория для логов\n",
    "    logging_steps=20,                      # Частота логирования\n",
    "    save_steps=300,                         # Частота сохранения\n",
    "    save_total_limit=2,                     # Максимум чекпоинтов\n",
    "    save_strategy='steps',                  # Стратегия сохранения\n",
    "    \n",
    "    # dataloader_num_workers=4,\n",
    "\n",
    "    # Валидация\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=300,            # Стратегия валидации\n",
    "    load_best_model_at_end=True,            # Загружать лучшую модель\n",
    "    metric_for_best_model='auc_roc',\n",
    "    greater_is_better=True,                 # Больше значение = лучше\n",
    "    # воспроизводимость\n",
    "    seed=42,                                # Seed для воспроизводимости\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca93be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pos = len(train_dataset.df[train_dataset.df['target'] == 1])\n",
    "# num_neg = len(train_dataset.df[train_dataset.df['target'] == 0])\n",
    "# weight = torch.tensor([1.0, num_neg / num_pos]).to(\"cuda\")  # [w0, w1]\n",
    "# class WeightedTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "#         labels = inputs.pop(\"labels\")\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.get(\"logits\")  # [B, num_labels]\n",
    "\n",
    "#         loss_fct = CrossEntropyLoss(weight=weight)\n",
    "#         loss = loss_fct(logits, labels.long())\n",
    "\n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "class_counts = train_data['target'].value_counts().to_dict()\n",
    "weights = [1.0 / class_counts[label] for label in train_data['target']]\n",
    "\n",
    "class RandomSamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        dataset = self.train_dataset\n",
    "        \n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=weights,\n",
    "            num_samples=len(dataset),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            sampler=sampler,\n",
    "            collate_fn=self.data_collator,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5965121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RandomSamplerTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4dca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1515' max='1640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1515/1640 6:02:27 < 29:56, 0.07 it/s, Epoch 4.62/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc Roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.378831</td>\n",
       "      <td>0.878812</td>\n",
       "      <td>0.980023</td>\n",
       "      <td>0.808087</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.267805</td>\n",
       "      <td>0.925921</td>\n",
       "      <td>0.983345</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.940502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.149879</td>\n",
       "      <td>0.957210</td>\n",
       "      <td>0.981419</td>\n",
       "      <td>0.940253</td>\n",
       "      <td>0.942726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.161560</td>\n",
       "      <td>0.953437</td>\n",
       "      <td>0.981815</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>0.946391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>0.950118</td>\n",
       "      <td>0.980856</td>\n",
       "      <td>0.928183</td>\n",
       "      <td>0.922710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\trainer.py:2618\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2616\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2617\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2618\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2619\u001b[39m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[32m   2620\u001b[39m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m.current_gradient_accumulation_steps = \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\trainer.py:5654\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5652\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5653\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5654\u001b[39m         batch_samples.append(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[32m   5655\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5656\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mISICDataset_train.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     13\u001b[39m     image = img.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     augmented = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     image = augmented[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\albumentations\\core\\composition.py:610\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **data)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocess(data)\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28mself\u001b[39m._track_transform_params(t, data)\n\u001b[32m    612\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.check_data_post_transform(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:273\u001b[39m, in \u001b[36mBasicTransform.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deterministic:\n\u001b[32m    272\u001b[39m         kwargs[\u001b[38;5;28mself\u001b[39m.save_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] = deepcopy(params)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:309\u001b[39m, in \u001b[36mBasicTransform.apply_with_params\u001b[39m\u001b[34m(self, params, *args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    308\u001b[39m         target_function = \u001b[38;5;28mself\u001b[39m._key2func[key]\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m         res[key] = \u001b[43mensure_contiguous_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_contiguous_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    313\u001b[39m     res[key] = arg\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\albumentations\\core\\utils.py:522\u001b[39m, in \u001b[36mensure_contiguous_output\u001b[39m\u001b[34m(arg)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensure that numpy arrays are contiguous in memory.\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m \n\u001b[32m    520\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, np.ndarray):\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     arg = np.ascontiguousarray(arg)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Sequence):\n\u001b[32m    524\u001b[39m     arg = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(ensure_contiguous_output, arg))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad316a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = 0\n",
    "test_dataset = ISICDataset_train(\"test\", test, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a48772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cdfae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor(predictions.predictions)\n",
    "\n",
    "probs = torch.softmax(logits, dim=1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ea9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"image_name\": test['image_name'],\n",
    "    \"target\": probs\n",
    "})\n",
    "submission_df.to_csv(\"submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8627ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='1381' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  34/1381 01:24 < 57:40, 0.39 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m full_train_dataset = ISICDataset_train(\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, train, preprocessor)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m full_train_predictions = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_train_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m full_train_logits = torch.tensor(predictions.predictions)\n\u001b[32m      4\u001b[39m full_train_probs = torch.softmax(logits, dim=\u001b[32m1\u001b[39m)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\trainer.py:4567\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4564\u001b[39m start_time = time.time()\n\u001b[32m   4566\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4567\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[32m   4569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4570\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\transformers\\trainer.py:4675\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4672\u001b[39m observed_num_examples = \u001b[32m0\u001b[39m\n\u001b[32m   4674\u001b[39m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4675\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4676\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[32m   4677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4678\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\accelerate\\data_loader.py:579\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    577\u001b[39m     current_batch = send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28mself\u001b[39m._non_blocking)\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m._update_state_dict()\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m next_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_index >= \u001b[38;5;28mself\u001b[39m.skip_batches:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mISICDataset_train.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     10\u001b[39m image_path = os.path.join(\u001b[38;5;28mself\u001b[39m.image_dir, image_name)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PIL.Image.open(image_path) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     image = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m     16\u001b[39m     augmented = \u001b[38;5;28mself\u001b[39m.transform(image=np.array(image))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\PIL\\Image.py:995\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    993\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    999\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\DL\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    290\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    292\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "full_train_dataset = ISICDataset_train(\"train\", train, preprocessor)\n",
    "full_train_predictions = trainer.predict(full_train_dataset)\n",
    "full_train_logits = torch.tensor(predictions.predictions)\n",
    "full_train_probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "submission_df = pd.DataFrame({\n",
    "    \"image_name\": train['image_name'],\n",
    "    \"target\": full_train_probs\n",
    "})\n",
    "submission_df.to_csv(\"train_submission2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
